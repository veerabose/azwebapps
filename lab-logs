[student@workstation ~]$ lab-configure

 . Enter the GitHub account name: veerabose
   Verifying GitHub account name: veerabose

 . Enter the Quay.io account name: veeraabose
   Verifying Quay.io account name: veeraabose

 . Configuring RHT_OCP4_GITHUB_USER variable: SUCCESS
 . Configuring RHT_OCP4_QUAY_USER variable:   SUCCESS

 . To reconfigure, run: lab-configure -d

 . Ensuring user 'developer' can log in to the OpenShift cluster.
Warning: Permanently added 'utility,172.25.250.253' (ECDSA) to the list of known hosts.
ERROR: Cannot currently log in as user kubeadmin.
[student@workstation ~]$ ^C
[student@workstation ~]$ ^C
[student@workstation ~]$ https://github.com/veerabose/DO180-apps.git
bash: https://github.com/veerabose/DO180-apps.git: No such file or directory
[student@workstation ~]$ git clone https://github.com/veerabose/DO180-apps.git
Cloning into 'DO180-apps'...
remote: Enumerating objects: 172, done.
remote: Total 172 (delta 0), reused 0 (delta 0), pack-reused 172
Receiving objects: 100% (172/172), 287.19 KiB | 480.00 KiB/s, done.
Resolving deltas: 100% (70/70), done.
[student@workstation ~]$ ls
Desktop  DO180-apps  Documents  Downloads  Music  Pictures  Public  Templates  Videos
[student@workstation ~]$ cd DO180-apps/
[student@workstation DO180-apps]$ git status
On branch master
Your branch is up to date with 'origin/master'.

nothing to commit, working tree clean
[student@workstation DO180-apps]$

[student@workstation DO180-apps]$ git checkout -b testbranch
Switched to a new branch testbranch

[student@workstation DO180-apps]$ git add .
[student@workstation DO180-apps]$ git commit -m "DO180"
[testbranch a2978b1] DO180
 1 file changed, 1 insertion(+)
 create mode 100644 TEST
[student@workstation DO180-apps]$ git push --set-upstream origin testbranch
Gtk-Message: 12:09:29.984: Failed to load module "canberra-gtk-module"
Gtk-Message: 12:09:42.026: Failed to load module "canberra-gtk-module"
remote: No anonymous write access.
fatal: Authentication failed for 'https://github.com/veerabose/DO180-apps.git/'
[student@workstation DO180-apps]$ git push --set-upstream origin testbranch
Gtk-Message: 12:10:00.358: Failed to load module "canberra-gtk-module"
Gtk-Message: 12:10:21.575: Failed to load module "canberra-gtk-module"
Enumerating objects: 4, done.
Counting objects: 100% (4/4), done.
Delta compression using up to 2 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 285 bytes | 285.00 KiB/s, done.
Total 3 (delta 1), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (1/1), completed with 1 local object.
remote: 
remote: Create a pull request for 'testbranch' on GitHub by visiting:
remote:      https://github.com/veerabose/DO180-apps/pull/new/testbranch
remote: 
To https://github.com/veerabose/DO180-apps.git
 * [new branch]      testbranch -> testbranch
Branch 'testbranch' set up to track remote branch 'testbranch' from 'origin'.
[student@workstation DO180-apps]$ echo "OCP4" > TEST
[student@workstation DO180-apps]$ git add .
[student@workstation DO180-apps]$ git commit -m "OCP4"
[testbranch 00edc58] OCP4
 1 file changed, 1 insertion(+), 1 deletion(-)
[student@workstation DO180-apps]$ git push
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 2 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 274 bytes | 274.00 KiB/s, done.
Total 3 (delta 1), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (1/1), completed with 1 local object.
To https://github.com/veerabose/DO180-apps.git
   a2978b1..00edc58  testbranch -> testbranch
[student@workstation DO180-apps]$ 

----------------------
In this chapter, you learned:
• Containers are isolated application runtimes, created with very little overhead.
• A container image packages an application with all of its dependencies, making it easier to run
the application in different environments.
• Applications such as Podman create containers using features of the standard Linux kernel.
• Container image registries are the preferred mechanism for distributing container images to
multiple users and hosts.
• OpenShift orchestrates applications composed of multiple containers using Kubernetes.
• Kubernetes manages load balancing, high availability, and persistent storage for containerized
applications.
• OpenShift adds to Kubernetes multitenancy, security, ease of use, and continuous integration
and continuous development features.
• OpenShift routes enable external access to containerized applications in a manageable way.

---------------------------------------------

[student@workstation DO180-apps]$ lab container-create start

Setting up workstation for the Guided Exercise: Creating a MySQL database instance

 · Checking podman configuration...............................  SUCCESS
 · Creating create_table.txt file..............................  SUCCESS
[student@workstation DO180-apps]$ podman login registry.redhat.io
Username: veeraabose
Password: 
Login Succeeded!
[student@workstation DO180-apps]$

[student@workstation DO180-apps]$ podman run --name mysql-basic -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55 -d registry.redhat.io/rhel8/mysql-80:1
Trying to pull registry.redhat.io/rhel8/mysql-80:1...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 36bead343ed7 done  
Copying blob e556e33d0b40 done  
Copying blob 1b3417e31a5e done  
Copying blob 809fe483e885 done  
Copying config 82eb01fb3a done  
Writing manifest to image destination
Storing signatures
770f4a2f7d0092db37f1ecbee7346ba52d13eb7ef9429259a2db7f5d83b01e24
[student@workstation DO180-apps]$ podman ps --format "{{.ID}} {{.Image}} {{.Names}}"
770f4a2f7d00 registry.redhat.io/rhel8/mysql-80:1 mysql-basic
[student@workstation DO180-apps]$ podman exec -it mysql-basic /bin/bash
bash-4.4$ mysql -uroot
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 8.0.26 Source distribution

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> SHOW DATABASES;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| items              |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> USE items;
Database changed
mysql> 
mysql> CREATE TABLE Projects (id int NOT NULL,
    -> name varchar(255) DEFAULT NULL,
    -> code varchar(255) DEFAULT NULL,
    -> PRIMARY KEY (id));
Query OK, 0 rows affected (0.06 sec)

mysql> SHOW TABLES;
+-----------------+
| Tables_in_items |
+-----------------+
| Projects        |
+-----------------+
1 row in set (0.00 sec)

mysql> INSERT INTO Projects (id, name, code) VALUES (1,'DevOps','DO180');
Query OK, 1 row affected (0.02 sec)

mysql> SELECT * FROM Projects;
+----+--------+-------+
| id | name   | code  |
+----+--------+-------+
|  1 | DevOps | DO180 |
+----+--------+-------+
1 row in set (0.00 sec)

mysql>
mysql> exit
Bye
bash-4.4$ exit
exit
[student@workstation DO180-apps]$ 

[student@workstation DO180-apps]$ lab container-create finish

Completing the Guided Exercise: Creating a MySQL database instance

 · Removing "mysql-basic" container............................  SUCCESS
 · Removing "registry.redhat.io/rhel8/mysql-80:1" image........  SUCCESS
[student@workstation DO180-apps]$

Summary
-------------------------------------------
In this chapter, you learned:
• Podman allows users to search for and download images from local or remote registries.
• The podman run command creates and starts a container from a container image.
• Containers are executed in the background by using the -d flag, or interactively by using the -
it flag.
• Some container images require environment variables that are set using the -e option with the
podman run command.
• Red Hat Container Catalog assists in searching, exploring, and analyzing container images from
Red Hat's official container image repository.

----------------------------------------------06Oct2022--------------------------------------------

[student@workstation ~]$ lab manage-lifecycle start

Setting up workstation for the Guided Excercise: Managing a MySQL Container

 · Checking podman configuration...............................  SUCCESS
 · Setting up labs folder......................................  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.

[student@workstation ~]$ podman login registry.redhat.io
Authenticating with existing credentials for registry.redhat.io
Existing credentials are valid. Already logged in to registry.redhat.io
[student@workstation ~]$ podman run --name mysql-db registry.redhat.io/rhel8/mysql-80:1
Trying to pull registry.redhat.io/rhel8/mysql-80:1...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 36bead343ed7 done  
Copying blob 1b3417e31a5e done  
Copying blob 1770f4614fe5 done  
Copying blob 809fe483e885 done  
Copying config b5b0298033 done  
Writing manifest to image destination
Storing signatures
=> sourcing 20-validate-variables.sh ...
You must either specify the following environment variables:
  MYSQL_USER (regex: '^[a-zA-Z0-9_]+$')
  MYSQL_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')
  MYSQL_DATABASE (regex: '^[a-zA-Z0-9_]+$')
Or the following environment variable:
  MYSQL_ROOT_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')
Or both.
Optional Settings:
  MYSQL_LOWER_CASE_TABLE_NAMES (default: 0)
  MYSQL_LOG_QUERIES_ENABLED (default: 0)
  MYSQL_MAX_CONNECTIONS (default: 151)
  MYSQL_FT_MIN_WORD_LEN (default: 4)
  MYSQL_FT_MAX_WORD_LEN (default: 20)
  MYSQL_AIO (default: 1)
  MYSQL_KEY_BUFFER_SIZE (default: 32M or 10% of available memory)
  MYSQL_MAX_ALLOWED_PACKET (default: 200M)
  MYSQL_TABLE_OPEN_CACHE (default: 400)
  MYSQL_SORT_BUFFER_SIZE (default: 256K)
  MYSQL_READ_BUFFER_SIZE (default: 8M or 5% of available memory)
  MYSQL_INNODB_BUFFER_POOL_SIZE (default: 32M or 50% of available memory)
  MYSQL_INNODB_LOG_FILE_SIZE (default: 8M or 15% of available memory)
  MYSQL_INNODB_LOG_BUFFER_SIZE (default: 8M or 15% of available memory)

For more information, see https://github.com/sclorg/mysql-container
[student@workstation ~]$ podman ps 
CONTAINER ID  IMAGE       COMMAND     CREATED     STATUS      PORTS       NAMES
[student@workstation ~]$ podman ps -a
CONTAINER ID  IMAGE                                COMMAND     CREATED         STATUS                     PORTS       NAMES
1004d03199c9  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  50 seconds ago  Exited (1) 51 seconds ago              mysql-db
[student@workstation ~]$ podman logs mysql-db
=> sourcing 20-validate-variables.sh ...
You must either specify the following environment variables:
  MYSQL_USER (regex: '^[a-zA-Z0-9_]+$')
  MYSQL_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')
  MYSQL_DATABASE (regex: '^[a-zA-Z0-9_]+$')
Or the following environment variable:
  MYSQL_ROOT_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')
Or both.
Optional Settings:
  MYSQL_LOWER_CASE_TABLE_NAMES (default: 0)
  MYSQL_LOG_QUERIES_ENABLED (default: 0)
  MYSQL_MAX_CONNECTIONS (default: 151)
  MYSQL_FT_MIN_WORD_LEN (default: 4)
  MYSQL_FT_MAX_WORD_LEN (default: 20)
  MYSQL_AIO (default: 1)
  MYSQL_KEY_BUFFER_SIZE (default: 32M or 10% of available memory)
  MYSQL_MAX_ALLOWED_PACKET (default: 200M)
  MYSQL_TABLE_OPEN_CACHE (default: 400)
  MYSQL_SORT_BUFFER_SIZE (default: 256K)
  MYSQL_READ_BUFFER_SIZE (default: 8M or 5% of available memory)
  MYSQL_INNODB_BUFFER_POOL_SIZE (default: 32M or 50% of available memory)
  MYSQL_INNODB_LOG_FILE_SIZE (default: 8M or 15% of available memory)
  MYSQL_INNODB_LOG_BUFFER_SIZE (default: 8M or 15% of available memory)

For more information, see https://github.com/sclorg/mysql-container
[student@workstation ~]$ podman run --name mysql -d -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55  registry.redhat.io/rhel8/mysql-80:1
2945d6aa479b1190c4bcabfa559059defe11794b398e1899acf9527aed01b0a4
[student@workstation ~]$ podman ps -a
CONTAINER ID  IMAGE                                COMMAND     CREATED        STATUS                    PORTS       NAMES
1004d03199c9  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  8 minutes ago  Exited (1) 8 minutes ago              mysql-db
2945d6aa479b  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  6 seconds ago  Up 7 seconds ago                      mysql
[student@workstation ~]$ podman ps 
CONTAINER ID  IMAGE                                COMMAND     CREATED         STATUS             PORTS       NAMES
2945d6aa479b  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  12 seconds ago  Up 12 seconds ago              mysql
[student@workstation ~]$ podman cp ~/DO180/labs/manage-lifecycle/db.sql mysql:/
[student@workstation ~]$ cat DO180/labs/manage-lifecycle/db.sql 
CREATE TABLE `Projects` (id int(11) NOT NULL, `name` varchar(255) DEFAULT NULL, `code` varchar(255) DEFAULT NULL, PRIMARY KEY (id));
insert into `Projects` (`id`, `name`, `code`) values (1,'DevOps','DO180');
[student@workstation ~]$ 
[student@workstation ~]$ podman exec mysql /bin/bash -c 'mysql -uuser1 -pmypa55 items < /db.sql'
mysql: [Warning] Using a password on the command line interface can be insecure.
[student@workstation ~]$ podman run --name mysql-2 -it registry.redhat.io/rhel8/mysql-80:1 /bin/bash
bash-4.4$ mysql -uroot
ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)
bash-4.4$ exit
exit
[student@workstation ~]$ podman ps -a
CONTAINER ID  IMAGE                                COMMAND     CREATED         STATUS                         PORTS       NAMES
1004d03199c9  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  16 minutes ago  Exited (1) 16 minutes ago                  mysql-db
2945d6aa479b  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  7 minutes ago   Up 7 minutes ago                           mysql
913c1f90aa08  registry.redhat.io/rhel8/mysql-80:1  /bin/bash   3 minutes ago   Exited (1) About a minute ago              mysql-2
[student@workstation ~]$ podman exec mysql /bin/bash -c 'mysql -uuser1 -pmypa55 -e "select * from items.Projects;"'
mysql: [Warning] Using a password on the command line interface can be insecure.
id	name	code
1	DevOps	DO180
[student@workstation ~]$ lab manage-lifecycle finish

Completing the Guided Excercise: Managing a MySQL Container

 · Stopping 'mysql' container..................................  SUCCESS
 · Stopping 'mysql-2' container................................  SUCCESS
 · Removing 'mysql' container..................................  SUCCESS
 · Removing 'mysql-2' container................................  SUCCESS
 · Removing 'mysql-db' container...............................  SUCCESS
 · Removing 'registry.redhat.io/rhel8/mysql-80:1' image........  SUCCESS
 · Removing the project directory..............................  SUCCESS
 · Removing the solution directory.............................  SUCCESS
[student@workstation ~]$ 

--------------------------------------Create MySQL Container with Persistent
Database-------------

[student@workstation ~]$ lab manage-storage start

Setting up workstation for the Guided Exercise: Persisting a MySQL Database

 · Checking podman configuration...............................  SUCCESS
 · Check if the directory used by lab is not created...........  SUCCESS
[student@workstation ~]$ mkdir -vp /home/student/local/mysql
mkdir: created directory '/home/student/local/mysql'
[student@workstation ~]$ sudo semanage fcontext -a -t container_file_t '/home/student/local/mysql(/.*)?'
ValueError: File context for /home/student/local/mysql(/.*)? already defined
[student@workstation ~]$ sudo restorecon -R /home/student/local/mysql
[student@workstation ~]$ ls -ldZ /home/student/local/mysql
drwxrwxr-x. 2 student student unconfined_u:object_r:container_file_t:s0 6 Oct  6 12:43 /home/student/local/mysql
[student@workstation ~]$ podman unshare chown 27:27 /home/student/local/mysql
[student@workstation ~]$ podman login registry.redhat.io
Username: veeraabose
Password: 
Login Succeeded!
[student@workstation ~]$ podman pull registry.redhat.io/rhel8/mysql-80:1
Trying to pull registry.redhat.io/rhel8/mysql-80:1...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 36bead343ed7 done  
Copying blob 809fe483e885 done  
Copying blob 1770f4614fe5 done  
Copying blob 1b3417e31a5e done  
Copying config b5b0298033 done  
Writing manifest to image destination
Storing signatures
b5b0298033611d0c00b66d8664f60997908e9b8ec0e131a5a124783879951bf2
[student@workstation ~]$ podman images
REPOSITORY                         TAG         IMAGE ID      CREATED     SIZE
registry.redhat.io/rhel8/mysql-80  1           b5b029803361  2 days ago  624 MB
[student@workstation ~]$ podman run --name persist-db -d -v /home/student/local/mysql:/var/lib/mysql/data -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55 registry.redhat.io/rhel8/mysql-80:1
8d709d45239b043b104a4c137de4bdfaf5470ab7c4755cfc73d7073eb841491f
[student@workstation ~]$ podman ps
CONTAINER ID  IMAGE                                COMMAND     CREATED        STATUS            PORTS       NAMES
8d709d45239b  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  8 seconds ago  Up 8 seconds ago              persist-db
[student@workstation ~]$ podman ps --format="{{.ID}} {{.Names}} {{.Status}}"
8d709d45239b persist-db Up 38 seconds ago
[student@workstation ~]$ ls -ld /home/student/local/mysql/items
drwxr-x---. 2 100026 100026 6 Oct  6 12:49 /home/student/local/mysql/items
[student@workstation ~]$ date
Thu Oct  6 12:50:38 EDT 2022
[student@workstation ~]$ lab manage-storage finish

Completing the Guided Exercise: Persisting a MySQL Database

 · Stopping 'persist-db' container.............................  SUCCESS
 · Removing 'persist-db' container.............................  SUCCESS
 · Removing the 'registry.redhat.io/rhel8/mysql-80:1' image....  SUCCESS
 · Removing the /home/student/local/mysql directory............  SUCCESS
 · Removing the fcontext for /home/student/local/mysql.........  SUCCESS
[student@workstation ~]$ 

----------------------------------------GE--Loading the Database------------------------

[student@workstation ~]$ lab manage-networking start

Setting up workstation for the Guided Exercise: Loading the Database

 · Checking podman configuration...............................  SUCCESS
 · Creating a host directory for the database container:
   · Adding fcontext policy for /home/student/local/mysql......  SUCCESS
   · Creating the /home/student/local/mysql directory..........  SUCCESS
   · Apply fcontext policy to /home/student/local/mysql........  SUCCESS
   · Change owner of the /home/student/local/mysql to the mysql  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.


[student@workstation ~]$ podman login registry.redhat.io
Authenticating with existing credentials for registry.redhat.io
Existing credentials are valid. Already logged in to registry.redhat.io
[student@workstation ~]$ podman run --name mysqldb-port -d -v /home/student/local/mysql:/var/lib/mysql/data -p 13306:3306 -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55 registry.redhat.io/rhel8/mysql-80:1
Trying to pull registry.redhat.io/rhel8/mysql-80:1...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 809fe483e885 done  
Copying blob 36bead343ed7 done  
Copying blob 1770f4614fe5 done  
Copying blob 1b3417e31a5e done  
Copying config b5b0298033 done  
Writing manifest to image destination
Storing signatures
3c57290e0e84e99143d43483353dd46fea2837ba7247172fe179ef795bab4bf1
[student@workstation ~]$ podman ps
CONTAINER ID  IMAGE                                COMMAND     CREATED         STATUS             PORTS                    NAMES
3c57290e0e84  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  29 seconds ago  Up 29 seconds ago  0.0.0.0:13306->3306/tcp  mysqldb-port
[student@workstation ~]$ 0.0.0.0:13306->3306/tcp  mysqldb-port
bash: 3306/tcp: No such file or directory
[student@workstation ~]$ podman ps --format="{{.ID}} {{.Names}} {{.Ports}}"
3c57290e0e84 mysqldb-port 0.0.0.0:13306->3306/tcp
[student@workstation ~]$ mysql -uuser1 -h 127.0.0.1 -pmypa55 -P13306 items < /home/student/DO180/labs/manage-networking/db.sql
mysql: [Warning] Using a password on the command line interface can be insecure.
[student@workstation ~]$ podman exec -it mysqldb-port mysql -uroot items -e "SELECT * FROM Item"
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
+----+-------------------+------+
[student@workstation ~]$ cat /home/student/DO180/labs/manage-networking/db.sql 
CREATE TABLE `Item` (`id` BIGINT not null auto_increment primary key, `description` VARCHAR(100), `done` INT);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (1,'Pick up newspaper', 0);
INSERT INTO `Item` (`id`,`description`,`done`) VALUES (2,'Buy groceries', 1);
[student@workstation ~]$ mysql -uuser1 -h 127.0.0.1 -pmypa55 -P13306 items -e "SELECT * FROM Item"
mysql: [Warning] Using a password on the command line interface can be insecure.
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
+----+-------------------+------+
[student@workstation ~]$ podman exec -it mysqldb-port /bin/bash
bash-4.4$ mysql -uroot items -e "SELECT * FROM Item"
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
+----+-------------------+------+
bash-4.4$ exit
exit
[student@workstation ~]$ lab manage-networking finish

Completing the Guided Exercise: Loading the Database

 · Stopping the 'mysqldb-port' container.......................  SUCCESS
 · Removing the 'mysqldb-port' container.......................  SUCCESS
 · Removing the 'registry.redhat.io/rhel8/mysql-80:1' image....  SUCCESS
 · Removing the /home/student/local/mysql directory............  SUCCESS
 · Removing the fcontext for /home/student/local/mysql.........  SUCCESS

-------------------------------------------LAB: Managing Containers -----------------------------------------
[student@workstation ~]$ lab manage-review start

Setting up workstation for the Lab: Managing Containers

 · Checking podman configuration...............................  SUCCESS
 · Check that /home/student/local/mysql does not exist.........  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.

[student@workstation ~]$ mkdir -vp /home/student/local/mysql
mkdir: created directory '/home/student/local/mysql'
[student@workstation ~]$ sudo semanage fcontext -a -t container_file_t  '/home/student/local/mysql(/.*)?'
[student@workstation ~]$ sudo restorecon -R /home/student/local/mysql
[student@workstation ~]$ podman unshare chown -Rv 27:27 /home/student/local/mysql
changed ownership of '/home/student/local/mysql' from root:root to 27:27
[student@workstation ~]$ podman login registry.redhat.io
Authenticating with existing credentials for registry.redhat.io
Existing credentials are valid. Already logged in to registry.redhat.io
[student@workstation ~]$ podman run --name mysql-1 -p 13306:3306 -d -v /home/student/local/mysql:/var/lib/mysql/data -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55 registry.redhat.io/rhel8/mysql-80:1
Trying to pull registry.redhat.io/rhel8/mysql-80:1...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 1b3417e31a5e done  
Copying blob 36bead343ed7 done  
Copying blob 809fe483e885 done  
Copying blob 1770f4614fe5 done  
Copying config b5b0298033 done  
Writing manifest to image destination
Storing signatures
de4c7277c799b456434e155757da10f5d42ccb9e5bff629791edc9da842496a1
[student@workstation ~]$ podman ps --format="{{.ID}} {{.Names}}"
de4c7277c799 mysql-1
[student@workstation ~]$ mysql -uuser1 -h 127.0.0.1 -pmypa55 -P13306 items < /home/student/DO180/labs/manage-review/db.sql
mysql: [Warning] Using a password on the command line interface can be insecure.
[student@workstation ~]$ podman ps
CONTAINER ID  IMAGE                                COMMAND     CREATED        STATUS            PORTS                    NAMES
de4c7277c799  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  2 minutes ago  Up 2 minutes ago  0.0.0.0:13306->3306/tcp  mysql-1
[student@workstation ~]$ mysql -uuser1 -h 127.0.0.1 -pmypa55 -P13306 items -e "SELECT * FROM Item"
mysql: [Warning] Using a password on the command line interface can be insecure.
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
+----+-------------------+------+
[student@workstation ~]$ podman stop mysql-1
mysql-1
[student@workstation ~]$ podman ps -a
CONTAINER ID  IMAGE                                COMMAND     CREATED        STATUS                    PORTS                    NAMES
de4c7277c799  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  3 minutes ago  Exited (0) 6 seconds ago  0.0.0.0:13306->3306/tcp  mysql-1
[student@workstation ~]$ podman run --name mysql-2 -p 13306:3306 -d -v /home/student/local/mysql:/var/lib/mysql/data -e MYSQL_USER=user1 -e MYSQL_PASSWORD=mypa55 -e MYSQL_DATABASE=items -e MYSQL_ROOT_PASSWORD=r00tpa55 registry.redhat.io/rhel8/mysql-80:1
481659683cd858b8d285dacec55cc132ea6e056d736a997669596862c930a142
[student@workstation ~]$ podman ps --format="{{.ID}} {{.Names}}"
481659683cd8 mysql-2
[student@workstation ~]$ podman ps -a > /tmp/my-containers
[student@workstation ~]$ cat /tmp/my-containers 
CONTAINER ID  IMAGE                                COMMAND     CREATED         STATUS                    PORTS                    NAMES
de4c7277c799  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  6 minutes ago   Exited (0) 2 minutes ago  0.0.0.0:13306->3306/tcp  mysql-1
481659683cd8  registry.redhat.io/rhel8/mysql-80:1  run-mysqld  40 seconds ago  Up 40 seconds ago         0.0.0.0:13306->3306/tcp  mysql-2
[student@workstation ~]$ podman exec -it mysql-2 /bin/bash
bash-4.4$ mysql -uroot
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 8.0.26 Source distribution

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> SHOW DATABASES;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| items              |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
5 rows in set (0.00 sec)

mysql> USE items;
Database changed
mysql> SHOW TABLES;
+-----------------+
| Tables_in_items |
+-----------------+
| Item            |
+-----------------+
1 row in set (0.00 sec)

mysql> SELECT * FROM Item;
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
+----+-------------------+------+
2 rows in set (0.00 sec)

mysql> exit
Bye
bash-4.4$ exit
exit
[student@workstation ~]$ mysql -uuser1 -h workstation.lab.example.com -pmypa55 -P13306 items
mysql: [Warning] Using a password on the command line interface can be insecure.
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 9
Server version: 8.0.26 Source distribution

Copyright (c) 2000, 2021, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> INSERT INTO Item (description, done) VALUES ('Finished lab', 1);
Query OK, 1 row affected (0.02 sec)

mysql> SELECT * from Item;
+----+-------------------+------+
| id | description       | done |
+----+-------------------+------+
|  1 | Pick up newspaper |    0 |
|  2 | Buy groceries     |    1 |
|  3 | Finished lab      |    1 |
+----+-------------------+------+
3 rows in set (0.01 sec)

mysql> exit
Bye
[student@workstation ~]$ podman rm mysql-1
de4c7277c799b456434e155757da10f5d42ccb9e5bff629791edc9da842496a1
[student@workstation ~]$ lab manage-review grade

Grading the student's work for the Lab: Managing Containers

 · Checking if the /home/student/local/mysql folder exists.....  PASS
 · Checking if owner was changed...............................  PASS
 · Checking if the container mysql-1 was created...............  PASS
 · Checking if the mysql-2 container is running................  PASS
 · Checking tables for the 'Finished lab' row..................  PASS
[student@workstation ~]$ lab manage-review finish

Completing the Lab: Managing Containers

 · Removing the /home/student/local/mysql folder...............  SUCCESS
 · Removing the fcontext for /home/student/local/mysql.........  SUCCESS
 · Stopping mysql-1 container..................................  SUCCESS
 · Removing mysql-1 container..................................  SUCCESS
 · Stopping mysql-2 container..................................  SUCCESS
 · Removing mysql-2 container..................................  SUCCESS
 · Removing MySQL container image..............................  SUCCESS
 · Removing temporary file.....................................  SUCCESS
 · Removing the project directory..............................  SUCCESS
 · Removing the solution directory.............................  SUCCESS
[student@workstation ~]$ 

Summary
-----------
In this chapter, you learned:
• Podman has subcommands to: create a new container (run), delete a container (rm), list
containers (ps), stop a container (stop), and start a process in a container (exec).
• Default container storage is ephemeral, meaning its contents are not present after the container
is removed.
• Containers can use a folder from the host file system to work with persistent data.
• Podman mounts volumes in a container with the -v option in the podman run command.
• The podman exec command starts an additional process inside a running container.
• Podman maps local ports to container ports by using the -p option in the run subcommand.

-----------------------Chapter 4 -----------------------------------------------

[student@workstation ~]$ lab image-operations start

Setting up workstation for the GE: Creating a Custom Apache Container Image

 · Checking podman configuration...............................  SUCCESS
[student@workstation ~]$ podman login quay.io
Username: veeraabose
Password: 
Login Succeeded!
[student@workstation ~]$ podman run -d --name official-httpd -p 8180:80 quay.io/redhattraining/httpd-parent
Trying to pull quay.io/redhattraining/httpd-parent:latest...
Getting image source signatures
Copying blob a3ed95caeb02 done  
Copying blob a3ed95caeb02 done  
Copying blob a3ed95caeb02 done  
Copying blob 787f47dbeaac done  
Copying blob 6a5240d60dc4 done  
Copying blob 08b8c9fdec44 done  
Copying blob a3ed95caeb02 skipped: already exists  
Copying blob a3ed95caeb02 skipped: already exists  
Copying blob a3ed95caeb02 skipped: already exists  
Copying blob 408208567b9a done  
Writing manifest to image destination
Storing signatures
43effcd465811d1388d84ced5f0be49f6d771e13ba624564b16e065865252fb1
[student@workstation ~]$ podman exec -it official-httpd /bin/bash
bash-4.4# cat /var/www/html/index.html 
Hello from the httpd-parent container!
bash-4.4# echo "DO180 Page" > /var/www/html/do180.html
bash-4.4# exit
exit
[student@workstation ~]$ curl 127.0.0.1:8180/do180.html
DO180 Page
[student@workstation ~]$ podman diff official-httpd
C /root
A /root/.bash_history
C /run/httpd
A /run/httpd/cgisock.1
A /run/httpd/httpd.pid
C /tmp
C /var
C /var/log
C /var/log/httpd
A /var/log/httpd/access_log
A /var/log/httpd/error_log
C /var/www
C /var/www/html
A /var/www/html/do180.html
[student@workstation ~]$ podman stop official-httpd
official-httpd
[student@workstation ~]$ podman commit -a 'veera' official-httpd do180-custom-httpd
Getting image source signatures
Copying blob 24d85c895b6b skipped: already exists  
Copying blob c613b100be16 skipped: already exists  
Copying blob 574bcc187eda skipped: already exists  
Copying blob 7f9108fde4a1 skipped: already exists  
Copying blob bad01b4b4478 done  
Copying config 779652b5b0 done  
Writing manifest to image destination
Storing signatures
779652b5b0978db3e5b76df85b864d72cfc3c524cbecbc43de7d3af4f74ffb6d
[student@workstation ~]$ podman images
REPOSITORY                           TAG         IMAGE ID      CREATED         SIZE
localhost/do180-custom-httpd         latest      779652b5b097  43 seconds ago  236 MB
quay.io/redhattraining/httpd-parent  latest      4346d3cace25  3 years ago     236 MB
[student@workstation ~]$ podman ps -a
CONTAINER ID  IMAGE                                       COMMAND               CREATED        STATUS                    PORTS                 NAMES
43effcd46581  quay.io/redhattraining/httpd-parent:latest  /bin/sh -c /usr/s...  6 minutes ago  Exited (0) 2 minutes ago  0.0.0.0:8180->80/tcp  official-httpd
[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ cat !$
cat /usr/local/etc/ocp4.config
RHT_OCP4_MASTER_API=https://api.ocp4.example.com:6443
RHT_OCP4_WILDCARD_DOMAIN=apps.ocp4.example.com
RHT_OCP4_NEXUS_SERVER=nexus-common.apps.ocp4.example.com
RHT_OCP4_DEV_USER=developer
RHT_OCP4_DEV_PASSWORD=developer
RHT_OCP4_GITHUB_USER=veerabose
RHT_OCP4_QUAY_USER=veeraabose
RHT_OCP4_USER_PASSWD=redhat
[student@workstation ~]$ podman push quay.io/${RHT_OCP4_QUAY_USER}/do180-custom-httpd:v1.0
Error: quay.io/veeraabose/do180-custom-httpd:v1.0: image not known
[student@workstation ~]$ podman tag do180-custom-httpd quay.io/${RHT_OCP4_QUAY_USER}/do180-custom-httpd:v1.0
[student@workstation ~]$ podman images
REPOSITORY                             TAG         IMAGE ID      CREATED        SIZE
localhost/do180-custom-httpd           latest      779652b5b097  5 minutes ago  236 MB
quay.io/veeraabose/do180-custom-httpd  v1.0        779652b5b097  5 minutes ago  236 MB
quay.io/redhattraining/httpd-parent    latest      4346d3cace25  3 years ago    236 MB
[student@workstation ~]$ podman push quay.io/${RHT_OCP4_QUAY_USER}/do180-custom-httpd:v1.0
Getting image source signatures
Copying blob bad01b4b4478 done  
Copying blob 24d85c895b6b skipped: already exists  
Copying blob c613b100be16 skipped: already exists  
Copying blob 574bcc187eda skipped: already exists  
Copying blob 7f9108fde4a1 skipped: already exists  
Copying config 779652b5b0 done  
Writing manifest to image destination
Storing signatures
[student@workstation ~]$ podman pull -q quay.io/${RHT_OCP4_QUAY_USER}/do180-custom-httpd:v1.0
779652b5b0978db3e5b76df85b864d72cfc3c524cbecbc43de7d3af4f74ffb6d
[student@workstation ~]$ podman images
REPOSITORY                             TAG         IMAGE ID      CREATED        SIZE
quay.io/veeraabose/do180-custom-httpd  v1.0        779652b5b097  9 minutes ago  236 MB
localhost/do180-custom-httpd           latest      779652b5b097  9 minutes ago  236 MB
quay.io/redhattraining/httpd-parent    latest      4346d3cace25  3 years ago    236 MB
[student@workstation ~]$ podman run -d --name test-httpd -p 8280:80  ${RHT_OCP4_QUAY_USER}/do180-custom-httpd:v1.0
ef3916ac3ff7889fa60b1ceb5f9e290e959006f2ade53372017e79443813da31
[student@workstation ~]$ curl http://localhost:8280/do180.html
DO180 Page
[student@workstation ~]$ lab image-operations finish

Completing the GE: Creating a Custom Apache Container Image

 · Stopping official-httpd container...........................  SUCCESS
 · Removing official-httpd container...........................  SUCCESS
 · Stopping test-httpd container...............................  SUCCESS
 · Removing test-httpd container...............................  SUCCESS
 · Removing redhattraining/httpd-parent image..................  SUCCESS
 · Removing quay.io/veeraabose/do180-custom-httpd image........  SUCCESS
 · Removing localhost/do180-custom-httpd image.................  SUCCESS
[student@workstation ~]$ 


-----------------Ch4 - Lab ----------------------------------------------------------
[student@workstation ~]$ lab image-review start

Setting up workstation for the Lab: Managing Images

 · Checking podman configuration...............................  SUCCESS
[student@workstation ~]$ podman pull quay.io/redhattraining/nginx:1.17
Trying to pull quay.io/redhattraining/nginx:1.17...
Getting image source signatures
Copying blob b00ee4473ca6 skipped: already exists  
Copying blob d1a81ca518e2 skipped: already exists  
Copying blob c78335199707 skipped: already exists  
Copying config 9beeba249f done  
Writing manifest to image destination
Storing signatures
9beeba249f3ee158d3e495a6ac25c5667ae2de8a43ac2a8bfd2bf687a58c06c9
[student@workstation ~]$ podman images
REPOSITORY                    TAG         IMAGE ID      CREATED      SIZE
quay.io/redhattraining/nginx  1.17        9beeba249f3e  2 years ago  131 MB
[student@workstation ~]$ podman run --name official-nginx -d -p 8080:80 quay.io/redhattraining/nginx:1.17
Error: error creating container storage: the container name "official-nginx" is already in use by "38bb58ad3f8734d4fcaac03d5620d7ae567db6fc1f76de378f94f8ce68498dd1". You have to remove that container to be able to reuse that name.: that name is already in use
[student@workstation ~]$ podman rm -f official-nginx 
38bb58ad3f8734d4fcaac03d5620d7ae567db6fc1f76de378f94f8ce68498dd1
[student@workstation ~]$ podman run --name official-nginx -d -p 8080:80 quay.io/redhattraining/nginx:1.17
24acad6eb003f0885651d33b353021d3453e2a6debb034b92f08e29a55264718
[student@workstation ~]$ podman exec -it official-nginx /bin/bash
root@24acad6eb003:/# cat /usr/share/nginx/html/index.html 
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
root@24acad6eb003:/# echo 'DO180' > /usr/share/nginx/html/index.html
root@24acad6eb003:/# cat /usr/share/nginx/html/index.html 
DO180
root@24acad6eb003:/# exit
exit
[student@workstation ~]$ curl 127.0.0.1:8080
DO180
[student@workstation ~]$ podman stop official-nginx
official-nginx
[student@workstation ~]$ podman commit -a 'veera' official-nginx do180/mynginx:v1.0-SNAPSHOT
Getting image source signatures
Copying blob ffc9b21953f4 skipped: already exists  
Copying blob 2f4accd375d9 skipped: already exists  
Copying blob 6c7de695ede3 skipped: already exists  
Copying blob fefe293d37ac done  
Copying config b6710f5af7 done  
Writing manifest to image destination
Storing signatures
b6710f5af796b1d886012872824d28b3e07891dae7c72113d7592a26bb0866b1
[student@workstation ~]$ podman images
REPOSITORY                    TAG            IMAGE ID      CREATED         SIZE
localhost/do180/mynginx       v1.0-SNAPSHOT  b6710f5af796  28 seconds ago  131 MB
quay.io/redhattraining/nginx  1.17           9beeba249f3e  2 years ago     131 MB
[student@workstation ~]$ podman run --name official-nginx-dev -d -p 8080:80 do180/mynginx:v1.0-SNAPSHOT
b1b288b3eeec628bc5ea8155e059380c08b6e6dcfac0e2dc063fde9748e73526
[student@workstation ~]$ podman ps
CONTAINER ID  IMAGE                                  COMMAND               CREATED        STATUS            PORTS                 NAMES
b1b288b3eeec  localhost/do180/mynginx:v1.0-SNAPSHOT  nginx -g daemon o...  7 seconds ago  Up 8 seconds ago  0.0.0.0:8080->80/tcp  official-nginx-dev
[student@workstation ~]$ podman exec -it official-nginx-dev /bin/bash
root@b1b288b3eeec:/# cat /usr/share/nginx/html/index.html 
DO180
root@b1b288b3eeec:/# echo 'DO180 Page' > /usr/share/nginx/html/index.html
root@b1b288b3eeec:/# exit
exit
[student@workstation ~]$ podman stop official-nginx-dev
official-nginx-dev
[student@workstation ~]$ podman commit -a 'veera' official-nginx-dev do180/mynginx:v1.0
Getting image source signatures
Copying blob ffc9b21953f4 skipped: already exists  
Copying blob 2f4accd375d9 skipped: already exists  
Copying blob 6c7de695ede3 skipped: already exists  
Copying blob fefe293d37ac skipped: already exists  
Copying blob aaf4fa91f1ff done  
Copying config 9f4c6deb97 done  
Writing manifest to image destination
Storing signatures
9f4c6deb9792a13f121da1a44a259612d635090fd3835070fdee8a0a1e4588a5
[student@workstation ~]$ podman images
REPOSITORY                    TAG            IMAGE ID      CREATED         SIZE
localhost/do180/mynginx       v1.0           9f4c6deb9792  26 seconds ago  131 MB
localhost/do180/mynginx       v1.0-SNAPSHOT  b6710f5af796  7 minutes ago   131 MB
quay.io/redhattraining/nginx  1.17           9beeba249f3e  2 years ago     131 MB
[student@workstation ~]$ podman ps -a --format="{{.ID}} {{.Names}} {{.Status}}"
24acad6eb003 official-nginx Exited (0) 9 minutes ago
b1b288b3eeec official-nginx-dev Exited (0) About a minute ago
[student@workstation ~]$ podman rm official-nginx-dev
b1b288b3eeec628bc5ea8155e059380c08b6e6dcfac0e2dc063fde9748e73526
[student@workstation ~]$ podman ps -a --format="{{.ID}} {{.Names}} {{.Status}}"
24acad6eb003 official-nginx Exited (0) 9 minutes ago
[student@workstation ~]$ podman rmi do180/mynginx:v1.0-SNAPSHOT
Untagged: localhost/do180/mynginx:v1.0-SNAPSHOT
[student@workstation ~]$ podman images
REPOSITORY                    TAG         IMAGE ID      CREATED        SIZE
localhost/do180/mynginx       v1.0        9f4c6deb9792  2 minutes ago  131 MB
quay.io/redhattraining/nginx  1.17        9beeba249f3e  2 years ago    131 MB
[student@workstation ~]$ podman run -d --name my-nginx -p 8280:80 do180/mynginx:v1.0
66246ea705e0b8cb1f42199ea302f0b8f081c9446b18a4a51195d7c4a2fed8fa
[student@workstation ~]$ curl 127.0.0.1:8280
DO180 Page
[student@workstation ~]$ lab image-review grade

Grading the student's work for the Lab: Managing Images

 · Nginx container image is pulled.............................  PASS
 · Container official-nginx is created.........................  PASS
 · Container official-nginx is stopped.........................  PASS
 · Tag do180/mynginx:v1.0-SNAPSHOT is removed..................  PASS
 · Tag do180/mynginx:v1.0 is created...........................  PASS
 · Container my-nginx is created and running...................  PASS
 · index.html is available with the custom content.............  PASS
[student@workstation ~]$ lab image-review finish

Completing the Lab: Managing Images

 · Stopping official-nginx-dev container.......................  SUCCESS
 · Removing official-nginx-dev container.......................  SUCCESS
 · Stopping official-nginx container...........................  SUCCESS
 · Removing official-nginx container...........................  SUCCESS
 · Removing do180/mynginx:v1.0 image...........................  SUCCESS
 · Removing quay.io/redhattraining/nginx:1.17 image............  SUCCESS
[student@workstation ~]$ 

Summary
In this chapter, you learned:
.• The Red Hat Container Catalog provides tested and certified images at registry.redhat.io.
• Podman can interact with remote container registries to search, pull, and push container images.
• Image tags are a mechanism to support multiple releases of a container image.
• Podman provides commands to manage container images both in local storage and as
compressed files.
• Use the podman commit command to create an image from a container.

-----------------CH5--Guided Exercise--------.Creating a Basic Apache Container Image-------------
[student@workstation ~]$ lab dockerfile-create start

Setting up workstation for the Guided Exercise: Building a basic Apache Container Image

 · Checking podman configuration...............................  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.

[student@workstation ~]$ vim ~/DO180/labs/dockerfile-create/Containerfile
[student@workstation ~]$ cat !$
cat ~/DO180/labs/dockerfile-create/Containerfile
FROM ubi8/ubi:8.5
MAINTAINER Your Name veera
LABEL description="A custom Apache container based on UBI 8"
RUN yum install -y httpd && yum clean all
RUN echo "Hello from Containerfile" > /var/www/html/index.html
EXPOSE 80
CMD ["httpd", "-D", "FOREGROUND"]
[student@workstation ~]$ cd ~/DO180/labs/dockerfile-create
[student@workstation dockerfile-create]$ ls
Containerfile
[student@workstation dockerfile-create]$ podman build --layers=false -t do180/apache .
STEP 1/7: FROM ubi8/ubi:8.5
Resolved "ubi8/ubi" as an alias (/etc/containers/registries.conf.d/001-rhel-shortnames.conf)
Trying to pull registry.access.redhat.com/ubi8/ubi:8.5...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 19b323993c37 done  
Copying blob b3c5b1f89131 done  
Copying config 202c1768b1 done  
Writing manifest to image destination
Storing signatures
STEP 2/7: MAINTAINER Your Name veera
STEP 3/7: LABEL description="A custom Apache container based on UBI 8"
STEP 4/7: RUN yum install -y httpd && yum clean all
Updating Subscription Management repositories.
Unable to read consumer identity
Subscription Manager is operating in container mode.

This system is not registered with an entitlement server. You can use subscription-manager to register.

Red Hat Universal Base Image 8 (RPMs) - BaseOS  446 kB/s | 803 kB     00:01    
Red Hat Universal Base Image 8 (RPMs) - AppStre 2.6 MB/s | 3.0 MB     00:01    
Red Hat Universal Base Image 8 (RPMs) - CodeRea  17 kB/s |  20 kB     00:01    
Last metadata expiration check: 0:00:01 ago on Sun Oct  9 17:40:09 2022.
Dependencies resolved.
==============================================================================================
 Package              Arch    Version                                   Repository        Size
==============================================================================================
Installing:
 httpd                x86_64  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream  1.4 M
Installing dependencies:
 apr                  x86_64  1.6.3-12.el8                              ubi-8-appstream  130 k
 apr-util             x86_64  1.6.1-6.el8                               ubi-8-appstream  105 k
 httpd-filesystem     noarch  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream   41 k
 httpd-tools          x86_64  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream  108 k
 mailcap              noarch  2.1.48-3.el8                              ubi-8-baseos      39 k
 mod_http2            x86_64  1.15.7-5.module+el8.6.0+13996+01710940    ubi-8-appstream  155 k
 redhat-logos-httpd   noarch  84.5-1.el8                                ubi-8-baseos      29 k
Installing weak dependencies:
 apr-util-bdb         x86_64  1.6.1-6.el8                               ubi-8-appstream   25 k
 apr-util-openssl     x86_64  1.6.1-6.el8                               ubi-8-appstream   27 k
Enabling module streams:
 httpd                        2.4                                                             

Transaction Summary
==============================================================================================
Install  10 Packages

Total download size: 2.1 M
Installed size: 5.5 M
Downloading Packages:
(1/10): mailcap-2.1.48-3.el8.noarch.rpm         1.0 MB/s |  39 kB     00:00    
(2/10): redhat-logos-httpd-84.5-1.el8.noarch.rp 660 kB/s |  29 kB     00:00    
(3/10): apr-util-1.6.1-6.el8.x86_64.rpm          11 MB/s | 105 kB     00:00    
(4/10): apr-1.6.3-12.el8.x86_64.rpm             2.7 MB/s | 130 kB     00:00    
(5/10): apr-util-openssl-1.6.1-6.el8.x86_64.rpm 7.8 MB/s |  27 kB     00:00    
(6/10): mod_http2-1.15.7-5.module+el8.6.0+13996  32 MB/s | 155 kB     00:00    
(7/10): apr-util-bdb-1.6.1-6.el8.x86_64.rpm     5.2 MB/s |  25 kB     00:00    
(8/10): httpd-tools-2.4.37-47.module+el8.6.0+15  20 MB/s | 108 kB     00:00    
(9/10): httpd-filesystem-2.4.37-47.module+el8.6 8.2 MB/s |  41 kB     00:00    
(10/10): httpd-2.4.37-47.module+el8.6.0+15654+4  92 MB/s | 1.4 MB     00:00    
--------------------------------------------------------------------------------
Total                                            29 MB/s | 2.1 MB     00:00     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1 
  Installing       : apr-1.6.3-12.el8.x86_64                               1/10 
  Running scriptlet: apr-1.6.3-12.el8.x86_64                               1/10 
  Installing       : apr-util-openssl-1.6.1-6.el8.x86_64                   2/10 
  Installing       : apr-util-bdb-1.6.1-6.el8.x86_64                       3/10 
  Installing       : apr-util-1.6.1-6.el8.x86_64                           4/10 
  Running scriptlet: apr-util-1.6.1-6.el8.x86_64                           4/10 
  Installing       : httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2    5/10 
  Running scriptlet: httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42    6/10 
  Installing       : httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42    6/10 
  Installing       : mailcap-2.1.48-3.el8.noarch                           7/10 
  Installing       : redhat-logos-httpd-84.5-1.el8.noarch                  8/10 
  Installing       : mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x    9/10 
  Installing       : httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8   10/10 
  Running scriptlet: httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8   10/10 
  Verifying        : redhat-logos-httpd-84.5-1.el8.noarch                  1/10 
  Verifying        : mailcap-2.1.48-3.el8.noarch                           2/10 
  Verifying        : apr-1.6.3-12.el8.x86_64                               3/10 
  Verifying        : apr-util-1.6.1-6.el8.x86_64                           4/10 
  Verifying        : apr-util-openssl-1.6.1-6.el8.x86_64                   5/10 
  Verifying        : mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x    6/10 
  Verifying        : apr-util-bdb-1.6.1-6.el8.x86_64                       7/10 
  Verifying        : httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2    8/10 
  Verifying        : httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8    9/10 
  Verifying        : httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42   10/10 
Installed products updated.

Installed:
  apr-1.6.3-12.el8.x86_64                                                       
  apr-util-1.6.1-6.el8.x86_64                                                   
  apr-util-bdb-1.6.1-6.el8.x86_64                                               
  apr-util-openssl-1.6.1-6.el8.x86_64                                           
  httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x86_64                        
  httpd-filesystem-2.4.37-47.module+el8.6.0+15654+427eba2e.2.noarch             
  httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x86_64                  
  mailcap-2.1.48-3.el8.noarch                                                   
  mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x86_64                       
  redhat-logos-httpd-84.5-1.el8.noarch                                          

Complete!
Updating Subscription Management repositories.
Unable to read consumer identity
Subscription Manager is operating in container mode.

This system is not registered with an entitlement server. You can use subscription-manager to register.

25 files removed
STEP 5/7: RUN echo "Hello from Containerfile" > /var/www/html/index.html
STEP 6/7: EXPOSE 80
STEP 7/7: CMD ["httpd", "-D", "FOREGROUND"]
COMMIT do180/apache
Getting image source signatures
Copying blob 3813924f3fa4 skipped: already exists  
Copying blob c86122b5e4d3 skipped: already exists  
Copying blob 230228eebc2e done  
Copying config 7f9154b1b6 done  
Writing manifest to image destination
Storing signatures
--> 7f9154b1b60
Successfully tagged localhost/do180/apache:latest
7f9154b1b6054ce505811b99d68ec36ce6905802a48b04bd2bb44ffcf191d3ab
[student@workstation dockerfile-create]$ podman images
REPOSITORY                           TAG         IMAGE ID      CREATED        SIZE
localhost/do180/apache               latest      7f9154b1b605  6 minutes ago  257 MB
registry.access.redhat.com/ubi8/ubi  8.5         202c1768b1f7  5 months ago   235 MB
[student@workstation dockerfile-create]$ podman run --name lab-apache -d -p 10080:80 do180/apache
f95d2cf65dd46cdb23c3f7b07a237dd8e3d9a071cc7f000cb32522ea5dd69b04
[student@workstation dockerfile-create]$ podman ps
CONTAINER ID  IMAGE                          COMMAND               CREATED         STATUS             PORTS                  NAMES
f95d2cf65dd4  localhost/do180/apache:latest  httpd -D FOREGROU...  17 seconds ago  Up 17 seconds ago  0.0.0.0:10080->80/tcp  lab-apache
[student@workstation dockerfile-create]$ curl -s 127.0.0.1:10080
Hello from Containerfile
[student@workstation dockerfile-create]$ lab dockerfile-create finish

Completing the Guided Exercise: Building a basic Apache Container Image

 · Stopping lab-apache container that is running...............  SUCCESS
 · Removing lab-apache container that is in the cache..........  SUCCESS
 · Removing do180/apache custom container image................  SUCCESS
 · Removing UBI8 container image...............................  SUCCESS
[student@workstation dockerfile-create]$ 

-----------------------------------------------------Lab- Creating Custom Container Images----------
[student@workstation ~]$ lab dockerfile-create start

Setting up workstation for the Guided Exercise: Building a basic Apache Container Image

 · Checking podman configuration...............................  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.

[student@workstation ~]$ vim ~/DO180/labs/dockerfile-create/Containerfile
[student@workstation ~]$ cat !$
cat ~/DO180/labs/dockerfile-create/Containerfile
FROM ubi8/ubi:8.5
MAINTAINER Your Name veera
LABEL description="A custom Apache container based on UBI 8"
RUN yum install -y httpd && yum clean all
RUN echo "Hello from Containerfile" > /var/www/html/index.html
EXPOSE 80
CMD ["httpd", "-D", "FOREGROUND"]
[student@workstation ~]$ cd ~/DO180/labs/dockerfile-create
[student@workstation dockerfile-create]$ ls
Containerfile
[student@workstation dockerfile-create]$ podman build --layers=false -t do180/apache .
STEP 1/7: FROM ubi8/ubi:8.5
Resolved "ubi8/ubi" as an alias (/etc/containers/registries.conf.d/001-rhel-shortnames.conf)
Trying to pull registry.access.redhat.com/ubi8/ubi:8.5...
Getting image source signatures
Checking if image destination supports signatures
Copying blob 19b323993c37 done  
Copying blob b3c5b1f89131 done  
Copying config 202c1768b1 done  
Writing manifest to image destination
Storing signatures
STEP 2/7: MAINTAINER Your Name veera
STEP 3/7: LABEL description="A custom Apache container based on UBI 8"
STEP 4/7: RUN yum install -y httpd && yum clean all
Updating Subscription Management repositories.
Unable to read consumer identity
Subscription Manager is operating in container mode.

This system is not registered with an entitlement server. You can use subscription-manager to register.

Red Hat Universal Base Image 8 (RPMs) - BaseOS  446 kB/s | 803 kB     00:01    
Red Hat Universal Base Image 8 (RPMs) - AppStre 2.6 MB/s | 3.0 MB     00:01    
Red Hat Universal Base Image 8 (RPMs) - CodeRea  17 kB/s |  20 kB     00:01    
Last metadata expiration check: 0:00:01 ago on Sun Oct  9 17:40:09 2022.
Dependencies resolved.
==============================================================================================
 Package              Arch    Version                                   Repository        Size
==============================================================================================
Installing:
 httpd                x86_64  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream  1.4 M
Installing dependencies:
 apr                  x86_64  1.6.3-12.el8                              ubi-8-appstream  130 k
 apr-util             x86_64  1.6.1-6.el8                               ubi-8-appstream  105 k
 httpd-filesystem     noarch  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream   41 k
 httpd-tools          x86_64  2.4.37-47.module+el8.6.0+15654+427eba2e.2 ubi-8-appstream  108 k
 mailcap              noarch  2.1.48-3.el8                              ubi-8-baseos      39 k
 mod_http2            x86_64  1.15.7-5.module+el8.6.0+13996+01710940    ubi-8-appstream  155 k
 redhat-logos-httpd   noarch  84.5-1.el8                                ubi-8-baseos      29 k
Installing weak dependencies:
 apr-util-bdb         x86_64  1.6.1-6.el8                               ubi-8-appstream   25 k
 apr-util-openssl     x86_64  1.6.1-6.el8                               ubi-8-appstream   27 k
Enabling module streams:
 httpd                        2.4                                                             

Transaction Summary
==============================================================================================
Install  10 Packages

Total download size: 2.1 M
Installed size: 5.5 M
Downloading Packages:
(1/10): mailcap-2.1.48-3.el8.noarch.rpm         1.0 MB/s |  39 kB     00:00    
(2/10): redhat-logos-httpd-84.5-1.el8.noarch.rp 660 kB/s |  29 kB     00:00    
(3/10): apr-util-1.6.1-6.el8.x86_64.rpm          11 MB/s | 105 kB     00:00    
(4/10): apr-1.6.3-12.el8.x86_64.rpm             2.7 MB/s | 130 kB     00:00    
(5/10): apr-util-openssl-1.6.1-6.el8.x86_64.rpm 7.8 MB/s |  27 kB     00:00    
(6/10): mod_http2-1.15.7-5.module+el8.6.0+13996  32 MB/s | 155 kB     00:00    
(7/10): apr-util-bdb-1.6.1-6.el8.x86_64.rpm     5.2 MB/s |  25 kB     00:00    
(8/10): httpd-tools-2.4.37-47.module+el8.6.0+15  20 MB/s | 108 kB     00:00    
(9/10): httpd-filesystem-2.4.37-47.module+el8.6 8.2 MB/s |  41 kB     00:00    
(10/10): httpd-2.4.37-47.module+el8.6.0+15654+4  92 MB/s | 1.4 MB     00:00    
--------------------------------------------------------------------------------
Total                                            29 MB/s | 2.1 MB     00:00     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                        1/1 
  Installing       : apr-1.6.3-12.el8.x86_64                               1/10 
  Running scriptlet: apr-1.6.3-12.el8.x86_64                               1/10 
  Installing       : apr-util-openssl-1.6.1-6.el8.x86_64                   2/10 
  Installing       : apr-util-bdb-1.6.1-6.el8.x86_64                       3/10 
  Installing       : apr-util-1.6.1-6.el8.x86_64                           4/10 
  Running scriptlet: apr-util-1.6.1-6.el8.x86_64                           4/10 
  Installing       : httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2    5/10 
  Running scriptlet: httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42    6/10 
  Installing       : httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42    6/10 
  Installing       : mailcap-2.1.48-3.el8.noarch                           7/10 
  Installing       : redhat-logos-httpd-84.5-1.el8.noarch                  8/10 
  Installing       : mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x    9/10 
  Installing       : httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8   10/10 
  Running scriptlet: httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8   10/10 
  Verifying        : redhat-logos-httpd-84.5-1.el8.noarch                  1/10 
  Verifying        : mailcap-2.1.48-3.el8.noarch                           2/10 
  Verifying        : apr-1.6.3-12.el8.x86_64                               3/10 
  Verifying        : apr-util-1.6.1-6.el8.x86_64                           4/10 
  Verifying        : apr-util-openssl-1.6.1-6.el8.x86_64                   5/10 
  Verifying        : mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x    6/10 
  Verifying        : apr-util-bdb-1.6.1-6.el8.x86_64                       7/10 
  Verifying        : httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2    8/10 
  Verifying        : httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x8    9/10 
  Verifying        : httpd-filesystem-2.4.37-47.module+el8.6.0+15654+42   10/10 
Installed products updated.

Installed:
  apr-1.6.3-12.el8.x86_64                                                       
  apr-util-1.6.1-6.el8.x86_64                                                   
  apr-util-bdb-1.6.1-6.el8.x86_64                                               
  apr-util-openssl-1.6.1-6.el8.x86_64                                           
  httpd-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x86_64                        
  httpd-filesystem-2.4.37-47.module+el8.6.0+15654+427eba2e.2.noarch             
  httpd-tools-2.4.37-47.module+el8.6.0+15654+427eba2e.2.x86_64                  
  mailcap-2.1.48-3.el8.noarch                                                   
  mod_http2-1.15.7-5.module+el8.6.0+13996+01710940.x86_64                       
  redhat-logos-httpd-84.5-1.el8.noarch                                          

Complete!
Updating Subscription Management repositories.
Unable to read consumer identity
Subscription Manager is operating in container mode.

This system is not registered with an entitlement server. You can use subscription-manager to register.

25 files removed
STEP 5/7: RUN echo "Hello from Containerfile" > /var/www/html/index.html
STEP 6/7: EXPOSE 80
STEP 7/7: CMD ["httpd", "-D", "FOREGROUND"]
COMMIT do180/apache
Getting image source signatures
Copying blob 3813924f3fa4 skipped: already exists  
Copying blob c86122b5e4d3 skipped: already exists  
Copying blob 230228eebc2e done  
Copying config 7f9154b1b6 done  
Writing manifest to image destination
Storing signatures
--> 7f9154b1b60
Successfully tagged localhost/do180/apache:latest
7f9154b1b6054ce505811b99d68ec36ce6905802a48b04bd2bb44ffcf191d3ab
[student@workstation dockerfile-create]$ podman images
REPOSITORY                           TAG         IMAGE ID      CREATED        SIZE
localhost/do180/apache               latest      7f9154b1b605  6 minutes ago  257 MB
registry.access.redhat.com/ubi8/ubi  8.5         202c1768b1f7  5 months ago   235 MB
[student@workstation dockerfile-create]$ podman run --name lab-apache -d -p 10080:80 do180/apache
f95d2cf65dd46cdb23c3f7b07a237dd8e3d9a071cc7f000cb32522ea5dd69b04
[student@workstation dockerfile-create]$ podman ps
CONTAINER ID  IMAGE                          COMMAND               CREATED         STATUS             PORTS                  NAMES
f95d2cf65dd4  localhost/do180/apache:latest  httpd -D FOREGROU...  17 seconds ago  Up 17 seconds ago  0.0.0.0:10080->80/tcp  lab-apache
[student@workstation dockerfile-create]$ curl -s 127.0.0.1:10080
Hello from Containerfile
[student@workstation dockerfile-create]$ lab dockerfile-create finish

Completing the Guided Exercise: Building a basic Apache Container Image

 · Stopping lab-apache container that is running...............  SUCCESS
 · Removing lab-apache container that is in the cache..........  SUCCESS
 · Removing do180/apache custom container image................  SUCCESS
 · Removing UBI8 container image...............................  SUCCESS
[student@workstation dockerfile-create]$ 

--------------------------------------------------CH6 10Oct22---------
GE-Deploying a Database Server on OpenShift
------------------------------------------------------------------------
[student@workstation ~]$ lab openshift-resources start

Setting up workstation for the Guided Exercise: Deploying a Database Server on OpenShift

 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
 · Ensuring the 'developer-mysql-openshift' project is absent..  SUCCESS
[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ cat !$
cat /usr/local/etc/ocp4.config
RHT_OCP4_MASTER_API=https://api.ocp4.example.com:6443
RHT_OCP4_WILDCARD_DOMAIN=apps.ocp4.example.com
RHT_OCP4_NEXUS_SERVER=nexus-common.apps.ocp4.example.com
RHT_OCP4_DEV_USER=developer
RHT_OCP4_DEV_PASSWORD=developer
RHT_OCP4_GITHUB_USER=veerabose
RHT_OCP4_QUAY_USER=veeraabose
RHT_OCP4_USER_PASSWD=redhat
[student@workstation ~]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project ${RHT_OCP4_DEV_USER}-mysql-openshift
Now using project "developer-mysql-openshift" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc et projet
error: unknown command "et" for "oc"

Did you mean this?
	cp
	edit
	get
	set
[student@workstation ~]$ oc get projects
NAME                        DISPLAY NAME   STATUS
developer-mysql-openshift                  Active
[student@workstation ~]$ oc get templates
No resources found in developer-mysql-openshift namespace.
[student@workstation ~]$ oc new-app --template=mysql-persistent -p MYSQL_USER=user1 -p MYSQL_PASSWORD=mypa55 -p MYSQL_DATABASE=testdb -p MYSQL_ROOT_PASSWORD=r00tpa55 -p VOLUME_CAPACITY=10Gi
--> Deploying template "openshift/mysql-persistent" to project developer-mysql-openshift

     MySQL
     ---------
     MySQL database service, with persistent storage. For more information about using this template, including OpenShift considerations, see https://github.com/sclorg/mysql-container/blob/master/8.0/root/usr/share/container-scripts/mysql/README.md.
     
     NOTE: Scaling to more than one replica is not supported. You must have persistent volumes available in your cluster to use this template.

     The following service(s) have been created in your project: mysql.
     
            Username: user1
            Password: mypa55
       Database Name: testdb
      Connection URL: mysql://mysql:3306/
     
     For more information about using this template, including OpenShift considerations, see https://github.com/sclorg/mysql-container/blob/master/8.0/root/usr/share/container-scripts/mysql/README.md.

     * With parameters:
        * Memory Limit=512Mi
        * Namespace=openshift
        * Database Service Name=mysql
        * MySQL Connection Username=user1
        * MySQL Connection Password=mypa55
        * MySQL root user Password=r00tpa55
        * MySQL Database Name=testdb
        * Volume Capacity=10Gi
        * Version of MySQL Image=8.0-el8

--> Creating resources ...
    secret "mysql" created
    service "mysql" created
    persistentvolumeclaim "mysql" created
    deploymentconfig.apps.openshift.io "mysql" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/mysql' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc status
In project developer-mysql-openshift on server https://api.ocp4.example.com:6443

svc/mysql - 172.30.198.205:3306
  dc/mysql deploys openshift/mysql:8.0-el8 
    deployment #1 running for 34 seconds - 0/1 pods

View details with 'oc describe <resource>/<name>' or list resources with 'oc get all'.
[student@workstation ~]$ oc get all
NAME                 READY   STATUS      RESTARTS   AGE
pod/mysql-1-deploy   0/1     Completed   0          52s
pod/mysql-1-q8vc8    1/1     Running     0          40s

NAME                            DESIRED   CURRENT   READY   AGE
replicationcontroller/mysql-1   1         1         1       52s

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/mysql   ClusterIP   172.30.198.205   <none>        3306/TCP   54s

NAME                                       REVISION   DESIRED   CURRENT   TRIGGERED BY
deploymentconfig.apps.openshift.io/mysql   1          1         1         config,image(mysql:8.0-el8)
[student@workstation ~]$ oc describe pod pod/mysql-1-deploy
error: there is no need to specify a resource type as a separate argument when passing arguments in resource/name form (e.g. 'oc get resource/<resource_name>' instead of 'oc get resource resource/<resource_name>'
[student@workstation ~]$ oc describe pod/mysql-1-deploy
Name:         mysql-1-deploy
Namespace:    developer-mysql-openshift
Priority:     0
Node:         master01/192.168.50.10
Start Time:   Mon, 10 Oct 2022 01:33:25 -0400
Labels:       openshift.io/deployer-pod-for.name=mysql-1
Annotations:  k8s.v1.cni.cncf.io/network-status:
                [{
                    "name": "openshift-sdn",
                    "interface": "eth0",
                    "ips": [
                        "10.9.0.21"
                    ],
                    "default": true,
                    "dns": {}
                }]
              k8s.v1.cni.cncf.io/networks-status:
                [{
                    "name": "openshift-sdn",
                    "interface": "eth0",
                    "ips": [
                        "10.9.0.21"
                    ],
                    "default": true,
                    "dns": {}
                }]
              openshift.io/deployment-config.name: mysql
              openshift.io/deployment.name: mysql-1
              openshift.io/scc: restricted
Status:       Succeeded
IP:           10.9.0.21
IPs:
  IP:  10.9.0.21
Containers:
  deployment:
    Container ID:   cri-o://f951059b1d946302ce37e68c9bc359101a78196daa45b7a0ae4f7643faa12b81
    Image:          quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9439e3e873a7b9005d08f0afc33b13252c4fe79630496d11cd659ca7327d96f6
    Image ID:       quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9439e3e873a7b9005d08f0afc33b13252c4fe79630496d11cd659ca7327d96f6
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Mon, 10 Oct 2022 01:33:36 -0400
      Finished:     Mon, 10 Oct 2022 01:34:08 -0400
    Ready:          False
    Restart Count:  0
    Environment:
      OPENSHIFT_DEPLOYMENT_NAME:       mysql-1
      OPENSHIFT_DEPLOYMENT_NAMESPACE:  developer-mysql-openshift
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-b4clm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  kube-api-access-b4clm:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason          Age    From               Message
  ----    ------          ----   ----               -------
  Normal  Scheduled       2m41s  default-scheduler  Successfully assigned developer-mysql-openshift/mysql-1-deploy to master01
  Normal  AddedInterface  2m39s  multus             Add eth0 [10.9.0.21/23] from openshift-sdn
  Normal  Pulling         2m39s  kubelet            Pulling image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9439e3e873a7b9005d08f0afc33b13252c4fe79630496d11cd659ca7327d96f6"
  Normal  Pulled          2m30s  kubelet            Successfully pulled image "quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:9439e3e873a7b9005d08f0afc33b13252c4fe79630496d11cd659ca7327d96f6" in 9.426959183s
  Normal  Created         2m30s  kubelet            Created container deployment
  Normal  Started         2m30s  kubelet            Started container deployment
[student@workstation ~]$ oc get svc
NAME    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
mysql   ClusterIP   172.30.198.205   <none>        3306/TCP   4m17s
[student@workstation ~]$ oc describe service mysql
Name:              mysql
Namespace:         developer-mysql-openshift
Labels:            app=mysql-persistent
                   app.kubernetes.io/component=mysql-persistent
                   app.kubernetes.io/instance=mysql-persistent
                   template=mysql-persistent-template
Annotations:       openshift.io/generated-by: OpenShiftNewApp
                   template.openshift.io/expose-uri: mysql://{.spec.clusterIP}:{.spec.ports[?(.name=="mysql")].port}
Selector:          name=mysql
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.198.205
IPs:               172.30.198.205
Port:              mysql  3306/TCP
TargetPort:        3306/TCP
Endpoints:         10.9.0.22:3306
Session Affinity:  None
Events:            <none>
[student@workstation ~]$ oc get pvc
NAME    STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
mysql   Bound    pvc-922bdda2-59d4-4bd5-9cb2-7bd61205d195   10Gi       RWO            nfs-storage    6m41s
[student@workstation ~]$ oc get pv
Error from server (Forbidden): persistentvolumes is forbidden: User "developer" cannot list resource "persistentvolumes" in API group "" at the cluster scope
[student@workstation ~]$ oc port-forward mysql-1-5vfn4 3306:3306
Error from server (NotFound): pods "mysql-1-5vfn4" not found
[student@workstation ~]$ oc get pod
NAME             READY   STATUS      RESTARTS   AGE
mysql-1-deploy   0/1     Completed   0          8m5s
mysql-1-q8vc8    1/1     Running     0          7m53s
[student@workstation ~]$ oc port-forward mysql-1-q8vc8 3306:3306
Forwarding from 127.0.0.1:3306 -> 3306
Forwarding from [::1]:3306 -> 3306

^C[student@workstation ~]$ oc port-forward mysql-1-q8vc8 3306:3306
Forwarding from 127.0.0.1:3306 -> 3306
Forwarding from [::1]:3306 -> 3306
Handling connection for 3306
^C[student@workstation ~]$ oc delete project ${RHT_OCP4_DEV_USER}-mysql-openshift
project.project.openshift.io "developer-mysql-openshift" deleted
[student@workstation ~]$ lab openshift-resources finish

Completing the Guided Exercise: Deploying a Database Server on OpenShift

 · Deleting the 'developer-mysql-openshift' project............  SUCCESS
[student@workstation ~]$ 

------------------------------------------------------GE-Exposing a Service as a Route-CH6--------------
[student@workstation ~]$ ls
Desktop  DO180  DO180-apps  Documents  Downloads  local  Music  Pictures  Public  Templates  Videos
[student@workstation ~]$ lab openshift-routes start

Setting up workstation for the Guided Exercise: Exposing a Service as a Route

 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
 · Ensuring the 'developer-route' project does not exist.......  SUCCESS
[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ cat !$
cat /usr/local/etc/ocp4.config
RHT_OCP4_MASTER_API=https://api.ocp4.example.com:6443
RHT_OCP4_WILDCARD_DOMAIN=apps.ocp4.example.com
RHT_OCP4_NEXUS_SERVER=nexus-common.apps.ocp4.example.com
RHT_OCP4_DEV_USER=developer
RHT_OCP4_DEV_PASSWORD=developer
RHT_OCP4_GITHUB_USER=veerabose
RHT_OCP4_QUAY_USER=veeraabose
RHT_OCP4_USER_PASSWD=redhat
[student@workstation ~]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project ${RHT_OCP4_DEV_USER}-route
Now using project "developer-route" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc new-app --image=quay.io/redhattraining/php-hello-dockerfile --name php-helloworld
--> Found container image 4b696cc (3 years old) from quay.io for "quay.io/redhattraining/php-hello-dockerfile"

    Red Hat Universal Base Image 8 
    ------------------------------ 
    The Universal Base Image is designed and engineered to be the base layer for all of your containerized applications, middleware and utilities. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.

    Tags: base rhel8

    * An image stream tag will be created as "php-helloworld:latest" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "php-helloworld" created
    deployment.apps "php-helloworld" created
    service "php-helloworld" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/php-helloworld' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get pods -w
NAME                              READY   STATUS    RESTARTS   AGE
php-helloworld-85484585d6-thnjf   1/1     Running   0          2m52s
^C[student@workstation ~]$ oc logs -f php-helloworld-85484585d6-thnjf
[10-Oct-2022 17:07:03] NOTICE: [pool www] 'user' directive is ignored when FPM is not running as root
[10-Oct-2022 17:07:03] NOTICE: [pool www] 'group' directive is ignored when FPM is not running as root
AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.9.0.17. Set the 'ServerName' directive globally to suppress this message
^C
[student@workstation ~]$ oc describe svc/php-helloworld
Name:              php-helloworld
Namespace:         developer-route
Labels:            app=php-helloworld
                   app.kubernetes.io/component=php-helloworld
                   app.kubernetes.io/instance=php-helloworld
Annotations:       openshift.io/generated-by: OpenShiftNewApp
Selector:          deployment=php-helloworld
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.158.72
IPs:               172.30.158.72
Port:              8080-tcp  8080/TCP
TargetPort:        8080/TCP
Endpoints:         10.9.0.17:8080
Session Affinity:  None
Events:            <none>
[student@workstation ~]$ oc expose svc/php-helloworld
route.route.openshift.io/php-helloworld exposed
[student@workstation ~]$ oc describe route
Name:			php-helloworld
Namespace:		developer-route
Created:		17 seconds ago
Labels:			app=php-helloworld
			app.kubernetes.io/component=php-helloworld
			app.kubernetes.io/instance=php-helloworld
Annotations:		openshift.io/host.generated=true
Requested Host:		php-helloworld-developer-route.apps.ocp4.example.com
			   exposed on router default (host router-default.apps.ocp4.example.com) 17 seconds ago
Path:			<none>
TLS Termination:	<none>
Insecure Policy:	<none>
Endpoint Port:		8080-tcp

Service:	php-helloworld
Weight:		100 (100%)
Endpoints:	10.9.0.17:8080
[student@workstation ~]$ curl php-helloworld-${RHT_OCP4_DEV_USER}-route.${RHT_OCP4_WILDCARD_DOMAIN}
Hello, World! PHP version is 7.2.11
[student@workstation ~]$ curl php-helloworld-developer-route.apps.ocp4.example.com
Hello, World! PHP version is 7.2.11
[student@workstation ~]$ oc delete route/php-helloworld
route.route.openshift.io "php-helloworld" deleted
[student@workstation ~]$ oc expose svc/php-helloworld --name=${RHT_OCP4_DEV_USER}-xyz
route.route.openshift.io/developer-xyz exposed
[student@workstation ~]$ curl route.route.openshift.io/developer-xyz
curl: (6) Could not resolve host: route.route.openshift.io
[student@workstation ~]$ oc describe route
Name:			developer-xyz
Namespace:		developer-route
Created:		25 seconds ago
Labels:			app=php-helloworld
			app.kubernetes.io/component=php-helloworld
			app.kubernetes.io/instance=php-helloworld
Annotations:		openshift.io/host.generated=true
Requested Host:		developer-xyz-developer-route.apps.ocp4.example.com
			   exposed on router default (host router-default.apps.ocp4.example.com) 25 seconds ago
Path:			<none>
TLS Termination:	<none>
Insecure Policy:	<none>
Endpoint Port:		8080-tcp

Service:	php-helloworld
Weight:		100 (100%)
Endpoints:	10.9.0.17:8080
[student@workstation ~]$ curl developer-xyz-developer-route.apps.ocp4.example.com
Hello, World! PHP version is 7.2.11
[student@workstation ~]$ lab openshift-routes finish

Completing the Guided Exercise: Exposing a Service as a Route

 · Removing OpenShift project 'developer-route'................  SUCCESS
[student@workstation ~]$ 

--------------------------------GE--Creating a Containerized Application with Source-to-Image-CH6-----------------------
 [student@workstation ~]$ lab openshift-s2i start

Setting up workstation for the Guided Excercise: Creating a Containerized Application with Source-to-Image

 · Installing the tree command.................................  SUCCESS
 Checking local clone of the applications repository:
 · Folder '/home/student/DO180-apps' is a git repo.............  SUCCESS
 · Git repo '/home/student/DO180-apps' has no pending changes..  SUCCESS
 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
 · Ensuring the 'developer-s2i' project does not exist.........  SUCCESS
[student@workstation ~]$ cd ~/DO180-apps
[student@workstation DO180-apps]$ git checkout master
Switched to branch 'master'
Your branch is up to date with 'origin/master'.
[student@workstation DO180-apps]$ git checkout -b s2i
Switched to a new branch 's2i'
[student@workstation DO180-apps]$ git push -u origin s2i
Total 0 (delta 0), reused 0 (delta 0), pack-reused 0
remote: 
remote: Create a pull request for 's2i' on GitHub by visiting:
remote:      https://github.com/veerabose/DO180-apps/pull/new/s2i
remote: 
To https://github.com/veerabose/DO180-apps.git
 * [new branch]      s2i -> s2i
Branch 's2i' set up to track remote branch 's2i' from 'origin'.
[student@workstation DO180-apps]$ cd php-helloworld/
[student@workstation php-helloworld]$ ls
index.php
[student@workstation php-helloworld]$ cat index.php 
<?php
print "Hello, World! php version is " . PHP_VERSION . "\n";
?>
[student@workstation php-helloworld]$ source /usr/local/etc/ocp4.config
[student@workstation php-helloworld]$ cd ..
[student@workstation DO180-apps]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation DO180-apps]$ oc new-project ${RHT_OCP4_DEV_USER}-s2i
Now using project "developer-s2i" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation DO180-apps]$ oc new-app php:7.3 --name=php-helloworld https://github.com/${RHT_OCP4_GITHUB_USER}/DO180-apps#s2i --context-dir php-helloworld
--> Found image 0d7c8b9 (3 months old) in image stream "openshift/php" under tag "7.3" for "php:7.3"

    Apache 2.4 with PHP 7.3 
    ----------------------- 
    PHP 7.3 available as container is a base platform for building and running various PHP 7.3 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php73, rh-php73

    * The source repository appears to match: php
    * A source build using source code from https://github.com/veerabose/DO180-apps#s2i will be created
      * The resulting image will be pushed to image stream tag "php-helloworld:latest"
      * Use 'oc start-build' to trigger a new build

--> Creating resources ...
    imagestream.image.openshift.io "php-helloworld" created
    buildconfig.build.openshift.io "php-helloworld" created
    deployment.apps "php-helloworld" created
    service "php-helloworld" created
--> Success
    Build scheduled, use 'oc logs -f buildconfig/php-helloworld' to track its progress.
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/php-helloworld' 
    Run 'oc status' to view your app.
[student@workstation DO180-apps]$ oc logs -f buildconfig/php-helloworld
Adding cluster TLS certificate authority to trust store
Cloning "https://github.com/veerabose/DO180-apps" ...
	Commit:	180da897d2146855cd58eef0bdb6483d3b880f97 (Delete labs)
	Author:	veerabose <34031941+veerabose@users.noreply.github.com>
	Date:	Wed Apr 28 17:20:06 2021 +0530
Adding cluster TLS certificate authority to trust store
Adding cluster TLS certificate authority to trust store
time="2022-10-11T17:15:22Z" level=info msg="Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled"
I1011 17:15:22.054366       1 defaults.go:102] Defaulting to storage driver "overlay" with options [mountopt=metacopy=on].
Caching blobs under "/var/cache/blobs".
Trying to pull image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510...
Getting image source signatures
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying config sha256:0d7c8b9be5d6986eddaba0f2e3c338594c64f75903ced01930661e5c9271d78a
Writing manifest to image destination
Storing signatures
Generating dockerfile with builder image image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
Adding transient rw bind mount for /run/secrets/rhsm
STEP 1/9: FROM image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
STEP 2/9: LABEL "io.openshift.build.commit.date"="Wed Apr 28 17:20:06 2021 +0530"       "io.openshift.build.commit.id"="180da897d2146855cd58eef0bdb6483d3b880f97"       "io.openshift.build.commit.ref"="s2i"       "io.openshift.build.commit.message"="Delete labs"       "io.openshift.build.source-location"="https://github.com/veerabose/DO180-apps"       "io.openshift.build.source-context-dir"="php-helloworld"       "io.openshift.build.image"="image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510"       "io.openshift.build.commit.author"="veerabose <34031941+veerabose@users.noreply.github.com>"
STEP 3/9: ENV OPENSHIFT_BUILD_NAME="php-helloworld-1"     OPENSHIFT_BUILD_NAMESPACE="developer-s2i"     OPENSHIFT_BUILD_SOURCE="https://github.com/veerabose/DO180-apps"     OPENSHIFT_BUILD_REFERENCE="s2i"     OPENSHIFT_BUILD_COMMIT="180da897d2146855cd58eef0bdb6483d3b880f97"
STEP 4/9: USER root
STEP 5/9: COPY upload/src /tmp/src
STEP 6/9: RUN chown -R 1001:0 /tmp/src
STEP 7/9: USER 1001
STEP 8/9: RUN /usr/libexec/s2i/assemble
---> Installing application source...
=> sourcing 20-copy-config.sh ...
---> 17:15:41     Processing additional arbitrary httpd configuration provided by s2i ...
=> sourcing 00-documentroot.conf ...
=> sourcing 50-mpm-tuning.conf ...
=> sourcing 40-ssl-certs.sh ...
STEP 9/9: CMD /usr/libexec/s2i/run
COMMIT temp.builder.openshift.io/developer-s2i/php-helloworld-1:5dd5119d
time="2022-10-11T17:15:41Z" level=warning msg="Adding metacopy option, configured globally"
Getting image source signatures
Copying blob sha256:63c0270243d0ab5c36d4b250fbb9a7cee6e03e2391dcff38a405ad8553a6fe05
Copying blob sha256:cbd5a225fe2d34dfab50eecfbd5bb1b99eefdbfe3903fc2afaab24b79b60ffe2
Copying blob sha256:aba55b1131ca8729f8f118e018866d271512ccd5cfb03acbc7e33e9b4ab76411
Copying blob sha256:1c027f3e4a1adeb5a3b7346a48471ba8e2091a0eb6363c4ff6f97561f5d38607
Copying blob sha256:2907061238ee4021d20835d15e9b334891ee600f01466d31256bcce3c9262315
Copying blob sha256:18f1850e5e0d1fb529032d8c40e9b70da4312dc4e5e0bb15065912f929034cff
Copying config sha256:9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Writing manifest to image destination
Storing signatures
--> 9f46cfa130d
Successfully tagged temp.builder.openshift.io/developer-s2i/php-helloworld-1:5dd5119d
9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Getting image source signatures

Pushing image image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld:latest ...
Copying blob sha256:18f1850e5e0d1fb529032d8c40e9b70da4312dc4e5e0bb15065912f929034cff
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying config sha256:9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Writing manifest to image destination
Storing signatures
Successfully pushed image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld@sha256:d8293426fc5590fc465a8aeeabb8f85e5484437144dafc74222d45d79b1cf451
Push successful
[student@workstation DO180-apps]$ oc status
In project developer-s2i on server https://api.ocp4.example.com:6443

svc/php-helloworld - 172.30.228.110 ports 8080, 8443
  deployment/php-helloworld deploys istag/php-helloworld:latest <-
    bc/php-helloworld source builds https://github.com/veerabose/DO180-apps#s2i on openshift/php:7.3 
    deployment #2 running for about a minute - 1 pod
    deployment #1 deployed 2 minutes ago


1 info identified, use 'oc status --suggest' to see details.
[student@workstation DO180-apps]$ oc get all
NAME                                  READY   STATUS      RESTARTS   AGE
pod/php-helloworld-1-build            0/1     Completed   0          2m46s
pod/php-helloworld-54f8754498-54m7k   1/1     Running     0          119s

NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/php-helloworld   ClusterIP   172.30.228.110   <none>        8080/TCP,8443/TCP   2m46s

NAME                             READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/php-helloworld   1/1     1            1           2m46s

NAME                                        DESIRED   CURRENT   READY   AGE
replicaset.apps/php-helloworld-54f8754498   1         1         1       119s
replicaset.apps/php-helloworld-767c6c8b8d   0         0         0       2m46s

NAME                                            TYPE     FROM      LATEST
buildconfig.build.openshift.io/php-helloworld   Source   Git@s2i   1

NAME                                        TYPE     FROM          STATUS     STARTED         DURATION
build.build.openshift.io/php-helloworld-1   Source   Git@180da89   Complete   2 minutes ago   48s

NAME                                            IMAGE REPOSITORY                                                                TAGS     UPDATED
imagestream.image.openshift.io/php-helloworld   image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld   latest   2 minutes ago
[student@workstation DO180-apps]$ oc get pods
NAME                              READY   STATUS      RESTARTS   AGE
php-helloworld-1-build            0/1     Completed   0          4m51s
php-helloworld-54f8754498-54m7k   1/1     Running     0          4m4s
[student@workstation DO180-apps]$ oc logs --all-containers -f php-helloworld-1-build
Adding cluster TLS certificate authority to trust store
Adding cluster TLS certificate authority to trust store
Cloning "https://github.com/veerabose/DO180-apps" ...
	Commit:	180da897d2146855cd58eef0bdb6483d3b880f97 (Delete labs)
	Author:	veerabose <34031941+veerabose@users.noreply.github.com>
	Date:	Wed Apr 28 17:20:06 2021 +0530
Adding cluster TLS certificate authority to trust store
time="2022-10-11T17:15:22Z" level=info msg="Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled"
I1011 17:15:22.054366       1 defaults.go:102] Defaulting to storage driver "overlay" with options [mountopt=metacopy=on].
Caching blobs under "/var/cache/blobs".
Trying to pull image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510...
Getting image source signatures
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying config sha256:0d7c8b9be5d6986eddaba0f2e3c338594c64f75903ced01930661e5c9271d78a
Writing manifest to image destination
Storing signatures
Generating dockerfile with builder image image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
Adding transient rw bind mount for /run/secrets/rhsm
STEP 1/9: FROM image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
STEP 2/9: LABEL "io.openshift.build.commit.date"="Wed Apr 28 17:20:06 2021 +0530"       "io.openshift.build.commit.id"="180da897d2146855cd58eef0bdb6483d3b880f97"       "io.openshift.build.commit.ref"="s2i"       "io.openshift.build.commit.message"="Delete labs"       "io.openshift.build.source-location"="https://github.com/veerabose/DO180-apps"       "io.openshift.build.source-context-dir"="php-helloworld"       "io.openshift.build.image"="image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510"       "io.openshift.build.commit.author"="veerabose <34031941+veerabose@users.noreply.github.com>"
STEP 3/9: ENV OPENSHIFT_BUILD_NAME="php-helloworld-1"     OPENSHIFT_BUILD_NAMESPACE="developer-s2i"     OPENSHIFT_BUILD_SOURCE="https://github.com/veerabose/DO180-apps"     OPENSHIFT_BUILD_REFERENCE="s2i"     OPENSHIFT_BUILD_COMMIT="180da897d2146855cd58eef0bdb6483d3b880f97"
STEP 4/9: USER root
STEP 5/9: COPY upload/src /tmp/src
STEP 6/9: RUN chown -R 1001:0 /tmp/src
STEP 7/9: USER 1001
STEP 8/9: RUN /usr/libexec/s2i/assemble
---> Installing application source...
=> sourcing 20-copy-config.sh ...
---> 17:15:41     Processing additional arbitrary httpd configuration provided by s2i ...
=> sourcing 00-documentroot.conf ...
=> sourcing 50-mpm-tuning.conf ...
=> sourcing 40-ssl-certs.sh ...
STEP 9/9: CMD /usr/libexec/s2i/run
COMMIT temp.builder.openshift.io/developer-s2i/php-helloworld-1:5dd5119d
time="2022-10-11T17:15:41Z" level=warning msg="Adding metacopy option, configured globally"
Getting image source signatures
Copying blob sha256:63c0270243d0ab5c36d4b250fbb9a7cee6e03e2391dcff38a405ad8553a6fe05
Copying blob sha256:cbd5a225fe2d34dfab50eecfbd5bb1b99eefdbfe3903fc2afaab24b79b60ffe2
Copying blob sha256:aba55b1131ca8729f8f118e018866d271512ccd5cfb03acbc7e33e9b4ab76411
Copying blob sha256:1c027f3e4a1adeb5a3b7346a48471ba8e2091a0eb6363c4ff6f97561f5d38607
Copying blob sha256:2907061238ee4021d20835d15e9b334891ee600f01466d31256bcce3c9262315
Copying blob sha256:18f1850e5e0d1fb529032d8c40e9b70da4312dc4e5e0bb15065912f929034cff
Copying config sha256:9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Writing manifest to image destination
Storing signatures
--> 9f46cfa130d
Successfully tagged temp.builder.openshift.io/developer-s2i/php-helloworld-1:5dd5119d
9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Getting image source signatures

Pushing image image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld:latest ...
Copying blob sha256:18f1850e5e0d1fb529032d8c40e9b70da4312dc4e5e0bb15065912f929034cff
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying config sha256:9f46cfa130db1dc52cde5c9fddbfaae6612c8e6edc50dca9be3cef661b8532a4
Writing manifest to image destination
Storing signatures
Successfully pushed image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld@sha256:d8293426fc5590fc465a8aeeabb8f85e5484437144dafc74222d45d79b1cf451
Push successful
[student@workstation DO180-apps]$ oc describe deployment/php-helloworld
Name:                   php-helloworld
Namespace:              developer-s2i
CreationTimestamp:      Tue, 11 Oct 2022 13:14:57 -0400
Labels:                 app=php-helloworld
                        app.kubernetes.io/component=php-helloworld
                        app.kubernetes.io/instance=php-helloworld
Annotations:            deployment.kubernetes.io/revision: 2
                        image.openshift.io/triggers:
                          [{"from":{"kind":"ImageStreamTag","name":"php-helloworld:latest"},"fieldPath":"spec.template.spec.containers[?(@.name==\"php-helloworld\")...
                        openshift.io/generated-by: OpenShiftNewApp
Selector:               deployment=php-helloworld
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:       deployment=php-helloworld
  Annotations:  openshift.io/generated-by: OpenShiftNewApp
  Containers:
   php-helloworld:
    Image:        image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld@sha256:d8293426fc5590fc465a8aeeabb8f85e5484437144dafc74222d45d79b1cf451
    Ports:        8443/TCP, 8080/TCP
    Host Ports:   0/TCP, 0/TCP
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   php-helloworld-54f8754498 (1/1 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  6m37s  deployment-controller  Scaled up replica set php-helloworld-767c6c8b8d to 1
  Normal  ScalingReplicaSet  5m50s  deployment-controller  Scaled up replica set php-helloworld-54f8754498 to 1
  Normal  ScalingReplicaSet  5m35s  deployment-controller  Scaled down replica set php-helloworld-767c6c8b8d to 0
[student@workstation DO180-apps]$ oc get svc
NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
php-helloworld   ClusterIP   172.30.228.110   <none>        8080/TCP,8443/TCP   9m41s
[student@workstation DO180-apps]$ oc expose service php-helloworld --name ${RHT_OCP4_DEV_USER}-helloworld
route.route.openshift.io/developer-helloworld exposed
[student@workstation DO180-apps]$ oc get route -o jsonpath='{..spec.host}{"\n"}'
developer-helloworld-developer-s2i.apps.ocp4.example.com
[student@workstation DO180-apps]$ curl -s developer-helloworld-developer-s2i.apps.ocp4.example.com
Hello, World! php version is 7.3.33
[student@workstation DO180-apps]$ curl -s ${RHT_OCP4_DEV_USER}-helloworld-${RHT_OCP4_DEV_USER}-s2i.${RHT_OCP4_WILDCARD_DOMAIN}
Hello, World! php version is 7.3.33
[student@workstation DO180-apps]$ cd ~/DO180-apps/php-helloworld
[student@workstation php-helloworld]$ vi index.php 
[student@workstation php-helloworld]$ git status
On branch s2i
Your branch is up to date with 'origin/s2i'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   index.php

no changes added to commit (use "git add" and/or "git commit -a")
[student@workstation php-helloworld]$ git add .
[student@workstation php-helloworld]$ git commit -m 'Changed index page contents.'
[s2i 50aacb8] Changed index page contents.
 1 file changed, 1 insertion(+)
[student@workstation php-helloworld]$ git push origin s2i
Enumerating objects: 7, done.
Counting objects: 100% (7/7), done.
Delta compression using up to 2 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (4/4), 419 bytes | 419.00 KiB/s, done.
Total 4 (delta 1), reused 3 (delta 1), pack-reused 0
remote: Resolving deltas: 100% (1/1), completed with 1 local object.
To https://github.com/veerabose/DO180-apps.git
   180da89..50aacb8  s2i -> s2i
[student@workstation php-helloworld]$ oc start-build php-helloworld
build.build.openshift.io/php-helloworld-2 started
[student@workstation php-helloworld]$ oc get pods
NAME                              READY   STATUS      RESTARTS   AGE
php-helloworld-1-build            0/1     Completed   0          18m
php-helloworld-2-build            1/1     Running     0          14s
php-helloworld-54f8754498-54m7k   1/1     Running     0          17m
[student@workstation php-helloworld]$ oc get pods
NAME                              READY   STATUS      RESTARTS   AGE
php-helloworld-1-build            0/1     Completed   0          19m
php-helloworld-2-build            0/1     Completed   0          86s
php-helloworld-56bcd46bd4-fgxlm   1/1     Running     0          61s
[student@workstation php-helloworld]$ oc logs php-helloworld-2-build -f
Adding cluster TLS certificate authority to trust store
time="2022-10-11T17:33:32Z" level=info msg="Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled"
I1011 17:33:32.108313       1 defaults.go:102] Defaulting to storage driver "overlay" with options [mountopt=metacopy=on].
Caching blobs under "/var/cache/blobs".
Trying to pull image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510...
Getting image source signatures
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying config sha256:0d7c8b9be5d6986eddaba0f2e3c338594c64f75903ced01930661e5c9271d78a
Writing manifest to image destination
Storing signatures
Generating dockerfile with builder image image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
Adding transient rw bind mount for /run/secrets/rhsm
STEP 1/9: FROM image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
STEP 2/9: LABEL "io.openshift.build.image"="image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510"       "io.openshift.build.commit.author"="Student User <student@workstation.lab.example.com>"       "io.openshift.build.commit.date"="Tue Oct 11 13:28:56 2022 -0400"       "io.openshift.build.commit.id"="50aacb8ec673ba812736bb7d8ca486c8ce62a0a0"       "io.openshift.build.commit.ref"="s2i"       "io.openshift.build.commit.message"="Changed index page contents."       "io.openshift.build.source-location"="https://github.com/veerabose/DO180-apps"       "io.openshift.build.source-context-dir"="php-helloworld"
STEP 3/9: ENV OPENSHIFT_BUILD_NAME="php-helloworld-2"     OPENSHIFT_BUILD_NAMESPACE="developer-s2i"     OPENSHIFT_BUILD_SOURCE="https://github.com/veerabose/DO180-apps"     OPENSHIFT_BUILD_REFERENCE="s2i"     OPENSHIFT_BUILD_COMMIT="50aacb8ec673ba812736bb7d8ca486c8ce62a0a0"
STEP 4/9: USER root
STEP 5/9: COPY upload/src /tmp/src
STEP 6/9: RUN chown -R 1001:0 /tmp/src
STEP 7/9: USER 1001
STEP 8/9: RUN /usr/libexec/s2i/assemble
---> Installing application source...
=> sourcing 20-copy-config.sh ...
---> 17:33:47     Processing additional arbitrary httpd configuration provided by s2i ...
=> sourcing 00-documentroot.conf ...
=> sourcing 50-mpm-tuning.conf ...
=> sourcing 40-ssl-certs.sh ...
STEP 9/9: CMD /usr/libexec/s2i/run
COMMIT temp.builder.openshift.io/developer-s2i/php-helloworld-2:10370f97
time="2022-10-11T17:33:47Z" level=warning msg="Adding metacopy option, configured globally"
Getting image source signatures
Copying blob sha256:63c0270243d0ab5c36d4b250fbb9a7cee6e03e2391dcff38a405ad8553a6fe05
Copying blob sha256:cbd5a225fe2d34dfab50eecfbd5bb1b99eefdbfe3903fc2afaab24b79b60ffe2
Copying blob sha256:aba55b1131ca8729f8f118e018866d271512ccd5cfb03acbc7e33e9b4ab76411
Copying blob sha256:1c027f3e4a1adeb5a3b7346a48471ba8e2091a0eb6363c4ff6f97561f5d38607
Copying blob sha256:2907061238ee4021d20835d15e9b334891ee600f01466d31256bcce3c9262315
Copying blob sha256:f50350ae5c1bafb1641fb5165eef4e2520977b1eb1646e56ea71f49c34fcdf49
Copying config sha256:29c1b612f0451e64d2c725e05eb7a60c85aaf52f1c084c7885eff31afe07ed5d
Writing manifest to image destination
Storing signatures
--> 29c1b612f04
Successfully tagged temp.builder.openshift.io/developer-s2i/php-helloworld-2:10370f97
29c1b612f0451e64d2c725e05eb7a60c85aaf52f1c084c7885eff31afe07ed5d

Pushing image image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld:latest ...
Getting image source signatures
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:f50350ae5c1bafb1641fb5165eef4e2520977b1eb1646e56ea71f49c34fcdf49
Copying config sha256:29c1b612f0451e64d2c725e05eb7a60c85aaf52f1c084c7885eff31afe07ed5d
Writing manifest to image destination
Storing signatures
Successfully pushed image-registry.openshift-image-registry.svc:5000/developer-s2i/php-helloworld@sha256:01e0cce6a534233a68a591a297e14b2618922b4ad0e64dc0f9fce70fd63a5894
Push successful
[student@workstation php-helloworld]$ oc get pods
NAME                              READY   STATUS      RESTARTS   AGE
php-helloworld-1-build            0/1     Completed   0          22m
php-helloworld-2-build            0/1     Completed   0          3m34s
php-helloworld-56bcd46bd4-fgxlm   1/1     Running     0          3m9s
[student@workstation php-helloworld]$ curl -s developer-helloworld-developer-s2i.apps.ocp4.example.com
Hello, World! php version is 7.3.33
A change is a coming!
[student@workstation php-helloworld]$ lab openshift-s2i finish

Completing the Guided Excercise: Creating a Containerized Application with Source-to-Image

 · Log in on OpenShift.........................................  SUCCESS
 · Deleting the 'developer-s2i' project........................  SUCCESS
[student@workstation php-helloworld]$ 

 --------------LAB 06 Deploying Containerized Applications on OpenShift----------
 [student@workstation ~]$ lab openshift-review start

Setting up workstation for the Lab: Deploying Containerized Applications on OpenShift

 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
 · Ensuring the 'developer-ocp' project does not exist.........  SUCCESS

[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project ${RHT_OCP4_DEV_USER}-ocp
Now using project "developer-ocp" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc new-app php:7.3~https://github.com/RedHatTraining/DO180-apps --context-dir temps --name temps
--> Found image 0d7c8b9 (3 months old) in image stream "openshift/php" under tag "7.3" for "php:7.3"

    Apache 2.4 with PHP 7.3 
    ----------------------- 
    PHP 7.3 available as container is a base platform for building and running various PHP 7.3 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy for developers to write dynamically generated web pages. PHP also offers built-in database integration for several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement for CGI scripts.

    Tags: builder, php, php73, rh-php73

    * A source build using source code from https://github.com/RedHatTraining/DO180-apps will be created
      * The resulting image will be pushed to image stream tag "temps:latest"
      * Use 'oc start-build' to trigger a new build

--> Creating resources ...
    imagestream.image.openshift.io "temps" created
    buildconfig.build.openshift.io "temps" created
    deployment.apps "temps" created
    service "temps" created
--> Success
    Build scheduled, use 'oc logs -f buildconfig/temps' to track its progress.
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/temps' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc logs -f bc/temps
Adding cluster TLS certificate authority to trust store
Cloning "https://github.com/RedHatTraining/DO180-apps" ...
	Commit:	f7cd8963ef353d9173c3a21dcccf402f3616840b (Initial commit, including all apps previously in course)
	Author:	Jordi Sola <someth2say@gmail.com>
	Date:	Fri Oct 4 13:04:03 2019 +0200
Adding cluster TLS certificate authority to trust store
Adding cluster TLS certificate authority to trust store
time="2022-10-11T17:47:06Z" level=info msg="Not using native diff for overlay, this may cause degraded performance for building images: kernel has CONFIG_OVERLAY_FS_REDIRECT_DIR enabled"
I1011 17:47:06.579323       1 defaults.go:102] Defaulting to storage driver "overlay" with options [mountopt=metacopy=on].
Caching blobs under "/var/cache/blobs".
Trying to pull image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510...
Getting image source signatures
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying config sha256:0d7c8b9be5d6986eddaba0f2e3c338594c64f75903ced01930661e5c9271d78a
Writing manifest to image destination
Storing signatures
Generating dockerfile with builder image image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
Adding transient rw bind mount for /run/secrets/rhsm
STEP 1/9: FROM image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510
STEP 2/9: LABEL "io.openshift.build.commit.author"="Jordi Sola <someth2say@gmail.com>"       "io.openshift.build.commit.date"="Fri Oct 4 13:04:03 2019 +0200"       "io.openshift.build.commit.id"="f7cd8963ef353d9173c3a21dcccf402f3616840b"       "io.openshift.build.commit.ref"="master"       "io.openshift.build.commit.message"="Initial commit, including all apps previously in course"       "io.openshift.build.source-location"="https://github.com/RedHatTraining/DO180-apps"       "io.openshift.build.source-context-dir"="temps"       "io.openshift.build.image"="image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:8a55f47ae8a635e5dab3cbd63b404137ae25fc2aa5357abd1c3adfd355ebc510"
STEP 3/9: ENV OPENSHIFT_BUILD_NAME="temps-1"     OPENSHIFT_BUILD_NAMESPACE="developer-ocp"     OPENSHIFT_BUILD_SOURCE="https://github.com/RedHatTraining/DO180-apps"     OPENSHIFT_BUILD_COMMIT="f7cd8963ef353d9173c3a21dcccf402f3616840b"
STEP 4/9: USER root
STEP 5/9: COPY upload/src /tmp/src
STEP 6/9: RUN chown -R 1001:0 /tmp/src
STEP 7/9: USER 1001
STEP 8/9: RUN /usr/libexec/s2i/assemble
---> Installing application source...
=> sourcing 20-copy-config.sh ...
---> 17:47:20     Processing additional arbitrary httpd configuration provided by s2i ...
=> sourcing 00-documentroot.conf ...
=> sourcing 50-mpm-tuning.conf ...
=> sourcing 40-ssl-certs.sh ...
STEP 9/9: CMD /usr/libexec/s2i/run
COMMIT temp.builder.openshift.io/developer-ocp/temps-1:cdd577ec
time="2022-10-11T17:47:20Z" level=warning msg="Adding metacopy option, configured globally"
Getting image source signatures
Copying blob sha256:63c0270243d0ab5c36d4b250fbb9a7cee6e03e2391dcff38a405ad8553a6fe05
Copying blob sha256:cbd5a225fe2d34dfab50eecfbd5bb1b99eefdbfe3903fc2afaab24b79b60ffe2
Copying blob sha256:aba55b1131ca8729f8f118e018866d271512ccd5cfb03acbc7e33e9b4ab76411
Copying blob sha256:1c027f3e4a1adeb5a3b7346a48471ba8e2091a0eb6363c4ff6f97561f5d38607
Copying blob sha256:2907061238ee4021d20835d15e9b334891ee600f01466d31256bcce3c9262315
Copying blob sha256:4bd6e2eabb42ca6beb3c19d1f040faa9da2d5026ee668b19dcfe0a2e7ab62c0e
Copying config sha256:f20c0dcc4cde069b020b4cbfeb938572aa2611e473eb759923485049c9a8bf5a
Writing manifest to image destination
Storing signatures
--> f20c0dcc4cd
Successfully tagged temp.builder.openshift.io/developer-ocp/temps-1:cdd577ec
f20c0dcc4cde069b020b4cbfeb938572aa2611e473eb759923485049c9a8bf5a

Pushing image image-registry.openshift-image-registry.svc:5000/developer-ocp/temps:latest ...
Getting image source signatures
Copying blob sha256:4bd6e2eabb42ca6beb3c19d1f040faa9da2d5026ee668b19dcfe0a2e7ab62c0e
Copying blob sha256:b8b9f4fbfc2dbc0a5c14a11cd3ee717cd2fb9c8b58499863ca111c9356af84d4
Copying blob sha256:f6029bef86708a073e687c7ececb22245ee3cc2bff1dd9108e98e19469ac3c0f
Copying blob sha256:6b5d6793adb89f3531e554d5066a6f7c5518cb9c8958f4c139713cbd7bacf30b
Copying blob sha256:1cc60fbe16bd8c6d9af0ca63602331cb25bd68705ae0160dbaae1de6ac5457d3
Copying blob sha256:ffb0ffdba2a920e44896cc35806092f88cef747e2bb92cffc9538507dd9f5238
Copying config sha256:f20c0dcc4cde069b020b4cbfeb938572aa2611e473eb759923485049c9a8bf5a
Writing manifest to image destination
Storing signatures
Successfully pushed image-registry.openshift-image-registry.svc:5000/developer-ocp/temps@sha256:961adb6b9758a47292931421e985cfc1ae72869e15ead96d28ba4fc3927a8f6f
Push successful
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS      RESTARTS   AGE
temps-1-build            0/1     Completed   0          110s
temps-785df57c66-j96qx   1/1     Running     0          81s
^C[student@workstation ~]$ oc status
In project developer-ocp on server https://api.ocp4.example.com:6443

svc/temps - 172.30.155.116 ports 8080, 8443
  deployment/temps deploys istag/temps:latest <-
    bc/temps source builds https://github.com/RedHatTraining/DO180-apps on openshift/php:7.3 
    deployment #2 running for about a minute - 1 pod
    deployment #1 deployed 2 minutes ago


1 info identified, use 'oc status --suggest' to see details.
[student@workstation ~]$ oc get all
NAME                         READY   STATUS      RESTARTS   AGE
pod/temps-1-build            0/1     Completed   0          2m22s
pod/temps-785df57c66-j96qx   1/1     Running     0          113s

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/temps   ClusterIP   172.30.155.116   <none>        8080/TCP,8443/TCP   2m23s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/temps   1/1     1            1           2m23s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/temps-564dbdbbbb   0         0         0       2m23s
replicaset.apps/temps-785df57c66   1         1         1       113s

NAME                                   TYPE     FROM   LATEST
buildconfig.build.openshift.io/temps   Source   Git    1

NAME                               TYPE     FROM          STATUS     STARTED         DURATION
build.build.openshift.io/temps-1   Source   Git@f7cd896   Complete   2 minutes ago   29s

NAME                                   IMAGE REPOSITORY                                                       TAGS     UPDATED
imagestream.image.openshift.io/temps   image-registry.openshift-image-registry.svc:5000/developer-ocp/temps   latest   About a minute ago
[student@workstation ~]$ oc expose svc/temps
route.route.openshift.io/temps exposed
[student@workstation ~]$ oc get route/temps
NAME    HOST/PORT                                   PATH   SERVICES   PORT       TERMINATION   WILDCARD
temps   temps-developer-ocp.apps.ocp4.example.com          temps      8080-tcp                 None
[student@workstation ~]$ lab openshift-review grade

Grading the student's work for the Lab: Deploying Containerized Applications on OpenShift

 · Log in on OpenShift.........................................  SUCCESS
Accessing the web application..................................  PASS
[student@workstation ~]$ lab openshift-review finish

Completing the Lab: Deploying Containerized Applications on OpenShift

 · Log in on OpenShift.........................................  SUCCESS
 · Deleting the developer-ocp project..........................  SUCCESS
[student@workstation ~]$ 

------------------------------------------------Summary---------------------------
In this chapter, you learned:

• OpenShift Container Platform stores definitions of each OpenShift or Kubernetes resource
instance as an object in the cluster's distributed database service, etcd. Common resource
types are: Pod, Persistent Volume (PV), Persistent Volume Claim (PVC), Service
(SVC), Route, Deployment, DeploymentConfig and Build Configuration (BC).
• Use the OpenShift command-line client oc to:
– Create, change, and delete projects.
– Create application resources inside a project.
– Delete, inspect, edit, and export resources inside a project.
– Check logs from application pods, deployments, and build operations.
• The oc new-app command can create application pods in many different ways: from an
existing container image hosted on an image registry, from Containerfiles, and from source code
using the Source-to-Image (S2I) process.
• Source-to-Image (S2I) is a tool that makes it easy to build a container image from application
source code. This tool retrieves source code from a Git repository, injects the source code into
a selected container image based on a specific language or technology, and produces a new
container image that runs the assembled application.
• A Route connects a public-facing IP address and DNS host name to an internal-facing service
IP. While services allow for network access between pods inside an OpenShift instance, routes
allow for network access to pods from users and applications outside the OpenShift instance.
• You can create, build, deploy, and monitor applications using the OpenShift web console.

----------------------------CH7 - Deploying Multi-Container Applications-------12OCt22------------------
----------------------------------------------
[student@workstation ~]$ lab multicontainer-application start

Setting up workstation for the Guided Exercise: Creating an Application on OpenShift

 · Checking podman configuration...............................  SUCCESS

 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
 · Ensure application project does not exist...................  SUCCESS
 · Downloading starter project.................................  SUCCESS
 · Downloading solution project................................  SUCCESS

Setup successful. Please proceed with the exercise.


[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project ${RHT_OCP4_DEV_USER}-application
Now using project "developer-application" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc get projects
NAME                    DISPLAY NAME   STATUS
developer-application                  Active
[student@workstation ~]$ pwd
/home/student
[student@workstation ~]$ cd DO180-apps/
[student@workstation DO180-apps]$ cd ..
[student@workstation ~]$ cd DO180
[student@workstation DO180]$ cd labs/multicontainer-application/
[student@workstation multicontainer-application]$ ls
db.sql  todo-app.yml
[student@workstation multicontainer-application]$ less todo-app.yml 
[student@workstation multicontainer-application]$ oc get sc
NAME                    PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  75d
[student@workstation multicontainer-application]$ oc get sc -o ymal | less
[student@workstation multicontainer-application]$ oc get sc -o yaml | less
[student@workstation multicontainer-application]$ oc get sc -o yaml 
apiVersion: v1
items:
- apiVersion: storage.k8s.io/v1
  kind: StorageClass
  metadata:
    annotations:
      storageclass.kubernetes.io/is-default-class: "true"
    creationTimestamp: "2022-07-28T16:27:24Z"
    name: nfs-storage
    resourceVersion: "22949"
    uid: d34dc63c-af3f-45a6-b90d-06efdd5aa823
  parameters:
    archiveOnDelete: "false"
  provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
  reclaimPolicy: Delete
  volumeBindingMode: Immediate
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
[student@workstation multicontainer-application]$ oc get pvc
No resources found in developer-application namespace.
[student@workstation multicontainer-application]$ oc create -f todo-app.yml
pod/mysql created
pod/todoapi created
service/todoapi created
service/mysql created
persistentvolumeclaim/dbclaim created
[student@workstation multicontainer-application]$ oc get app
error: the server doesn't have a resource type "app"
[student@workstation multicontainer-application]$ oc get all
NAME          READY   STATUS    RESTARTS   AGE
pod/mysql     1/1     Running   0          43s
pod/todoapi   1/1     Running   0          43s

NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
service/mysql     ClusterIP   172.30.66.189   <none>        3306/TCP    43s
service/todoapi   ClusterIP   172.30.39.114   <none>        30080/TCP   43s
[student@workstation multicontainer-application]$ cat todo-app.yml 
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    labels:
      app: todonodejs
      name: mysql
    name: mysql
  spec:
    containers:
    - env:
      - name: MYSQL_ROOT_PASSWORD
        value: r00tpa55
      - name: MYSQL_USER
        value: user1
      - name: MYSQL_PASSWORD
        value: mypa55
      - name: MYSQL_DATABASE
        value: items
      image: registry.redhat.io/rhel8/mysql-80:1
      name: mysql
      ports:
      - containerPort: 3306
        name: mysql
      volumeMounts:
      - mountPath: /var/lib/mysql/data
        name: db-volume
    volumes:
    - name: db-volume
      persistentVolumeClaim:
        claimName: dbclaim

- apiVersion: v1
  kind: Pod
  metadata:
    labels:
      app: todonodejs
      name: todoapi
    name: todoapi
  spec:
    containers:
    - env:
      - name: MYSQL_ENV_MYSQL_DATABASE
        value: items
      - name: MYSQL_ENV_MYSQL_USER
        value: user1
      - name: MYSQL_ENV_MYSQL_PASSWORD
        value: mypa55
      image: quay.io/redhattraining/do180-todonodejs-12
      name: todoapi
      ports:
      - containerPort: 30080
        name: nodejs-http
      resources:
        limits:
          cpu: "0.5"
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: todonodejs
      name: todoapi
    name: todoapi
  spec:
    ports:
    - port: 30080
    selector:
      name: todoapi
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: todonodejs
      name: mysql
    name: mysql
  spec:
    ports:
    - port: 3306
    selector:
      name: mysql
- apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    labels:
      app: todonodejs
    name: dbclaim
  spec:
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 10Mi
kind: List
metadata: {}
[student@workstation multicontainer-application]$ oc get pvc
NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
dbclaim   Bound    pvc-5eedb2d4-2442-451f-aab0-0bb344878363   10Mi       RWO            nfs-storage    79s
[student@workstation multicontainer-application]$ oc get pods -w
NAME      READY   STATUS    RESTARTS   AGE
mysql     1/1     Running   0          110s
todoapi   1/1     Running   0          110s
^C[student@workstation multicontainer-application]$ oc port-forward mysql 3306:3306
Forwarding from 127.0.0.1:3306 -> 3306
Forwarding from [::1]:3306 -> 3306
Handling connection for 3306
^C[student@workstation multicontainer-application]$ 
[student@workstation multicontainer-application]$ mysql -uuser1 -h 127.0.0.1 -pmypa55 -P3306 items < db.sql
mysql: [Warning] Using a password on the command line interface can be insecure.
[student@workstation multicontainer-application]$ 

[student@workstation ~]$ oc expose service todoapi
route.route.openshift.io/todoapi exposed
[student@workstation ~]$ oc status | grep -o "http:.*com"
http://todoapi-developer-application.apps.ocp4.example.com
[student@workstation ~]$ curl -w "\n" $(oc status | grep -o "http:.*com")/todo/api/items/1
{"id":1,"description":"Pick up newspaper","done":false}
[student@workstation ~]$ cd ~
[student@workstation ~]$ lab multicontainer-application finish

Completing the Guided Exercise: Creating an Application on OpenShift

 · Log in on OpenShift.........................................  SUCCESS
 · Removing developer-application project......................  SUCCESS
 · Removing the project directory..............................  SUCCESS
 · Removing the solution directory.............................  SUCCESS
[student@workstation ~]$ 
------------------------------------------------LAB -Deploying Multi-Container Applications ------------------

[student@workstation ~]$ lab multicontainer-review start

Setting up workstation for the Lab: Deploying Multi-container Applications

Exercise is already setup.
 Verifying the OpenShift cluster is running:
 · Log in on OpenShift.........................................  SUCCESS
 · Check the internal registry is up and running...............  SUCCESS
[student@workstation ~]$ cd ~/DO180/labs/multicontainer-review
[student@workstation multicontainer-review]$ source /usr/local/etc/ocp4.config
[student@workstation multicontainer-review]$ oc login -u ${RHT_OCP4_DEV_USER} -p ${RHT_OCP4_DEV_PASSWORD} ${RHT_OCP4_MASTER_API}
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation multicontainer-review]$ oc new-project  ${RHT_OCP4_DEV_USER}-deploy
Error from server (AlreadyExists): project.project.openshift.io "developer-deploy" already exists
[student@workstation multicontainer-review]$ podman login registry.redhat.io
Username: veeraabose
Password: 
Login Succeeded!
[student@workstation multicontainer-review]$ oc new-project  ${RHT_OCP4_DEV_USER}-deploy
Already on project "developer-deploy" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation multicontainer-review]$ cd images/mysql/
[student@workstation mysql]$ ls
build.sh  Containerfile  delete.sh  README.md  root  test  test.sh
[student@workstation mysql]$ cat Containerfile 
FROM registry.redhat.io/rhel8/mysql-80:1

MAINTAINER username <username@example.com>

RUN echo "default_authentication_plugin = mysql_native_password" >> /etc/my.cnf
# MySQL image for DO180
#
# Volumes:
#  * /var/lib/mysql/data - Datastore for MySQL
#    /var/lib/mysql/init - Folder to load *.sql scripts
# Environment:
#  * $MYSQL_USER - Database user name
#  * $MYSQL_PASSWORD - User's password
#  * $MYSQL_DATABASE - Name of the database to create
#  * $MYSQL_ROOT_PASSWORD (Optional) - Password for the 'root' MySQL account

ADD root /
[student@workstation mysql]$ podman build -t do180-mysql-80-rhel8 .
STEP 1/4: FROM registry.redhat.io/rhel8/mysql-80:1
STEP 2/4: MAINTAINER username <username@example.com>
--> Using cache 9bbf8c0131b2e3fc9afcd20824c3f1d900053cec76b91ae03e6851ac2246a450
--> 9bbf8c0131b
STEP 3/4: RUN echo "default_authentication_plugin = mysql_native_password" >> /etc/my.cnf
--> Using cache 2317d0ccc0e662fbe5ffedb950e037f1eacb180cbc83dd546a71d8feda242da7
--> 2317d0ccc0e
STEP 4/4: ADD root /
--> Using cache e098971e846d72c626e26f8c0ef7c7035d4d8358e2786978db696ac98128447a
COMMIT do180-mysql-80-rhel8
--> e098971e846
Successfully tagged localhost/do180-mysql-80-rhel8:latest
Successfully tagged quay.io/veeraabose/do180-mysql-80-rhel8:latest
e098971e846d72c626e26f8c0ef7c7035d4d8358e2786978db696ac98128447a
[student@workstation mysql]$ oc get images
Error from server (Forbidden): images.image.openshift.io is forbidden: User "developer" cannot list resource "images" in API group "image.openshift.io" at the cluster scope
[student@workstation mysql]$ podman login quay.io -u ${RHT_OCP4_QUAY_USER}
Password: 
Login Succeeded!
[student@workstation mysql]$ podman images
REPOSITORY                               TAG         IMAGE ID      CREATED       SIZE
localhost/do180-quote-php                latest      7da0ae1dbf13  11 hours ago  278 MB
quay.io/veeraabose/do180-quote-php       latest      7da0ae1dbf13  11 hours ago  278 MB
localhost/do180-mysql-80-rhel8           latest      e098971e846d  11 hours ago  619 MB
quay.io/veeraabose/do180-mysql-80-rhel8  latest      e098971e846d  11 hours ago  619 MB
registry.redhat.io/rhel8/mysql-80        1           b5b029803361  8 days ago    619 MB
registry.access.redhat.com/ubi8/ubi      latest      10f854072e7e  5 weeks ago   227 MB
[student@workstation mysql]$ podman tag do180-mysql-80-rhel8 quay.io/${RHT_OCP4_QUAY_USER}/do180-mysql-80-rhel8
[student@workstation mysql]$ quay.io/veeraabose/do180-mysql-80-rhel8
bash: quay.io/veeraabose/do180-mysql-80-rhel8: No such file or directory
[student@workstation mysql]$ podman push quay.io/${RHT_OCP4_QUAY_USER}/do180-mysql-80-rhel8
Getting image source signatures
Copying blob 55d990a50708 skipped: already exists  
Copying blob 66a040e73ac3 skipped: already exists  
Copying blob 742ded26f924 skipped: already exists  
Copying blob 5863c9bfd6af skipped: already exists  
Copying blob 23e15b9ab3f0 skipped: already exists  
Copying blob b38cb9259677 skipped: already exists  
Copying config e098971e84 done  
Writing manifest to image destination
Storing signatures
[student@workstation mysql]$ cd ~/DO180/labs/multicontainer-review
[student@workstation multicontainer-review]$ cd images/quote-php
[student@workstation quote-php]$ cat Containerfile 
FROM registry.access.redhat.com/ubi8/ubi

RUN yum --disableplugin=subscription-manager -y module enable php:7.2 \
  && yum --disableplugin=subscription-manager -y install httpd php php-mysqlnd \
  && yum --disableplugin=subscription-manager clean all

ADD index.php /var/www/html

RUN sed -i 's/Listen 80/Listen 8080/' /etc/httpd/conf/httpd.conf \
  && sed -i 's/variables_order = "GPCS"/variables_order = "EGPCS"/' /etc/php.ini \
  && sed -i 's/;clear_env/clear_env/' /etc/php-fpm.d/www.conf  \
  && mkdir /run/php-fpm \
  && chgrp -R 0 /var/log/httpd /var/run/httpd /run/php-fpm \
  && chmod -R g=u /var/log/httpd /var/run/httpd /run/php-fpm

EXPOSE 8080

USER 1001

CMD php-fpm & httpd -D FOREGROUND[student@workstation quote-php]$ podman build -t do180-quote-php .
STEP 1/7: FROM registry.access.redhat.com/ubi8/ubi
STEP 2/7: RUN yum --disableplugin=subscription-manager -y module enable php:7.2   && yum --disableplugin=subscription-manager -y install httpd php php-mysqlnd   && yum --disableplugin=subscription-manager clean all
--> Using cache 07f7691238d3cb27b8023159b4d861f6b21d3071ba54bf648d2a2b74977843b7
--> 07f7691238d
STEP 3/7: ADD index.php /var/www/html
--> Using cache fcd1d2680c37cc7280473ea07111b98e6a5328d396b220273673ebcaac0ad5e6
--> fcd1d2680c3
STEP 4/7: RUN sed -i 's/Listen 80/Listen 8080/' /etc/httpd/conf/httpd.conf   && sed -i 's/variables_order = "GPCS"/variables_order = "EGPCS"/' /etc/php.ini   && sed -i 's/;clear_env/clear_env/' /etc/php-fpm.d/www.conf    && mkdir /run/php-fpm   && chgrp -R 0 /var/log/httpd /var/run/httpd /run/php-fpm   && chmod -R g=u /var/log/httpd /var/run/httpd /run/php-fpm
--> Using cache b6333ad3b93e5c01ef2076e4798321b5c97b9cfd59217fdfd3d0bee786711d32
--> b6333ad3b93
STEP 5/7: EXPOSE 8080
--> Using cache 638f023e352c508e9b769b36ea7be4e7644472dc264ae91cd67ab5a6d3904535
--> 638f023e352
STEP 6/7: USER 1001
--> Using cache ab99443cead3c77566e05154c486f75f646513672d658e3a3de33d9285ba2721
--> ab99443cead
STEP 7/7: CMD php-fpm & httpd -D FOREGROUND
--> Using cache 7da0ae1dbf134110a0c90ac752afb74c62fc72b8c0249e0682a8ceda27ea809e
COMMIT do180-quote-php
--> 7da0ae1dbf1
Successfully tagged localhost/do180-quote-php:latest
Successfully tagged quay.io/veeraabose/do180-quote-php:latest
7da0ae1dbf134110a0c90ac752afb74c62fc72b8c0249e0682a8ceda27ea809e
[student@workstation quote-php]$ podman tag do180-quote-php quay.io/${RHT_OCP4_QUAY_USER}/do180-quote-php
[student@workstation quote-php]$ podman push quay.io/${RHT_OCP4_QUAY_USER}/do180-quote-php
Getting image source signatures
Copying blob b44d85c56b38 skipped: already exists  
Copying blob 582c3b5b156b skipped: already exists  
Copying blob a72a2eb4d390 skipped: already exists  
Copying blob 23e15b9ab3f0 skipped: already exists  
Copying blob b38cb9259677 skipped: already exists  
Copying config 7da0ae1dbf done  
Writing manifest to image destination
Storing signatures
[student@workstation quote-php]$ cd ~/DO180/labs/multicontainer-review
[student@workstation multicontainer-review]$ cat 
images/                  quote-php-template.json  
[student@workstation multicontainer-review]$ cat 
images/                  quote-php-template.json  
[student@workstation multicontainer-review]$ cat cat quote-php-template.json 
cat: cat: No such file or directory
{
  "kind": "Template",
  "apiVersion": "template.openshift.io/v1",
  "metadata": {
    "name": "quote-php-persistent",
    "annotations": {
      "openshift.io/display-name": "Quote PHP Application and MySQL 8"
    }
  },
  "message": "",
  "labels": {
    "template": "quote-php-mysql-persistent-template",
    "app": "quote-php"
  },
  "objects": [
    {
      "apiVersion": "v1",
      "kind": "Pod",
      "metadata": {
        "name": "mysql",
        "labels": {
          "name": "mysql"
        }
      },
      "spec": {
        "containers": [
          {
            "image": "quay.io/${RHT_OCP4_QUAY_USER}/do180-mysql-80-rhel8",
            "name": "mysql",
            "env": [
              {
                "name": "MYSQL_ROOT_PASSWORD",
                "value": "r00tpa55"
              },
              {
                "name": "MYSQL_USER",
                "value": "user1"
              },
              {
                "name": "MYSQL_PASSWORD",
                "value": "mypa55"
              },
              {
                "name": "MYSQL_DATABASE",
                "value": "quotes"
              }
            ],
            "ports": [
              {
                "containerPort": 3306,
                "name": "mysql"
              }
            ],
            "volumeMounts": [
              {
                "mountPath": "/var/lib/mysql/data",
                "name": "db-volume"
              },
              {
                "mountPath": "/var/lib/mysql/init",
                "name": "db-init"
              }
            ]
          }
        ],
        "volumes": [
          {
            "name": "db-volume",
            "persistentVolumeClaim": {
              "claimName": "dbclaim"
            }
          },
          {
            "name": "db-init",
            "persistentVolumeClaim": {
              "claimName": "dbinit"
            }
          }
        ]
      }
    },
    {
      "apiVersion": "v1",
      "kind": "Pod",
      "metadata": {
        "name": "quote-php",
        "labels": {
          "name": "quote-php"
        }
      },
      "spec": {
        "containers": [
          {
            "resources": {
              "limits" : {
                "cpu": "0.5"
              }
            },
            "image": "quay.io/${RHT_OCP4_QUAY_USER}/do180-quote-php",
            "name": "quote-php",
            "ports": [
              {
                "containerPort": 8080,
                "name": "php-http"
              }
            ],
            "env": [
              {
                "name": "MYSQL_ENV_MYSQL_DATABASE",
                "value": "items"
              },
              {
                "name": "MYSQL_ENV_MYSQL_USER",
                "value": "user1"
              },
              {
                "name": "MYSQL_ENV_MYSQL_PASSWORD",
                "value": "mypa55"
              }
            ]
          }
        ]
      }
    },
    {
      "apiVersion": "v1",
      "kind": "Service",
      "metadata": {
        "labels": {
          "name": "quote-php"
        },
        "name": "quote-php"
      },
      "spec": {
        "ports": [
          {
            "port": 8080
          }
        ],
        "selector": {
          "name": "quote-php"
        }
      }
    },
    {
      "apiVersion": "v1",
      "kind": "Service",
      "metadata": {
        "labels": {
          "name": "mysql"
        },
        "name": "mysql"
      },
      "spec": {
        "ports": [
          {
            "port": 3306
          }
        ],
        "selector": {
          "name": "mysql"
        }
      }
    },
    {
      "kind": "PersistentVolumeClaim",
      "apiVersion": "v1",
      "metadata": {
        "name": "dbinit"
      },
      "spec": {
        "accessModes": [
          "ReadWriteOnce"
        ],
        "resources": {
          "requests": {
            "storage": "1Mi"
          }
        }
      }
    },
    {
      "kind": "PersistentVolumeClaim",
      "apiVersion": "v1",
      "metadata": {
        "name": "dbclaim"
      },
      "spec": {
        "accessModes": [
          "ReadWriteOnce"
        ],
        "resources": {
          "requests": {
            "storage": "10Mi"
          }
        }
      }
    }
  ],
  "parameters": [
    {
      "description": "Quay namespace the images are stored in",
      "name": "RHT_OCP4_QUAY_USER",
      "required": true
    }
  ]
}
[student@workstation multicontainer-review]$ oc create -f quote-php-template.json
template.template.openshift.io/quote-php-persistent created
[student@workstation multicontainer-review]$ oc process quote-php-persistent -p RHT_OCP4_QUAY_USER=${RHT_OCP4_QUAY_USER} | oc create -f -
pod/mysql created
pod/quote-php created
service/quote-php created
service/mysql created
persistentvolumeclaim/dbinit created
persistentvolumeclaim/dbclaim created
[student@workstation multicontainer-review]$ oc get pods -w
NAME        READY   STATUS             RESTARTS   AGE
mysql       0/1     ImagePullBackOff   0          26s
quote-php   0/1     ImagePullBackOff   0          26s
quote-php   0/1     ErrImagePull       0          29s
mysql       0/1     ErrImagePull       0          34s
quote-php   0/1     ImagePullBackOff   0          41s
mysql       0/1     ImagePullBackOff   0          47s
quote-php   0/1     ErrImagePull       0          55s
mysql       0/1     ErrImagePull       0          62s
quote-php   0/1     ImagePullBackOff   0          68s
mysql       0/1     ImagePullBackOff   0          73s
quote-php   0/1     ErrImagePull       0          96s
quote-php   0/1     ImagePullBackOff   0          111s
^C[student@workstation multicontainer-review]$ oc get pods -w
NAME        READY   STATUS             RESTARTS   AGE
mysql       0/1     ImagePullBackOff   0          2m31s
quote-php   0/1     ImagePullBackOff   0          2m31s
^C[student@workstation multicontainer-review]$ podman pull quay.io/${RHT_OCP4_QUAY_USER}/do180-quote-php
Trying to pull quay.io/veeraabose/do180-quote-php:latest...
Getting image source signatures
Copying blob 2d277c581f0b skipped: already exists  
Copying blob 6ccad2a77f3f skipped: already exists  
Copying blob 3d185440f04a skipped: already exists  
Copying blob 21dbc25c21f4 skipped: already exists  
Copying blob 0b8b5d0c8345 skipped: already exists  
Copying config 7da0ae1dbf done  
Writing manifest to image destination
Storing signatures
7da0ae1dbf134110a0c90ac752afb74c62fc72b8c0249e0682a8ceda27ea809e
[student@workstation multicontainer-review]$ podman images
REPOSITORY                               TAG         IMAGE ID      CREATED       SIZE
quay.io/veeraabose/do180-quote-php       latest      7da0ae1dbf13  11 hours ago  278 MB
localhost/do180-quote-php                latest      7da0ae1dbf13  11 hours ago  278 MB
localhost/do180-mysql-80-rhel8           latest      e098971e846d  11 hours ago  619 MB
quay.io/veeraabose/do180-mysql-80-rhel8  latest      e098971e846d  11 hours ago  619 MB
registry.redhat.io/rhel8/mysql-80        1           b5b029803361  8 days ago    619 MB
registry.access.redhat.com/ubi8/ubi      latest      10f854072e7e  5 weeks ago   227 MB
[student@workstation multicontainer-review]$ oc events
error: unknown command "events" for "oc"
[student@workstation multicontainer-review]$ ls -lhrt
total 8.0K
-rw-rw-r--. 1 student student 4.4K Aug  8 14:21 quote-php-template.json
drwxrwxr-x. 4 student student   71 Aug  8 14:21 images
[student@workstation multicontainer-review]$ less quote-php-template.json 
[student@workstation multicontainer-review]$ oc get pods
NAME        READY   STATUS             RESTARTS   AGE
mysql       0/1     ImagePullBackOff   0          4m10s
quote-php   0/1     ImagePullBackOff   0          4m10s
[student@workstation multicontainer-review]$ oc get all
NAME            READY   STATUS             RESTARTS   AGE
pod/mysql       0/1     ImagePullBackOff   0          5m24s
pod/quote-php   0/1     ImagePullBackOff   0          5m24s

NAME                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/mysql       ClusterIP   172.30.128.223   <none>        3306/TCP   5m24s
service/quote-php   ClusterIP   172.30.173.40    <none>        8080/TCP   5m24s
[student@workstation multicontainer-review]$ oc expose svc quote-php
route.route.openshift.io/quote-php exposed
[student@workstation multicontainer-review]$ oc get route
NAME        HOST/PORT                                          PATH   SERVICES    PORT   TERMINATION   WILDCARD
quote-php   quote-php-developer-deploy.apps.ocp4.example.com          quote-php   8080                 None
[student@workstation multicontainer-review]$ curl -w "\n" http://quote-php-${RHT_OCP4_DEV_USER}-deploy.${RHT_OCP4_WILDCARD_DOMAIN}
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <style type="text/css">
      body {
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
        line-height: 1.66666667;
        font-size: 16px;
        color: #333;
        background-color: #fff;
        margin: 2em 1em;
      }
      h1 {
        font-size: 28px;
        font-weight: 400;
      }
      p {
        margin: 0 0 10px;
      }
      .alert.alert-info {
        background-color: #F0F0F0;
        margin-top: 30px;
        padding: 30px;
      }
      .alert p {
        padding-left: 35px;
      }
      ul {
        padding-left: 51px;
        position: relative;
      }
      li {
        font-size: 14px;
        margin-bottom: 1em;
      }
      p.info {
        position: relative;
        font-size: 20px;
      }
      p.info:before, p.info:after {
        content: "";
        left: 0;
        position: absolute;
        top: 0;
      }
      p.info:before {
        background: #0066CC;
        border-radius: 16px;
        color: #fff;
        content: "i";
        font: bold 16px/24px serif;
        height: 24px;
        left: 0px;
        text-align: center;
        top: 4px;
        width: 24px;
      }

      @media (min-width: 768px) {
        body {
          margin: 6em;
        }
      }
    </style>
  </head>
  <body>
    <div>
      <h1>Application is not available</h1>
      <p>The application is currently not serving requests at this endpoint. It may not have been started or is still starting.</p>

      <div class="alert alert-info">
        <p class="info">
          Possible reasons you are seeing this page:
        </p>
        <ul>
          <li>
            <strong>The host doesn't exist.</strong>
            Make sure the hostname was typed correctly and that a route matching this hostname exists.
          </li>
          <li>
            <strong>The host exists, but doesn't have a matching path.</strong>
            Check if the URL path was typed correctly and that the route was created using the desired path.
          </li>
          <li>
            <strong>Route and path matches, but all pods are down.</strong>
            Make sure that the resources exposed by this route (pods, services, deployment configs, etc) have at least one pod running.
          </li>
        </ul>
      </div>
    </div>
  </body>
</html>

[student@workstation multicontainer-review]$ 
-----------------------------------------------Deploying Multi-Container Applications -- END ---------------

Summary
In this chapter, you learned:
• Software-defined networks enable communication between containers. Containers must be
attached to the same software-defined network to communicate.
• Containerized applications cannot rely on fixed IP addresses or host names to find services.
• Podman uses Container Network Interface (CNI) to create a software-defined network and
attaches all containers on the host to that network. Kubernetes and OpenShift create a
software-defined network between all containers in a pod.
• Within the same project, Kubernetes injects a set of variables for each service into all pods.
• OpenShift templates automate creating applications consisting of multiple resources. Template
parameters allow using the same values when creating multiple resources.


---------------------------------------------------------13oct22-------------------------------------
CH-9 GE-Troubleshooting OpenShift Clusters and Applications
[student@workstation ~]$ lab install-troubleshoot start

Checking prerequisites for Guided Exercise: Troubleshooting OpenShift Clusters and Applications

 Preparing the student's workstation:
 · Download exercise files.....................................  SUCCESS
 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'install-troubleshoot' project is absent................  SUCCESS

Setting up the classroom for Guided Exercise: Troubleshooting OpenShift Clusters and Applications

 Restoring authentication settings to installation defaults:
 · Removing 'cluster-admin' role from the 'admin' user.........  SUCCESS
 · Remove HTPasswd secret: 'htpasswd-secret'...................  SUCCESS
 · Remove all configured Identity Providers....................  SUCCESS
 · Remove all existing users...................................  SUCCESS
 · Remove all existing identities..............................  SUCCESS
 Preparing the exercise:
 · Create project 'install-troubleshoot'.......................  SUCCESS
 · Deploy PostgreSQL in 'install-troubleshoot'.................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ oc login -u kubeadmin -p ${RHT_OCP4_KUBEADM_PASSWD} https://api.ocp4.example.com:6443
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "developer-deploy".
[student@workstation ~]$ oc get nodes
NAME       STATUS   ROLES           AGE   VERSION
master01   Ready    master,worker   77d   v1.23.3+e419edf
master02   Ready    master,worker   77d   v1.23.3+e419edf
master03   Ready    master,worker   77d   v1.23.3+e419edf
[student@workstation ~]$ oc adm top node
NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
master01   535m         15%    6282Mi          42%       
master02   599m         17%    5873Mi          39%       
master03   937m         26%    9133Mi          61%       
[student@workstation ~]$ oc describe node master01
Name:               master01
Roles:              master,worker
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=master01
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/master=
                    node-role.kubernetes.io/worker=
                    node.openshift.io/os_id=rhcos
Annotations:        machineconfiguration.openshift.io/controlPlaneTopology: HighlyAvailable
                    machineconfiguration.openshift.io/currentConfig: rendered-master-dac1e919b294c370b32172cffe4ba8e9
                    machineconfiguration.openshift.io/desiredConfig: rendered-master-dac1e919b294c370b32172cffe4ba8e9
                    machineconfiguration.openshift.io/reason: 
                    machineconfiguration.openshift.io/state: Done
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Thu, 28 Jul 2022 12:11:26 -0400
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  master01
  AcquireTime:     <unset>
  RenewTime:       Thu, 13 Oct 2022 13:44:58 -0400
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Thu, 13 Oct 2022 13:40:41 -0400   Thu, 28 Jul 2022 12:45:30 -0400   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Thu, 13 Oct 2022 13:40:41 -0400   Thu, 28 Jul 2022 12:45:30 -0400   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Thu, 13 Oct 2022 13:40:41 -0400   Thu, 28 Jul 2022 12:45:30 -0400   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Thu, 13 Oct 2022 13:40:41 -0400   Wed, 12 Oct 2022 00:38:53 -0400   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.50.10
  Hostname:    master01
Capacity:
  cpu:                4
  ephemeral-storage:  41407468Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             16409340Ki
  pods:               250
Allocatable:
  cpu:                3500m
  ephemeral-storage:  38161122446
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             15258364Ki
  pods:               250
System Info:
  Machine ID:                             5a24320e1fb84806a18b8cbc6b6ffc87
  System UUID:                            0f26ca2d-1b85-4908-bc4e-21c45cb2f177
  Boot ID:                                0166c6b1-b9df-428d-8c2d-a2518d45495d
  Kernel Version:                         4.18.0-305.34.2.el8_4.x86_64
  OS Image:                               Red Hat Enterprise Linux CoreOS 410.84.202202251620-0 (Ootpa)
  Operating System:                       linux
  Architecture:                           amd64
  Container Runtime Version:              cri-o://1.23.1-9.rhaos4.10.gitbdffb9a.el8
  Kubelet Version:                        v1.23.3+e419edf
  Kube-Proxy Version:                     v1.23.3+e419edf
Non-terminated Pods:                      (32 in total)
  Namespace                               Name                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                               ----                                       ------------  ----------  ---------------  -------------  ---
  common                                  nexus-1-b8w47                              0 (0%)        0 (0%)      512Mi (3%)       2Gi (13%)      76d
  developer-deploy                        mysql                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         24h
  developer-deploy                        quote-php                                  500m (14%)    500m (14%)  0 (0%)           0 (0%)         24h
  openshift-apiserver                     apiserver-678b596447-t64mg                 110m (3%)     0 (0%)      250Mi (1%)       0 (0%)         77d
  openshift-authentication                oauth-openshift-bbb74db59-txvhg            10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         3m48s
  openshift-cluster-node-tuning-operator  tuned-xxj7j                                10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         77d
  openshift-controller-manager            controller-manager-bzvmm                   100m (2%)     0 (0%)      100Mi (0%)       0 (0%)         14d
  openshift-dns                           dns-default-7h288                          60m (1%)      0 (0%)      110Mi (0%)       0 (0%)         77d
  openshift-dns                           node-resolver-9756h                        5m (0%)       0 (0%)      21Mi (0%)        0 (0%)         77d
  openshift-etcd                          etcd-master01                              400m (11%)    0 (0%)      930Mi (6%)       0 (0%)         77d
  openshift-etcd                          etcd-quorum-guard-7d8dc4bd99-pql5k         10m (0%)      0 (0%)      5Mi (0%)         0 (0%)         77d
  openshift-image-registry                node-ca-94wbj                              10m (0%)      0 (0%)      10Mi (0%)        0 (0%)         77d
  openshift-ingress-canary                ingress-canary-wt7bx                       10m (0%)      0 (0%)      20Mi (0%)        0 (0%)         77d
  openshift-kube-apiserver                kube-apiserver-guard-master01              10m (0%)      0 (0%)      5Mi (0%)         0 (0%)         77d
  openshift-kube-apiserver                kube-apiserver-master01                    290m (8%)     0 (0%)      1224Mi (8%)      0 (0%)         14d
  openshift-kube-controller-manager       kube-controller-manager-guard-master01     10m (0%)      0 (0%)      5Mi (0%)         0 (0%)         77d
  openshift-kube-controller-manager       kube-controller-manager-master01           80m (2%)      0 (0%)      500Mi (3%)       0 (0%)         77d
  openshift-kube-scheduler                openshift-kube-scheduler-guard-master01    10m (0%)      0 (0%)      5Mi (0%)         0 (0%)         77d
  openshift-kube-scheduler                openshift-kube-scheduler-master01          25m (0%)      0 (0%)      150Mi (1%)       0 (0%)         77d
  openshift-machine-config-operator       machine-config-daemon-r4tg7                40m (1%)      0 (0%)      100Mi (0%)       0 (0%)         77d
  openshift-machine-config-operator       machine-config-server-gvm88                20m (0%)      0 (0%)      50Mi (0%)        0 (0%)         77d
  openshift-marketplace                   do285-catalog-jn2jm                        10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         76d
  openshift-monitoring                    node-exporter-jg7xm                        9m (0%)       0 (0%)      47Mi (0%)        0 (0%)         77d
  openshift-monitoring                    prometheus-adapter-59f98c64fc-6f2hc        1m (0%)       0 (0%)      40Mi (0%)        0 (0%)         14d
  openshift-multus                        multus-additional-cni-plugins-hgmg8        10m (0%)      0 (0%)      10Mi (0%)        0 (0%)         77d
  openshift-multus                        multus-admission-controller-dkfhb          20m (0%)      0 (0%)      70Mi (0%)        0 (0%)         77d
  openshift-multus                        multus-fcsvm                               10m (0%)      0 (0%)      65Mi (0%)        0 (0%)         77d
  openshift-multus                        network-metrics-daemon-pk985               20m (0%)      0 (0%)      120Mi (0%)       0 (0%)         77d
  openshift-network-diagnostics           network-check-target-kvczc                 10m (0%)      0 (0%)      15Mi (0%)        0 (0%)         77d
  openshift-oauth-apiserver               apiserver-d4dddf5fc-tjz9h                  150m (4%)     0 (0%)      200Mi (1%)       0 (0%)         77d
  openshift-sdn                           sdn-controller-cvdj2                       20m (0%)      0 (0%)      70Mi (0%)        0 (0%)         77d
  openshift-sdn                           sdn-z8csz                                  110m (3%)     0 (0%)      220Mi (1%)       0 (0%)         77d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests      Limits
  --------           --------      ------
  cpu                2080m (59%)   500m (14%)
  memory             5004Mi (33%)  2Gi (13%)
  ephemeral-storage  0 (0%)        0 (0%)
  hugepages-1Gi      0 (0%)        0 (0%)
  hugepages-2Mi      0 (0%)        0 (0%)
Events:
  Type     Reason                   Age                    From     Message
  ----     ------                   ----                   ----     -------
  Normal   Starting                 77d                    kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  77d                    kubelet  Updated Node Allocatable limit across pods
  Normal   NodeReady                77d                    kubelet  Node master01 status is now: NodeReady
  Normal   NodeNotSchedulable       77d                    kubelet  Node master01 status is now: NodeNotSchedulable
  Normal   NodeHasNoDiskPressure    77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientMemory  77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   Starting                 77d                    kubelet  Starting kubelet.
  Normal   NodeHasSufficientPID     77d (x2 over 77d)      kubelet  Node master01 status is now: NodeHasSufficientPID
  Warning  Rebooted                 77d                    kubelet  Node master01 has been rebooted, boot id: b20dcdba-b64a-4f8b-9d4d-acf2ee0849cc
  Normal   NodeNotReady             77d                    kubelet  Node master01 status is now: NodeNotReady
  Normal   NodeNotSchedulable       77d                    kubelet  Node master01 status is now: NodeNotSchedulable
  Normal   NodeAllocatableEnforced  77d                    kubelet  Updated Node Allocatable limit across pods
  Normal   NodeReady                77d                    kubelet  Node master01 status is now: NodeReady
  Normal   NodeSchedulable          77d                    kubelet  Node master01 status is now: NodeSchedulable
  Normal   NodeAllocatableEnforced  76d                    kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 76d                    kubelet  Starting kubelet.
  Normal   NodeHasNoDiskPressure    76d (x8 over 76d)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     76d (x7 over 76d)      kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeHasSufficientMemory  76d (x8 over 76d)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   Starting                 7d2h                   kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  7d2h (x8 over 7d2h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    7d2h (x8 over 7d2h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     7d2h (x7 over 7d2h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  7d2h                   kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 7d1h                   kubelet  Starting kubelet.
  Normal   NodeAllocatableEnforced  7d1h                   kubelet  Updated Node Allocatable limit across pods
  Normal   NodeHasNoDiskPressure    7d1h (x8 over 7d1h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     7d1h (x7 over 7d1h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeHasSufficientMemory  7d1h (x8 over 7d1h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   Starting                 7d1h                   kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  7d1h (x8 over 7d1h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    7d1h (x8 over 7d1h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     7d1h (x7 over 7d1h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  7d1h                   kubelet  Updated Node Allocatable limit across pods
  Normal   NodeHasSufficientMemory  4d1h (x8 over 4d1h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    4d1h (x8 over 4d1h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     4d1h (x7 over 4d1h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  4d1h                   kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 4d1h                   kubelet  Starting kubelet.
  Normal   NodeAllocatableEnforced  3d12h                  kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 3d12h                  kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  3d12h (x8 over 3d12h)  kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasSufficientPID     3d12h (x7 over 3d12h)  kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeHasNoDiskPressure    3d12h (x8 over 3d12h)  kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   Starting                 3d1h                   kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  3d1h (x8 over 3d1h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    3d1h (x8 over 3d1h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     3d1h (x7 over 3d1h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  3d1h                   kubelet  Updated Node Allocatable limit across pods
  Normal   NodeAllocatableEnforced  2d1h                   kubelet  Updated Node Allocatable limit across pods
  Normal   NodeHasSufficientMemory  2d1h (x8 over 2d1h)    kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   Starting                 2d1h                   kubelet  Starting kubelet.
  Normal   NodeHasSufficientPID     2d1h (x7 over 2d1h)    kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeHasNoDiskPressure    2d1h (x8 over 2d1h)    kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientMemory  37h (x8 over 37h)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    37h (x8 over 37h)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     37h (x7 over 37h)      kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  37h                    kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 37h                    kubelet  Starting kubelet.
  Normal   NodeHasSufficientPID     25h (x7 over 25h)      kubelet  Node master01 status is now: NodeHasSufficientPID
  Normal   NodeAllocatableEnforced  25h                    kubelet  Updated Node Allocatable limit across pods
  Normal   NodeHasSufficientMemory  25h (x8 over 25h)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    25h (x8 over 25h)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   Starting                 25h                    kubelet  Starting kubelet.
  Normal   NodeAllocatableEnforced  42m                    kubelet  Updated Node Allocatable limit across pods
  Normal   Starting                 42m                    kubelet  Starting kubelet.
  Normal   NodeHasSufficientMemory  42m (x8 over 42m)      kubelet  Node master01 status is now: NodeHasSufficientMemory
  Normal   NodeHasNoDiskPressure    42m (x8 over 42m)      kubelet  Node master01 status is now: NodeHasNoDiskPressure
  Normal   NodeHasSufficientPID     42m (x7 over 42m)      kubelet  Node master01 status is now: NodeHasSufficientPID
[student@workstation ~]$ oc get pod -n openshift-image-registry
NAME                                               READY   STATUS    RESTARTS   AGE
cluster-image-registry-operator-6f7784dc86-hbhq9   1/1     Running   12         77d
image-registry-589dbd88dd-wld7p                    1/1     Running   12         77d
node-ca-94wbj                                      1/1     Running   13         77d
node-ca-fzrm2                                      1/1     Running   13         77d
node-ca-xxn6f                                      1/1     Running   13         77d
[student@workstation ~]$ oc logs --tail 3 -n openshift-image-registry cluster-image-registry-operator-564bd5dd8f-s46bz
Error from server (NotFound): pods "cluster-image-registry-operator-564bd5dd8f-s46bz" not found
[student@workstation ~]$ oc logs --tail 3 -n openshift-image-registry cluster-image-registry-operator-6f7784dc86-hbhq9
I1013 17:47:25.564857       1 generator.go:60] object *v1.DaemonSet, Namespace=openshift-image-registry, Name=node-ca updated: 
I1013 17:47:25.574638       1 recorder_logging.go:44] &Event{ObjectMeta:{dummy.171db21630cabcf4  dummy    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] []  []},InvolvedObject:ObjectReference{Kind:Pod,Namespace:dummy,Name:dummy,UID:,APIVersion:v1,ResourceVersion:,FieldPath:,},Reason:DaemonSetUpdated,Message:Updated DaemonSet.apps/node-ca -n openshift-image-registry because it changed,Source:EventSource{Component:,Host:,},FirstTimestamp:2022-10-13 17:47:25.574569204 +0000 UTC m=+2548.813628627,LastTimestamp:2022-10-13 17:47:25.574569204 +0000 UTC m=+2548.813628627,Count:1,Type:Normal,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:,ReportingInstance:,}
I1013 17:47:25.575367       1 generator.go:60] object *v1.DaemonSet, Namespace=openshift-image-registry, Name=node-ca updated: 
[student@workstation ~]$ oc logs --tail 1 -n openshift-image-registry image-registry-589dbd88dd-wld7p
time="2022-10-13T17:49:13.910077433Z" level=info msg=response go.version=go1.17.5 http.request.host="10.8.0.9:5000" http.request.id=ef2898e0-5d79-44db-8eef-73d8a8028ddf http.request.method=GET http.request.remoteaddr="10.8.0.1:36368" http.request.uri=/healthz http.request.useragent=kube-probe/1.23 http.response.duration="42.283µs" http.response.status=200 http.response.written=0
[student@workstation ~]$ oc adm node-logs --tail 1 -u kubelet master01
-- Logs begin at Thu 2022-07-28 16:08:57 UTC, end at Thu 2022-10-13 17:50:12 UTC. --
Oct 12 18:10:55.363853 master01 systemd[1]: kubelet.service: Consumed 7min 6.601s CPU time
-- Logs begin at Thu 2022-07-28 16:08:57 UTC, end at Thu 2022-10-13 17:50:12 UTC. --
Oct 13 17:50:06.980222 master01 hyperkube[1807]: E1013 17:50:06.980045    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with ImagePullBackOff: \"Back-off pulling image \\\"quay.io/veeraabose/do180-mysql-80-rhel8\\\"\"" pod="developer-deploy/mysql" podUID=174436c7-71b5-45aa-a8f6-79a416e94bf6
[student@workstation ~]$ oc debug node/master01
Starting pod/master01-debug ...
To use host binaries, run `chroot /host`

chroot /host 
Pod IP: 192.168.50.10
If you don't see a command prompt, try pressing enter.

sh-4.4# sh-4.4# chroot /host
sh-4.4# systemctl status kubelet
● kubelet.service - Kubernetes Kubelet
   Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-mco-default-madv.conf, 20-logging.conf, 20-nodenet.conf
   Active: active (running) since Thu 2022-10-13 17:02:48 UTC; 48min ago
  Process: 1805 ExecStartPre=/bin/rm -f /var/lib/kubelet/memory_manager_state (code=exited, status=0/SUCCESS)
  Process: 1803 ExecStartPre=/bin/rm -f /var/lib/kubelet/cpu_manager_state (code=exited, status=0/SUCCESS)
  Process: 1801 ExecStartPre=/bin/mkdir --parents /etc/kubernetes/manifests (code=exited, status=0/SUCCESS)
 Main PID: 1807 (kubelet)
    Tasks: 22 (limit: 101964)
   Memory: 302.8M
      CPU: 2min 51.347s
   CGroup: /system.slice/kubelet.service
           └─1807 kubelet --config=/etc/kubernetes/kubelet.conf --bootstrap-kubeconfig=/etc/kubernetes/kubeconfig --kubeconfig=/var/lib/kubelet/kubeconfig --container-runtime=remote --c>

Oct 13 17:50:49 master01 hyperkube[1807]: W1013 17:50:49.484226    1807 manager.go:1176] Failed to process watch event {EventType:0 Name:/kubepods.slice/kubepods-besteffort.slice/kubepo>
Oct 13 17:50:49 master01 hyperkube[1807]: I1013 17:50:49.870590    1807 kubelet.go:2124] "SyncLoop (PLEG): event for pod" pod="developer-deploy/master01-debug" event=&{ID:2cf5e1d3-3eb1->
Oct 13 17:50:53 master01 hyperkube[1807]: E1013 17:50:53.974939    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with ImagePullB>
Oct 13 17:51:00 master01 hyperkube[1807]: E1013 17:51:00.043618    1807 remote_image.go:236] "PullImage from image service failed" err="rpc error: code = Unknown desc = reading manifest>
Oct 13 17:51:00 master01 hyperkube[1807]: E1013 17:51:00.043782    1807 kuberuntime_manager.go:919] container &Container{Name:quote-php,Image:quay.io/veeraabose/do180-quote-php,Command:>
Oct 13 17:51:00 master01 hyperkube[1807]: E1013 17:51:00.043814    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"quote-php\" with ErrIma>
Oct 13 17:51:00 master01 hyperkube[1807]: I1013 17:51:00.903697    1807 kubelet.go:2124] "SyncLoop (PLEG): event for pod" pod="developer-deploy/master01-debug" event=&{ID:2cf5e1d3-3eb1->
Oct 13 17:51:07 master01 hyperkube[1807]: E1013 17:51:07.975413    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with ImagePullB>
Oct 13 17:51:14 master01 hyperkube[1807]: E1013 17:51:14.973973    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"quote-php\" with ImageP>
Oct 13 17:51:18 master01 hyperkube[1807]: E1013 17:51:18.974828    1807 pod_workers.go:949] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"mysql\" with ImagePullB>
sh-4.4# systemctl status crio
● crio.service - Container Runtime Interface for OCI (CRI-O)
   Loaded: loaded (/usr/lib/systemd/system/crio.service; disabled; vendor preset: disabled)
  Drop-In: /etc/systemd/system/crio.service.d
           └─10-mco-default-madv.conf, 10-mco-profile-unix-socket.conf, 20-nodenet.conf
   Active: active (running) since Thu 2022-10-13 17:02:42 UTC; 48min ago
     Docs: https://github.com/cri-o/cri-o
 Main PID: 1774 (crio)
    Tasks: 35
   Memory: 5.2G
      CPU: 3min 31.859s
   CGroup: /system.slice/crio.service
           └─1774 /usr/bin/crio

Oct 13 17:51:07 master01 crio[1774]: time="2022-10-13 17:51:07.974668987Z" level=info msg="Checking image status: quay.io/veeraabose/do180-mysql-80-rhel8:latest" id=f4dc3f60-e869-40c7-8>
Oct 13 17:51:07 master01 crio[1774]: time="2022-10-13 17:51:07.974889445Z" level=info msg="Image quay.io/veeraabose/do180-mysql-80-rhel8:latest not found" id=f4dc3f60-e869-40c7-8245-a73>
Oct 13 17:51:14 master01 crio[1774]: time="2022-10-13 17:51:14.973415073Z" level=info msg="Checking image status: quay.io/veeraabose/do180-quote-php:latest" id=3ad12059-2e63-487f-b285-5>
Oct 13 17:51:14 master01 crio[1774]: time="2022-10-13 17:51:14.973672391Z" level=info msg="Image quay.io/veeraabose/do180-quote-php:latest not found" id=3ad12059-2e63-487f-b285-587dd69a>
Oct 13 17:51:18 master01 crio[1774]: time="2022-10-13 17:51:18.974232830Z" level=info msg="Checking image status: quay.io/veeraabose/do180-mysql-80-rhel8:latest" id=36effe46-aceb-493c-9>
Oct 13 17:51:18 master01 crio[1774]: time="2022-10-13 17:51:18.974565488Z" level=info msg="Image quay.io/veeraabose/do180-mysql-80-rhel8:latest not found" id=36effe46-aceb-493c-92e1-122>
Oct 13 17:51:28 master01 crio[1774]: time="2022-10-13 17:51:28.974507850Z" level=info msg="Checking image status: quay.io/veeraabose/do180-quote-php:latest" id=d1ecdff9-96c0-4c0e-a81d-8>
Oct 13 17:51:28 master01 crio[1774]: time="2022-10-13 17:51:28.974866955Z" level=info msg="Image quay.io/veeraabose/do180-quote-php:latest not found" id=d1ecdff9-96c0-4c0e-a81d-821e273e>
Oct 13 17:51:29 master01 crio[1774]: time="2022-10-13 17:51:29.973354100Z" level=info msg="Checking image status: quay.io/veeraabose/do180-mysql-80-rhel8:latest" id=3f8d40e5-1bde-4c7e-a>
Oct 13 17:51:29 master01 crio[1774]: time="2022-10-13 17:51:29.973714647Z" level=info msg="Image quay.io/veeraabose/do180-mysql-80-rhel8:latest not found" id=3f8d40e5-1bde-4c7e-a647-97c>
sh-4.4# crictl ps --name etcd          
CONTAINER           IMAGE                                                                                                                    CREATED             STATE               NAME                  ATTEMPT             POD ID
7ca0133927913       quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:fe8d01e2de1a04428b2dfd71711a6893ea84ad22890ea29ca92185705fc11f48   49 minutes ago      Running             etcd-health-monitor   13                  91c22e7abc8f3
3ea1d997a2d2d       0de0f377b0c457a2e16e7fc161782b95af27694459bf00c0066f94ad4ced9a91                                                         49 minutes ago      Running             etcd-metrics          13                  91c22e7abc8f3
83e03d55f6bcd       0de0f377b0c457a2e16e7fc161782b95af27694459bf00c0066f94ad4ced9a91                                                         49 minutes ago      Running             etcd                  13                  91c22e7abc8f3
2843dad9e79c8       0de0f377b0c457a2e16e7fc161782b95af27694459bf00c0066f94ad4ced9a91                                                         49 minutes ago      Running             etcdctl               13                  91c22e7abc8f3
sh-4.4# exit
exit
sh-4.4# exit
exit

Removing debug pod ...
[student@workstation ~]$ oc project install-troubleshoot
Now using project "install-troubleshoot" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ image-registry-589dbd88dd-wld7p
bash: image-registry-589dbd88dd-wld7p: command not found...
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS             RESTARTS   AGE
psql-768d797946-ljvj2   0/1     ImagePullBackOff   0          13m
[student@workstation ~]$ oc status
In project install-troubleshoot on server https://api.ocp4.example.com:6443

svc/psql - 172.30.120.214:5432

deployment/psql deploys registry.redhat.io/rhel8/postgresq-13:1
  deployment #1 running for 13 minutes - 0/1 pods

View details with 'oc describe <resource>/<name>' or list resources with 'oc get all'.
[student@workstation ~]$ oc get events
LAST SEEN   TYPE      REASON              OBJECT                       MESSAGE
14m         Normal    Scheduled           pod/psql-768d797946-ljvj2    Successfully assigned install-troubleshoot/psql-768d797946-ljvj2 to master02
14m         Normal    AddedInterface      pod/psql-768d797946-ljvj2    Add eth0 [10.8.0.35/23] from openshift-sdn
12m         Normal    Pulling             pod/psql-768d797946-ljvj2    Pulling image "registry.redhat.io/rhel8/postgresq-13:1"
12m         Warning   Failed              pod/psql-768d797946-ljvj2    Failed to pull image "registry.redhat.io/rhel8/postgresq-13:1": rpc error: code = Unknown desc = reading manifest 1 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found
12m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ErrImagePull
4m10s       Normal    BackOff             pod/psql-768d797946-ljvj2    Back-off pulling image "registry.redhat.io/rhel8/postgresq-13:1"
12m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ImagePullBackOff
14m         Normal    SuccessfulCreate    replicaset/psql-768d797946   Created pod: psql-768d797946-ljvj2
14m         Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-768d797946 to 1
[student@workstation ~]$ podman login registry.redhat.io
Username: veeraabose
Password: 
Login Succeeded!
[student@workstation ~]$ skopeo inspect docker://registry.redhat.io/rhel8/postgresq-13:1
FATA[0001] Error parsing image name "docker://registry.redhat.io/rhel8/postgresq-13:1": reading manifest 1 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found 
[student@workstation ~]$ oc get deploy
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
psql   0/1     1            0           16m
[student@workstation ~]$ oc edit deployment psql
deployment.apps/psql edited
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS             RESTARTS   AGE
psql-768d797946-ljvj2   0/1     ImagePullBackOff   0          17m
psql-f9957b75d-dvjwx    0/1     ErrImagePull       0          8s
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS             RESTARTS   AGE
psql-768d797946-ljvj2   0/1     ImagePullBackOff   0          17m
psql-f9957b75d-dvjwx    0/1     ErrImagePull       0          15s
[student@workstation ~]$ oc status
In project install-troubleshoot on server https://api.ocp4.example.com:6443

svc/psql - 172.30.120.214:5432

deployment/psql deploys registry.redhat.io/rhel8/postgresq-13:1-7
  deployment #2 running for 35 seconds - 0/1 pods
  deployment #1 deployed 17 minutes ago - 0/1 pods

View details with 'oc describe <resource>/<name>' or list resources with 'oc get all'.
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS             RESTARTS   AGE
psql-768d797946-ljvj2   0/1     ImagePullBackOff   0          18m
psql-f9957b75d-dvjwx    0/1     ErrImagePull       0          57s
[student@workstation ~]$ oc get events
LAST SEEN   TYPE      REASON              OBJECT                       MESSAGE
18m         Normal    Scheduled           pod/psql-768d797946-ljvj2    Successfully assigned install-troubleshoot/psql-768d797946-ljvj2 to master02
18m         Normal    AddedInterface      pod/psql-768d797946-ljvj2    Add eth0 [10.8.0.35/23] from openshift-sdn
17m         Normal    Pulling             pod/psql-768d797946-ljvj2    Pulling image "registry.redhat.io/rhel8/postgresq-13:1"
17m         Warning   Failed              pod/psql-768d797946-ljvj2    Failed to pull image "registry.redhat.io/rhel8/postgresq-13:1": rpc error: code = Unknown desc = reading manifest 1 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found
17m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ErrImagePull
3m27s       Normal    BackOff             pod/psql-768d797946-ljvj2    Back-off pulling image "registry.redhat.io/rhel8/postgresq-13:1"
16m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ImagePullBackOff
18m         Normal    SuccessfulCreate    replicaset/psql-768d797946   Created pod: psql-768d797946-ljvj2
85s         Normal    Scheduled           pod/psql-f9957b75d-dvjwx     Successfully assigned install-troubleshoot/psql-f9957b75d-dvjwx to master02
83s         Normal    AddedInterface      pod/psql-f9957b75d-dvjwx     Add eth0 [10.8.0.38/23] from openshift-sdn
43s         Normal    Pulling             pod/psql-f9957b75d-dvjwx     Pulling image "registry.redhat.io/rhel8/postgresq-13:1-7"
41s         Warning   Failed              pod/psql-f9957b75d-dvjwx     Failed to pull image "registry.redhat.io/rhel8/postgresq-13:1-7": rpc error: code = Unknown desc = reading manifest 1-7 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found
41s         Warning   Failed              pod/psql-f9957b75d-dvjwx     Error: ErrImagePull
14s         Normal    BackOff             pod/psql-f9957b75d-dvjwx     Back-off pulling image "registry.redhat.io/rhel8/postgresq-13:1-7"
14s         Warning   Failed              pod/psql-f9957b75d-dvjwx     Error: ImagePullBackOff
85s         Normal    SuccessfulCreate    replicaset/psql-f9957b75d    Created pod: psql-f9957b75d-dvjwx
18m         Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-768d797946 to 1
85s         Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-f9957b75d to 1
[student@workstation ~]$ oc edit deployment psql
deployment.apps/psql edited
[student@workstation ~]$ oc get deployment
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
psql   0/1     1            0           21m
[student@workstation ~]$ oc status
In project install-troubleshoot on server https://api.ocp4.example.com:6443

svc/psql - 172.30.120.214:5432

deployment/psql deploys registry.redhat.io/rhel8/postgresql-13:1-7
  deployment #3 running for 15 seconds - 0/1 pods
  deployment #2 deployed 4 minutes ago - 0/1 pods
  deployment #1 deployed 21 minutes ago

View details with 'oc describe <resource>/<name>' or list resources with 'oc get all'.
[student@workstation ~]$ oc get event
LAST SEEN   TYPE      REASON              OBJECT                       MESSAGE
21m         Normal    Scheduled           pod/psql-768d797946-ljvj2    Successfully assigned install-troubleshoot/psql-768d797946-ljvj2 to master02
21m         Normal    AddedInterface      pod/psql-768d797946-ljvj2    Add eth0 [10.8.0.35/23] from openshift-sdn
19m         Normal    Pulling             pod/psql-768d797946-ljvj2    Pulling image "registry.redhat.io/rhel8/postgresq-13:1"
19m         Warning   Failed              pod/psql-768d797946-ljvj2    Failed to pull image "registry.redhat.io/rhel8/postgresq-13:1": rpc error: code = Unknown desc = reading manifest 1 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found
19m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ErrImagePull
76s         Normal    BackOff             pod/psql-768d797946-ljvj2    Back-off pulling image "registry.redhat.io/rhel8/postgresq-13:1"
19m         Warning   Failed              pod/psql-768d797946-ljvj2    Error: ImagePullBackOff
21m         Normal    SuccessfulCreate    replicaset/psql-768d797946   Created pod: psql-768d797946-ljvj2
23s         Normal    SuccessfulDelete    replicaset/psql-768d797946   Deleted pod: psql-768d797946-ljvj2
22s         Normal    Scheduled           pod/psql-cdf8f86f8-nd8bc     Successfully assigned install-troubleshoot/psql-cdf8f86f8-nd8bc to master01
20s         Normal    AddedInterface      pod/psql-cdf8f86f8-nd8bc     Add eth0 [10.9.0.20/23] from openshift-sdn
20s         Normal    Pulling             pod/psql-cdf8f86f8-nd8bc     Pulling image "registry.redhat.io/rhel8/postgresql-13:1-7"
23s         Normal    SuccessfulCreate    replicaset/psql-cdf8f86f8    Created pod: psql-cdf8f86f8-nd8bc
4m13s       Normal    Scheduled           pod/psql-f9957b75d-dvjwx     Successfully assigned install-troubleshoot/psql-f9957b75d-dvjwx to master02
4m12s       Normal    AddedInterface      pod/psql-f9957b75d-dvjwx     Add eth0 [10.8.0.38/23] from openshift-sdn
2m49s       Normal    Pulling             pod/psql-f9957b75d-dvjwx     Pulling image "registry.redhat.io/rhel8/postgresq-13:1-7"
2m47s       Warning   Failed              pod/psql-f9957b75d-dvjwx     Failed to pull image "registry.redhat.io/rhel8/postgresq-13:1-7": rpc error: code = Unknown desc = reading manifest 1-7 in registry.redhat.io/rhel8/postgresq-13: unknown: Not Found
2m47s       Warning   Failed              pod/psql-f9957b75d-dvjwx     Error: ErrImagePull
2m6s        Normal    BackOff             pod/psql-f9957b75d-dvjwx     Back-off pulling image "registry.redhat.io/rhel8/postgresq-13:1-7"
2m21s       Warning   Failed              pod/psql-f9957b75d-dvjwx     Error: ImagePullBackOff
4m14s       Normal    SuccessfulCreate    replicaset/psql-f9957b75d    Created pod: psql-f9957b75d-dvjwx
21m         Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-768d797946 to 1
4m14s       Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-f9957b75d to 1
23s         Normal    ScalingReplicaSet   deployment/psql              Scaled down replica set psql-768d797946 to 0
23s         Normal    ScalingReplicaSet   deployment/psql              Scaled up replica set psql-cdf8f86f8 to 1
[student@workstation ~]$ oc get pods
NAME                   READY   STATUS    RESTARTS   AGE
psql-cdf8f86f8-nd8bc   1/1     Running   0          34s
[student@workstation ~]$ lab install-troubleshoot finish

Completing Guided Exercise: Troubleshooting OpenShift Clusters and Applications

 · Delete OpenShift project 'install-troubleshoot'.............  SUCCESS
 · Wait for project 'install-troubleshoot' to be gone..........  SUCCESS
 · Remove exercise files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
--------------------------------------------------GE-Introducing OpenShift Dynamic Storage--------------------------------
[student@workstation ~]$ lab install-storage start

Checking prerequisites for Guided Exercise: Introducing OpenShift Dynamic Storage

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'install-storage' project is absent.....................  SUCCESS

Setting up the classroom for Guided Exercise: Introducing OpenShift Dynamic Storage

 · Download exercise files.....................................  SUCCESS
 · Persistent volume claim 'postgresql-storage' is not present.  SUCCESS
 · Application 'postgres-persistent' is not present............  SUCCESS
 · Application 'postgres-persistent2' is not present...........  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ oc login -u kubeadmin -p ${RHT_OCP4_KUBEADM_PASSWD} https://api.ocp4.example.com:6443
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc new-project install-storage
Now using project "install-storage" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc get projects
NAME                                               DISPLAY NAME      STATUS
common                                                               Active
default                                                              Active
developer-deploy                                                     Active
install-storage                                                      Active
kube-node-lease                                                      Active
kube-public                                                          Active
kube-system                                                          Active
nfs-client-provisioner                             NFS Provisioner   Active
openshift                                                            Active
openshift-apiserver                                                  Active
openshift-apiserver-operator                                         Active
openshift-authentication                                             Active
openshift-authentication-operator                                    Active
openshift-cloud-controller-manager                                   Active
openshift-cloud-controller-manager-operator                          Active
openshift-cloud-credential-operator                                  Active
openshift-cloud-network-config-controller                            Active
openshift-cluster-csi-drivers                                        Active
openshift-cluster-machine-approver                                   Active
openshift-cluster-node-tuning-operator                               Active
openshift-cluster-samples-operator                                   Active
openshift-cluster-storage-operator                                   Active
openshift-cluster-version                                            Active
openshift-config                                                     Active
openshift-config-managed                                             Active
openshift-config-operator                                            Active
openshift-console                                                    Active
openshift-console-operator                                           Active
openshift-console-user-settings                                      Active
openshift-controller-manager                                         Active
openshift-controller-manager-operator                                Active
openshift-dns                                                        Active
openshift-dns-operator                                               Active
openshift-etcd                                                       Active
openshift-etcd-operator                                              Active
openshift-host-network                                               Active
openshift-image-registry                                             Active
openshift-infra                                                      Active
openshift-ingress                                                    Active
openshift-ingress-canary                                             Active
openshift-ingress-operator                                           Active
openshift-insights                                                   Active
openshift-kni-infra                                                  Active
openshift-kube-apiserver                                             Active
openshift-kube-apiserver-operator                                    Active
openshift-kube-controller-manager                                    Active
openshift-kube-controller-manager-operator                           Active
openshift-kube-scheduler                                             Active
openshift-kube-scheduler-operator                                    Active
openshift-kube-storage-version-migrator                              Active
openshift-kube-storage-version-migrator-operator                     Active
openshift-machine-api                                                Active
openshift-machine-config-operator                                    Active
openshift-marketplace                                                Active
openshift-monitoring                                                 Active
openshift-multus                                                     Active
openshift-network-diagnostics                                        Active
openshift-network-operator                                           Active
openshift-node                                                       Active
openshift-oauth-apiserver                                            Active
openshift-openstack-infra                                            Active
openshift-operator-lifecycle-manager                                 Active
openshift-operators                                                  Active
openshift-ovirt-infra                                                Active
openshift-sdn                                                        Active
openshift-service-ca                                                 Active
openshift-service-ca-operator                                        Active
openshift-user-workload-monitoring                                   Active
openshift-vsphere-infra                                              Active
[student@workstation ~]$ oc get storageclass
NAME                    PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage (default)   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  77d
[student@workstation ~]$ oc new-app --name postgresql-persistent --image registry.redhat.io/rhel8/postgresql-13:1-7 -e POSTGRESQL_USER=redhat -e POSTGRESQL_PASSWORD=redhat123 -e POSTGRESQL_DATABASE=persistentdb
--> Found container image cafc055 (17 months old) from registry.redhat.io for "registry.redhat.io/rhel8/postgresql-13:1-7"

    PostgreSQL 13 
    ------------- 
    PostgreSQL is an advanced Object-Relational database management system (DBMS). The image contains the client and server programs that you'll need to create, run, maintain and access a PostgreSQL DBMS server.

    Tags: database, postgresql, postgresql13, postgresql-13

    * An image stream tag will be created as "postgresql-persistent:1-7" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "postgresql-persistent" created
    deployment.apps "postgresql-persistent" created
    service "postgresql-persistent" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/postgresql-persistent' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc status
In project install-storage on server https://api.ocp4.example.com:6443

svc/postgresql-persistent - 172.30.228.100:5432
  deployment/postgresql-persistent deploys istag/postgresql-persistent:1-7 
    deployment #2 running for 7 seconds - 1 pod
    deployment #1 deployed 9 seconds ago


1 info identified, use 'oc status --suggest' to see details.
------------------------------------------------------------------------------------------
SC --name=sc1    provisioner: kubernetes.io/azure-disk, reclaimPolicy: Retain, volumeBindingMode: WaitForFirstConsumer, allowVolumeExpansion: true  
|
PVC ] --name=pvc1, specify storageClassName=sc1, resourc.resequest.storage = 10gi, accessModes=readwriteonce
    ]
    PV -- Automicatically created by SC
    ]
    ]
Volume - --name=V1 , pvc=pcv1 (pod configutraiton)
|
Volume mointpoint  --name=vm1, volume=v1, mountpoint=/var/lib/mysql 
---------------------------------------------------------------------------------------------
[student@workstation ~]$ oc get pods
NAME                                     READY   STATUS    RESTARTS   AGE
postgresql-persistent-7c868bc77c-p5gpz   1/1     Running   0          21s
[student@workstation ~]$ cat ~/DO280/labs/install-storage/commands.txt
# Create the postgresql-persistent deployment
oc new-app --name postgresql-persistent \
  --image registry.redhat.io/rhel8/postgresql-13:1-7 \
  -e POSTGRESQL_USER=redhat \
  -e POSTGRESQL_PASSWORD=redhat123 \
  -e POSTGRESQL_DATABASE=persistentdb


# Create a PVC and volume for the postgresql-persistent deployment
oc set volumes deployment/postgresql-persistent \
  --add --name postgresql-storage --type pvc --claim-class nfs-storage \
  --claim-mode rwo --claim-size 10Gi --mount-path /var/lib/pgsql \
  --claim-name postgresql-storage


# List persistent volumes with custom columns
oc get pv \
  -o custom-columns=NAME:.metadata.name,CLAIM:.spec.claimRef.name

# Create the postgresql-persistent2 deployment
oc new-app --name postgresql-persistent2 \
  --image registry.redhat.io/rhel8/postgresql-13:1-7 \
  -e POSTGRESQL_USER=redhat \
  -e POSTGRESQL_PASSWORD=redhat123 \
  -e POSTGRESQL_DATABASE=persistentdb


# Attach the existing PVC to the postgresql-persistent2 deployment
oc set volumes \
  deployment/postgresql-persistent2 \
  --add --name postgresql-storage --type pvc \
  --claim-name postgresql-storage --mount-path /var/lib/pgsql

[student@workstation ~]$ oc set volumes deployment/postgresql-persistent --add --name postgresql-storage --type pvc --claim-class nfs-storage --claim-mode rwo --claim-size 10Gi --mount-path /var/lib/pgsql --claim-name postgresql-storage
deployment.apps/postgresql-persistent volume updated
[student@workstation ~]$ oc get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                     STORAGECLASS   REASON   AGE
pvc-1010c4b2-da69-4190-93b4-7f299fe83f66   5Gi        RWO            Delete           Bound    common/nexus-pv                           nfs-storage             76d
pvc-554870a3-cfc1-44cb-8fc5-0def104af532   20Gi       RWX            Delete           Bound    openshift-image-registry/registry-claim   nfs-storage             77d
pvc-a2f52f65-329d-49c3-b0cd-d5b92c2b5514   10Gi       RWO            Delete           Bound    install-storage/postgresql-storage        nfs-storage             8s
pvc-aecac07b-431d-42b9-ac7a-5cd436e27abb   1Mi        RWO            Delete           Bound    developer-deploy/dbinit                   nfs-storage             25h
pvc-c340ac9a-425e-428d-bfd3-87adea21a131   10Mi       RWO            Delete           Bound    developer-deploy/dbclaim                  nfs-storage             25h
[student@workstation ~]$ oc get pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
postgresql-storage   Bound    pvc-a2f52f65-329d-49c3-b0cd-d5b92c2b5514   10Gi       RWO            nfs-storage    43s
[student@workstation ~]$ oc get pv -o custom-columns=NAME:.metadata.name,CLAIM:.spec.claimRef.name
NAME                                       CLAIM
pvc-1010c4b2-da69-4190-93b4-7f299fe83f66   nexus-pv
pvc-554870a3-cfc1-44cb-8fc5-0def104af532   registry-claim
pvc-a2f52f65-329d-49c3-b0cd-d5b92c2b5514   postgresql-storage
pvc-aecac07b-431d-42b9-ac7a-5cd436e27abb   dbinit
pvc-c340ac9a-425e-428d-bfd3-87adea21a131   dbclaim
[student@workstation ~]$ cd ~/DO280/labs/install-storage
[student@workstation install-storage]$ ./init_data.sh
Populating characters table
CREATE TABLE
INSERT 0 5
[student@workstation install-storage]$ cat init_data.s
cat: init_data.s: No such file or directory
[student@workstation install-storage]$ cat init_data.sh 
#!/bin/bash

echo "Populating characters table"
oc exec deployment.apps/postgresql-persistent -i redhat123 -- /usr/bin/psql -U redhat persistentdb < /home/student/DO280/labs/install-storage/init_data.sql

[student@workstation install-storage]$ cat check_data.sh 
#!/bin/bash

echo "Checking characters table"

if [ "$(oc get pods -o name -l deployment=postgresql-persistent)" != "" ]
then
  APP="deployment/postgresql-persistent"
elif [ "$(oc get pods -o name -l deployment=postgresql-persistent2)" != "" ]
then
  APP="deployment/postgresql-persistent2"
else
  echo "ERROR: deployment/postgresql-persistent not found"
  echo "ERROR: deployment/postgresql-persistent2 not found"
fi

if [ -n "${APP}" ]
then
  if [[ "$(oc exec ${APP} -i redhat123 -t -- /usr/bin/psql -U redhat persistentdb -c '\d characters' 2>&1)" != *"exit code 1"* ]]
  then
    OUTPUT=$(oc exec ${APP} -i redhat123 -t -- /usr/bin/psql -U redhat persistentdb -c 'select id,name,nationality from characters' 2>&1)
  fi
fi

if [ -n "${OUTPUT}" ]
then
  echo "${OUTPUT}"
else
  echo "ERROR: 'characters' table does not exist"
fi
[student@workstation install-storage]$ ./check_data.sh h
Checking characters table
 id |          name           |           nationality            
----+-------------------------+----------------------------------
  1 | Wolfgang Amadeus Mozart | Prince-Archbishopric of Salzburg
  2 | Ludwig van Beethoven    | Bonn, Germany
  3 | Johann Sebastian Bach   | Eisenach, Germany
  4 | José Pablo Moncayo     | Guadalajara, México
  5 | Niccolò Paganini       | Genoa, Italy
(5 rows)

[student@workstation install-storage]$ oc delete all -l app=postgresql-persistent
service "postgresql-persistent" deleted
deployment.apps "postgresql-persistent" deleted
imagestream.image.openshift.io "postgresql-persistent" deleted
[student@workstation install-storage]$ oc new-app --name postgresql-persistent2 --image registry.redhat.io/rhel8/postgresql-13:1-7 -e POSTGRESQL_USER=redhat -e POSTGRESQL_PASSWORD=redhat123 -e POSTGRESQL_DATABASE=persistentdb
--> Found container image cafc055 (17 months old) from registry.redhat.io for "registry.redhat.io/rhel8/postgresql-13:1-7"

    PostgreSQL 13 
    ------------- 
    PostgreSQL is an advanced Object-Relational database management system (DBMS). The image contains the client and server programs that you'll need to create, run, maintain and access a PostgreSQL DBMS server.

    Tags: database, postgresql, postgresql13, postgresql-13

    * An image stream tag will be created as "postgresql-persistent2:1-7" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "postgresql-persistent2" created
    deployment.apps "postgresql-persistent2" created
    service "postgresql-persistent2" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/postgresql-persistent2' 
    Run 'oc status' to view your app.
[student@workstation install-storage]$ ./check_data.sh 
Checking characters table
ERROR: 'characters' table does not exist
[student@workstation install-storage]$ oc set volumes deployment/postgresql-persistent2 --add --name postgresql-storage --type pvc --claim-name postgresql-storage --mount-path /var/lib/pgsql
deployment.apps/postgresql-persistent2 volume updated
[student@workstation install-storage]$ ./check_data.sh 
Checking characters table
 id |          name           |           nationality            
----+-------------------------+----------------------------------
  1 | Wolfgang Amadeus Mozart | Prince-Archbishopric of Salzburg
  2 | Ludwig van Beethoven    | Bonn, Germany
  3 | Johann Sebastian Bach   | Eisenach, Germany
  4 | José Pablo Moncayo     | Guadalajara, México
  5 | Niccolò Paganini       | Genoa, Italy
(5 rows)

[student@workstation install-storage]$ oc delete all -l app=postgresql-persistent2
service "postgresql-persistent2" deleted
deployment.apps "postgresql-persistent2" deleted
imagestream.image.openshift.io "postgresql-persistent2" deleted
[student@workstation install-storage]$ oc delete pvc/postgresql-storage
persistentvolumeclaim "postgresql-storage" deleted
[student@workstation install-storage]$ cd ~
[student@workstation ~]$ lab install-storage finish

Completing Guided Exercise: Introducing OpenShift Dynamic Storage

 · Delete OpenShift project 'install-storage'..................  SUCCESS
 · Wait for project 'install-storage' to be gone...............  SUCCESS
 · Remove exercise files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
------------------------------------------Summary-----------------------------

Summary
In this chapter, you learned:

• Red Hat OpenShift Container Platform provides two main installation methods: full-stack
automation, and pre-existing infrastructure.
• Future releases are expected to add more cloud and virtualization providers, such as VMware,
Red Hat Virtualization, and IBM System Z.
• An OpenShift node based on Red Hat Enterprise Linux CoreOS runs very few local services that
would require direct access to a node to inspect their status. Most of the system services run as
containers, the main exceptions are the CRI-O container engine and the Kubelet.
• The oc get node, oc adm top, oc adm node-logs, and oc debug commands provide
troubleshooting information about OpenShift nodes

------------------------------------------------------------------------17Oct22------------------------------------------.
GE- Configuring Identity Providers
[student@workstation ~]$ sudo su -
Last login: Wed Oct 12 01:21:42 EDT 2022 on pts/0
[root@workstation ~]# exit
logout
[student@workstation ~]$ 
[student@workstation ~]$ lab auth-provider start

Checking prerequisites for Guided Exercise: Configuring Identity Providers

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'auth-provider' project is absent.......................  SUCCESS

Setting up the classroom for Guided Exercise: Configuring Identity Providers

 Preparing the student's workstation:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS
 Restoring authentication settings to installation defaults:
 · No need to perform any change...............................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ htpasswd -c -B -b ~/DO280/labs/auth-provider/htpasswd admin redhat
Adding password for user admin
[student@workstation ~]$ htpasswd -b ~/DO280/labs/auth-provider/htpasswd developer developer
Adding password for user developer
[student@workstation ~]$ cat ~/DO280/labs/auth-provider/htpasswd
admin:$2y$05$Jho/8gbtUvtk90Qmmso0s.dI2CBpskCxbeyStVpcqkZJuv9tk/YTW
developer:$apr1$GOSucLXM$jUNwIgHD7sMOndqVDH6mj.
[student@workstation ~]$ oc login -u kubeadmin -p ${RHT_OCP4_KUBEADM_PASSWD} https://api.ocp4.example.com:6443
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc create secret generic localusers --from-file htpasswd=~/DO280/labs/auth-provider/htpasswd -n openshift-config
secret/localusers created
[student@workstation ~]$ oc adm policy add-cluster-role-to-user cluster-admin admin
Warning: User 'admin' not found
clusterrole.rbac.authorization.k8s.io/cluster-admin added: "admin"
[student@workstation ~]$ oc get oauth cluster -o yaml > ~/DO280/labs/auth-provider/oauth.yaml
[student@workstation ~]$ cd ~/DO280/solutions/
[student@workstation solutions]$ cat auth-provider/
cat: auth-provider/: Is a directory
[student@workstation solutions]$ cd auth-provider/
[student@workstation auth-provider]$ ls
oauth.yaml
[student@workstation auth-provider]$ cat oauth.yaml 
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  name: cluster
spec:
  identityProviders:
  - htpasswd:
      fileData:
        name: localusers
    mappingMethod: claim
    name: myusers
    type: HTPasswd

[student@workstation auth-provider]$ ^C
[student@workstation auth-provider]$ cat ~/DO280/labs/auth-provider/oauth.yaml
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  annotations:
    include.release.openshift.io/ibm-cloud-managed: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"config.openshift.io/v1","kind":"OAuth","metadata":{"annotations":{},"name":"cluster"},"spec":{"identityProviders":[{"challenge":true,"htpasswd":{"fileData":{"name":"htpasswd-secret"}},"login":true,"mappingMethod":"claim","name":"htpasswd_provider","type":"HTPasswd"}]}}
    release.openshift.io/create-only: "true"
  creationTimestamp: "2022-07-28T16:11:32Z"
  generation: 3
  name: cluster
  ownerReferences:
  - apiVersion: config.openshift.io/v1
    kind: ClusterVersion
    name: version
    uid: fe2b3641-43ba-4e03-8b6b-28a5696a5901
  resourceVersion: "333513"
  uid: 5177eecf-0fcf-48c0-b0cb-e2e3e7bd5f64
spec: {}
[student@workstation auth-provider]$ pwd
/home/student/DO280/solutions/auth-provider
[student@workstation auth-provider]$ oc replace -f oauth.yaml 
oauth.config.openshift.io/cluster replaced
[student@workstation auth-provider]$ oc get oauth cluster -o yaml | more
apiVersion: config.openshift.io/v1
kind: OAuth
metadata:
  creationTimestamp: "2022-07-28T16:11:32Z"
  generation: 4
  name: cluster
  resourceVersion: "379930"
  uid: 5177eecf-0fcf-48c0-b0cb-e2e3e7bd5f64
spec:
  identityProviders:
  - htpasswd:
      fileData:
        name: localusers
    mappingMethod: claim
    name: myusers
    type: HTPasswd
[student@workstation auth-provider]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation auth-provider]$ oc get nodes
NAME       STATUS   ROLES           AGE   VERSION
master01   Ready    master,worker   81d   v1.23.3+e419edf
master02   Ready    master,worker   81d   v1.23.3+e419edf
master03   Ready    master,worker   81d   v1.23.3+e419edf
[student@workstation auth-provider]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation auth-provider]$ oc get nodes
Error from server (Forbidden): nodes is forbidden: User "developer" cannot list resource "nodes" in API group "" at the cluster scope
[student@workstation auth-provider]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "developer-deploy".
[student@workstation auth-provider]$ oc get users
NAME        UID                                    FULL NAME   IDENTITIES
admin       05b3eece-a288-4c01-842f-f48201bc5481               myusers:admin
developer   a5ebc71f-01b9-430a-93bb-9411c1c5668a               myusers:developer
[student@workstation auth-provider]$ oc get identity
NAME                IDP NAME   IDP USER NAME   USER NAME   USER UID
myusers:admin       myusers    admin           admin       05b3eece-a288-4c01-842f-f48201bc5481
myusers:developer   myusers    developer       developer   a5ebc71f-01b9-430a-93bb-9411c1c5668a
[student@workstation auth-provider]$ oc extract secret/localusers -n openshift-config --to ~/DO280/labs/auth-provider/ --confirm
/home/student/DO280/labs/auth-provider/htpasswd
[student@workstation auth-provider]$ cd ~/DO280/labs/auth-provider/
[student@workstation auth-provider]$ ls
htpasswd  oauth.yaml
[student@workstation auth-provider]$ cat htpasswd 
admin:$2y$05$Jho/8gbtUvtk90Qmmso0s.dI2CBpskCxbeyStVpcqkZJuv9tk/YTW
developer:$apr1$GOSucLXM$jUNwIgHD7sMOndqVDH6mj.
[student@workstation auth-provider]$ htpasswd -b ~/DO280/labs/auth-provider/htpasswd manager redhat
Adding password for user manager
[student@workstation auth-provider]$ cat htpasswd 
admin:$2y$05$Jho/8gbtUvtk90Qmmso0s.dI2CBpskCxbeyStVpcqkZJuv9tk/YTW
developer:$apr1$GOSucLXM$jUNwIgHD7sMOndqVDH6mj.
manager:$apr1$9eGeGnmJ$.YP7OIovMKst8t5CQej.G1
[student@workstation auth-provider]$ oc set data secret/localusers --from-file htpasswd=~/DO280/labs/auth-provider/htpasswd -n openshift-config
secret/localusers data updated
[student@workstation auth-provider]$ oc login -u manager -p redhat
Login failed (401 Unauthorized)
Verify you have provided correct credentials.
[student@workstation auth-provider]$ oc login -u manager -p redhat
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation auth-provider]$ oc new-project auth-provider
Now using project "auth-provider" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation auth-provider]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation auth-provider]$ oc delete project auth-provider
Error from server (Forbidden): projects.project.openshift.io "auth-provider" is forbidden: User "developer" cannot delete resource "projects" in API group "project.openshift.io" in the namespace "auth-provider"
[student@workstation auth-provider]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "developer-deploy".
[student@workstation auth-provider]$ oc extract secret/localusers -n openshift-config --to ~/DO280/labs/auth-provider/ --confirm
/home/student/DO280/labs/auth-provider/htpasswd
[student@workstation auth-provider]$ MANAGER_PASSWD="$(openssl rand -hex 15)"
[student@workstation auth-provider]$ echo $MANAGER_PASSWD
267ff873596e96f3016bbcddb5285b
[student@workstation auth-provider]$ htpasswd -b ~/DO280/labs/auth-provider/htpasswd manager ${MANAGER_PASSWD}
Updating password for user manager
[student@workstation auth-provider]$ oc set data secret/localusers --from-file htpasswd=~/DO280/labs/auth-provider/htpasswd -n openshift-config
secret/localusers data updated
[student@workstation auth-provider]$ oc login -u manager -p ${MANAGER_PASSWD}
Login failed (401 Unauthorized)
Verify you have provided correct credentials.
[student@workstation auth-provider]$ oc login -u manager -p ${MANAGER_PASSWD}
Login failed (401 Unauthorized)
Verify you have provided correct credentials.
[student@workstation auth-provider]$ oc login -u manager -p ${MANAGER_PASSWD}
Login successful.

You have one project on this server: "auth-provider"

Using project "auth-provider".
[student@workstation auth-provider]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "auth-provider".
[student@workstation auth-provider]$ oc extract secret/localusers -n openshift-config --to ~/DO280/labs/auth-provider/ --confirm
/home/student/DO280/labs/auth-provider/htpasswd
[student@workstation auth-provider]$ htpasswd -D ~/DO280/labs/auth-provider/htpasswd manager
Deleting password for user manager
[student@workstation auth-provider]$ oc set data secret/localusers --from-file htpasswd=~/DO280/labs/auth-provider/htpasswd -n openshift-config
secret/localusers data updated
[student@workstation auth-provider]$ oc delete identity "myusers:manager"
identity.user.openshift.io "myusers:manager" deleted
[student@workstation auth-provider]$ oc delete user manager
user.user.openshift.io "manager" deleted
[student@workstation auth-provider]$ oc login -u manager -p ${MANAGER_PASSWD}
Login failed (401 Unauthorized)
Verify you have provided correct credentials.
[student@workstation auth-provider]$ oc get users
NAME        UID                                    FULL NAME   IDENTITIES
admin       05b3eece-a288-4c01-842f-f48201bc5481               myusers:admin
developer   a5ebc71f-01b9-430a-93bb-9411c1c5668a               myusers:developer
[student@workstation auth-provider]$ oc get identity
NAME                IDP NAME   IDP USER NAME   USER NAME   USER UID
myusers:admin       myusers    admin           admin       05b3eece-a288-4c01-842f-f48201bc5481
myusers:developer   myusers    developer       developer   a5ebc71f-01b9-430a-93bb-9411c1c5668a
[student@workstation auth-provider]$ oc extract secret/localusers -n openshift-config --to -
# htpasswd
admin:$2y$05$Jho/8gbtUvtk90Qmmso0s.dI2CBpskCxbeyStVpcqkZJuv9tk/YTW
developer:$apr1$GOSucLXM$jUNwIgHD7sMOndqVDH6mj.
[student@workstation auth-provider]$ oc login -u kubeadmin -p ${RHT_OCP4_KUBEADM_PASSWD}
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "auth-provider".
[student@workstation auth-provider]$ oc delete project auth-provider
project.project.openshift.io "auth-provider" deleted
[student@workstation auth-provider]$ oc edit oauth
oauth.config.openshift.io/cluster edited
[student@workstation auth-provider]$ oc delete secret localusers -n openshift-config
secret "localusers" deleted
[student@workstation auth-provider]$ oc delete user --all
user.user.openshift.io "admin" deleted
user.user.openshift.io "developer" deleted
[student@workstation auth-provider]$ oc delete identity --all
identity.user.openshift.io "myusers:admin" deleted
identity.user.openshift.io "myusers:developer" deleted
[student@workstation auth-provider]$ lab auth-provider finish

Completing Guided Exercise: Configuring Identity Providers

 · Remove exercise files.......................................  FAIL

Cannot continue due to the previous errors.....................  FAIL
One or more terminal prompts is at /home/student/DO280/labs/auth-provider (or a subdirectory). Change to the /home/student/ directory and run 'lab auth-provider finish' again.

[student@workstation auth-provider]$ cd
[student@workstation ~]$ lab auth-provider finish

Completing Guided Exercise: Configuring Identity Providers

 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
------------------------------------------------------------18Oct22---------------------------------------------------------------------
GE - lab auth-rbac start
-------------------------

[student@workstation ~]$ lab auth-rbac start

Checking prerequisites for Guided Exercise: Defining and Applying permissions using RBAC

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'auth-rbac' project is absent...........................  SUCCESS

Setting up the classroom for Guided Exercise: Defining and Applying permissions using RBAC

 · Create HTPasswd entry for 'admin'...........................  SUCCESS
 · Create HTPasswd entry for 'leader'..........................  SUCCESS
 · Create HTPasswd entry for 'developer'.......................  SUCCESS
 · Create HTPasswd entry for 'qa-engineer'.....................  SUCCESS
 · Create HTPasswd secret: 'localusers'........................  SUCCESS
 · Add HTPasswd IdP............................................  SUCCESS
 · Pause for creation of first oauth pod.......................  SUCCESS
 · Pause for creation of second oauth pod......................  SUCCESS
 · Delete all previous users...................................  SUCCESS
 · Delete all previous identities..............................  SUCCESS
 · Pause 5 seconds before validating authentication............  SUCCESS
 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 · Validate 'qa-engineer' can log in with password 'redhat'....  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u admin -p redhat https://api.ocp4.example.com:6443
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc get clusterrolebinding -o wide | grep -E 'NAME|self-provisioner'
NAME                                                                        ROLE                                                                                    AGE   USERS                                                            GROUPS                                         SERVICEACCOUNTS
self-provisioners                                                           ClusterRole/self-provisioner                                                            82d                                                                    system:authenticated:oauth                     
[student@workstation ~]$ oc describe clusterrolebindings self-provisioners
Name:         self-provisioners
Labels:       <none>
Annotations:  rbac.authorization.kubernetes.io/autoupdate: true
Role:
  Kind:  ClusterRole
  Name:  self-provisioner
Subjects:
  Kind   Name                        Namespace
  ----   ----                        ---------
  Group  system:authenticated:oauth  
[student@workstation ~]$ oc adm policy remove-cluster-role-from-group self-provisioner system:authenticated:oauth
Warning: Your changes may get lost whenever a master is restarted, unless you prevent reconciliation of this rolebinding using the following command: oc annotate clusterrolebinding.rbac self-provisioners 'rbac.authorization.kubernetes.io/autoupdate=false' --overwrite
clusterrole.rbac.authorization.k8s.io/self-provisioner removed: "system:authenticated:oauth"
[student@workstation ~]$ oc describe clusterrolebindings self-provisioners
Error from server (NotFound): clusterrolebindings.rbac.authorization.k8s.io "self-provisioners" not found
[student@workstation ~]$ 
[student@workstation ~]$ oc login -u leader -p redhat
Login successful.

You don't have any projects. Contact your system administrator to request a project.
[student@workstation ~]$ oc new-project test
Error from server (Forbidden): You may not request a new project via this API.
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc new-project auth-rbac
Now using project "auth-rbac" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc policy add-role-to-user admin leader
clusterrole.rbac.authorization.k8s.io/admin added: "leader"
[student@workstation ~]$ oc adm groups new dev-group
group.user.openshift.io/dev-group created
[student@workstation ~]$ oc adm groups add-users dev-group developer
group.user.openshift.io/dev-group added: "developer"
[student@workstation ~]$ oc adm groups new qa-group
group.user.openshift.io/qa-group created
[student@workstation ~]$ oc adm groups add-users qa-group qa-engineer
group.user.openshift.io/qa-group added: "qa-engineer"
[student@workstation ~]$ oc get groups
NAME        USERS
dev-group   developer
qa-group    qa-engineer
[student@workstation ~]$ oc login -u leader -p redhat
Login successful.

You have one project on this server: "auth-rbac"

Using project "auth-rbac".
[student@workstation ~]$ oc policy add-role-to-group edit dev-group
clusterrole.rbac.authorization.k8s.io/edit added: "dev-group"
[student@workstation ~]$ oc policy add-role-to-group view qa-group
clusterrole.rbac.authorization.k8s.io/view added: "qa-group"
[student@workstation ~]$ oc get rolebindings -o wide
NAME                    ROLE                               AGE     USERS    GROUPS                             SERVICEACCOUNTS
admin                   ClusterRole/admin                  7m48s   admin                                       
admin-0                 ClusterRole/admin                  4m48s   leader                                      
edit                    ClusterRole/edit                   74s              dev-group                          
system:deployers        ClusterRole/system:deployer        7m47s                                               auth-rbac/deployer
system:image-builders   ClusterRole/system:image-builder   7m47s                                               auth-rbac/builder
system:image-pullers    ClusterRole/system:image-puller    7m47s            system:serviceaccounts:auth-rbac   
view                    ClusterRole/view                   44s              qa-group                           
[student@workstation ~]$ oc login -u developer -p developer
Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

  * auth-rbac
    developer-deploy

Using project "auth-rbac".
[student@workstation ~]$ oc new-app --name httpd httpd:2.4
--> Found image 7b8d40f (3 months old) in image stream "openshift/httpd" under tag "2.4" for "httpd:2.4"

    Apache httpd 2.4 
    ---------------- 
    Apache httpd 2.4 available as container, is a powerful, efficient, and extensible web server. Apache supports a variety of features, many implemented as compiled modules which extend the core functionality. These can range from server-side programming language support to authentication schemes. Virtual hosting allows one Apache installation to serve many different Web sites.

    Tags: builder, httpd, httpd24


--> Creating resources ...
    deployment.apps "httpd" created
    service "httpd" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/httpd' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc policy add-role-to-user edit qa-engineer
Error from server (Forbidden): rolebindings.rbac.authorization.k8s.io is forbidden: User "developer" cannot list resource "rolebindings" in API group "rbac.authorization.k8s.io" in the namespace "auth-rbac"
[student@workstation ~]$ oc login -u qa-engineer -p redhat
Login successful.

You have one project on this server: "auth-rbac"

Using project "auth-rbac".
[student@workstation ~]$ oc scale deployment httpd --replicas 3
Error from server (Forbidden): deployments.apps "httpd" is forbidden: User "qa-engineer" cannot patch resource "deployments/scale" in API group "apps" in the namespace "auth-rbac"
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "auth-rbac".
[student@workstation ~]$ oc scale deployment httpd --replicas 3
deployment.apps/httpd scaled
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS              RESTARTS   AGE
httpd-965dddc74-6k2pl   0/1     ContainerCreating   0          5s
httpd-965dddc74-bdzm6   0/1     ContainerCreating   0          6s
httpd-965dddc74-wxxtd   1/1     Running             0          109s
[student@workstation ~]$ oc adm policy add-cluster-role-to-group --rolebinding-name self-provisioners self-provisioner system:authenticated:oauth
Warning: Group 'system:authenticated:oauth' not found
clusterrole.rbac.authorization.k8s.io/self-provisioner added: "system:authenticated:oauth"
[student@workstation ~]$ lab auth-rbac finish

Completing Guided Exercise: Defining and Applying permissions using RBAC

 · Delete OpenShift project 'auth-rbac'........................  SUCCESS
 · Wait for project 'auth-rbac' to be gone.....................  SUCCESS
 · Remove group 'dev-group'....................................  SUCCESS
 · Remove group 'qa-group'.....................................  SUCCESS
 · Delete HTPasswd entry for 'qa-engineer'.....................  SUCCESS
 · Update the 'localusers' secret data.........................  SUCCESS
 · Remove user 'qa-engineer'...................................  SUCCESS
 · Remove identity 'localusers:qa-engineer'....................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

-------------------------------------------------Lab - Configuring Authentication and Authorization-----------------------------------------------------
[student@workstation ~]$ sudo su -
Last login: Mon Oct 17 12:36:55 EDT 2022 on pts/0
[root@workstation ~]# lab auth-review start

Checking prerequisites for Lab: Configuring Authentication and Authorization

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'auth-review' project is absent.........................  SUCCESS

Setting up the classroom for Lab: Configuring Authentication and Authorization

 Preparing the student's workstation:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS
 Restoring authentication settings to installation defaults:
 · Removing 'cluster-admin' role from the 'admin' user.........  SUCCESS
 · Remove HTPasswd secret: 'localusers'........................  SUCCESS
 · Remove all configured Identity Providers....................  SUCCESS
 · Remove all existing users...................................  SUCCESS
 · Remove all existing identities..............................  SUCCESS

Overall start status...........................................  SUCCESS

[root@workstation ~]# cat ~/DO280/labs/auth-review/tmp_users analyst
cat: /root/DO280/labs/auth-review/tmp_users: No such file or directory
cat: analyst: No such file or directory
[root@workstation ~]# cat ~/DO280/labs/auth-review/tmp_users
cat: /root/DO280/labs/auth-review/tmp_users: No such file or directory
[root@workstation ~]# exit
logout
[student@workstation ~]$ cat  ~/DO280/labs/auth-review/tmp_users
analyst:$apr1$hWPR4T6T$ArBfJyvDF1rHDv6dpqyTY.
tester:$apr1$eR/Ct6Pi$snWCZ.ecsMQNwYJhEHxYM1
leader:$apr1$v5ldniVX$XwMiaUdkuQJ5lKz7ayEy/0
[student@workstation ~]$ htpasswd -D ~/DO280/labs/auth-review/tmp_users analyst
Deleting password for user analyst
[student@workstation ~]$ for NAME in tester leader admin developer; do htpasswd -b ~/DO280/labs/auth-review/tmp_users ${NAME} 'L@bR3v!ew';done
Updating password for user tester
Updating password for user leader
Adding password for user admin
Adding password for user developer
[student@workstation ~]$ cat ~/DO280/labs/auth-review/tmp_users
tester:$apr1$qhq3yL0F$CtS9h6F8qNlxtj3TSdEJF0
leader:$apr1$tr4Pr1DS$NOuX14FKiMSwh.mQ7iuSY1
admin:$apr1$oLbzM99f$Tsqv.A8myIFFQhMN9K/Ei1
developer:$apr1$Bbva2fua$eRi2Tl40BXEkmQAUodGHx.
[student@workstation ~]$ source /usr/local/etc/ocp4.config
[student@workstation ~]$ oc login -u kubeadmin -p ${RHT_OCP4_KUBEADM_PASSWD} https://api.ocp4.example.com:6443
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc create secret generic auth-review --from-file htpasswd=/home/student/DO280/labs/auth-review/tmp_users -n openshift-config
secret/auth-review created
[student@workstation ~]$ oc get oauth cluster -o yaml > ~/DO280/labs/auth-review/oauth.yaml
[student@workstation ~]$ oc replace  ~/DO280/solutions/auth-review/oauth.yaml
error: must specify one of -f and -k
[student@workstation ~]$ oc replace -f ~/DO280/solutions/auth-review/oauth.yaml
oauth.config.openshift.io/cluster replaced
[student@workstation ~]$ watch oc get pods -n openshift-authentication
[student@workstation ~]$ watch oc get pods -n openshift-authentication
[student@workstation ~]$ oc adm policy add-cluster-role-to-user cluster-admin admin
Warning: User 'admin' not found
clusterrole.rbac.authorization.k8s.io/cluster-admin added: "admin"
[student@workstation ~]$ oc login -u admin -p 'L@bR3v!ew'
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc get nodes
NAME       STATUS   ROLES           AGE   VERSION
master01   Ready    master,worker   82d   v1.23.3+e419edf
master02   Ready    master,worker   82d   v1.23.3+e419edf
master03   Ready    master,worker   82d   v1.23.3+e419edf
[student@workstation ~]$ 
[student@workstation ~]$ oc login -u developer -p 'L@bR3v!ew'
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation ~]$ oc get nodes
Error from server (Forbidden): nodes is forbidden: User "developer" cannot list resource "nodes" in API group "" at the cluster scope
[student@workstation ~]$ oc login -u admin -p 'L@bR3v!ew'
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "developer-deploy".
[student@workstation ~]$ oc adm policy remove-cluster-role-from-group self-provisioner system:authenticated:oauth
clusterrole.rbac.authorization.k8s.io/self-provisioner removed: "system:authenticated:oauth"
[student@workstation ~]$ oc adm groups new managers
group.user.openshift.io/managers created
[student@workstation ~]$ oc adm groups add-users managers leader
group.user.openshift.io/managers added: "leader"
[student@workstation ~]$ oc adm policy add-cluster-role-to-group self-provisioner managers
clusterrole.rbac.authorization.k8s.io/self-provisioner added: "managers"
[student@workstation ~]$ oc login -u leader -p 'L@bR3v!ew'
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project auth-review
Now using project "auth-review" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc login -u admin -p 'L@bR3v!ew'
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "auth-review".
[student@workstation ~]$ oc adm groups new developers
group.user.openshift.io/developers created
[student@workstation ~]$ oc adm groups add-users developers developer
group.user.openshift.io/developers added: "developer"
[student@workstation ~]$ oc policy add-role-to-group edit developers
clusterrole.rbac.authorization.k8s.io/edit added: "developers"
[student@workstation ~]$ oc adm groups new qa
group.user.openshift.io/qa created
[student@workstation ~]$ oc adm groups add-users qa tester
group.user.openshift.io/qa added: "tester"
[student@workstation ~]$ oc policy add-role-to-group view qa
clusterrole.rbac.authorization.k8s.io/view added: "qa"
[student@workstation ~]$ lab auth-review grade

Grading the student's work for Lab: Configuring Authentication and Authorization

 · Cluster uses the HTPasswd identity provider.................  PASS
 · User 'analyst' does not exist in the HTPasswd secret........  PASS
 · The 'admin' user can log in with a password of 'L@bR3v!ew'..  PASS
 · The 'admin' user has the 'cluster-admin' cluster role.......  PASS
 · The 'self-provisioner' cluster role has been removed from th
   e 'system:authenticated:oauth' group........................  PASS
 · The 'managers' group exists.................................  PASS
 · The 'managers' group has the 'self-provisioner' cluster role
   ............................................................  PASS
 · The 'managers' group contains the 'leader' user.............  PASS
 · The 'leader' user can log in with a password of 'L@bR3v!ew'.  PASS
 · The 'auth-review' project exists............................  PASS
 · The 'leader' user has the 'admin' role on the 'auth-review' 
   project.....................................................  PASS
 · The 'developers' group exists...............................  PASS
 · The 'developers' group has the 'edit' role on the 'auth-revi
   ew' project.................................................  PASS
 · The 'dvelopers' group contains the 'developer' user.........  PASS
 · The 'developer' user can log in with a password of 'L@bR3v!e
   w'..........................................................  PASS
 · The 'qa' group exists.......................................  PASS
 · The 'qa' group has the 'view' role on the 'auth-review' proj
   ect.........................................................  PASS
 · The 'qa' group contains the 'tester' user...................  PASS
 · The 'tester' user can log in with a password of 'L@bR3v!ew'.  PASS

Overall exercise grade.........................................  PASS

[student@workstation ~]$ lab auth-review finish

Completing Lab: Configuring Authentication and Authorization

 · Delete OpenShift project 'auth-review'......................  SUCCESS
 · Wait for project 'auth-review' to be gone...................  SUCCESS
 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS
 · Restore project creation privileges.........................  SUCCESS
 · Removing the cluster role binding 'clusterrolebinding.rbac.a
   uthorization.k8s.io/self-provisioner'.......................  SUCCESS
 Restoring authentication settings to installation defaults:
 · Removing 'cluster-admin' role from the 'admin' user.........  SUCCESS
 · Remove HTPasswd secret: 'auth-review'.......................  SUCCESS
 · Remove all configured Identity Providers....................  SUCCESS
 · Remove all existing users...................................  SUCCESS
 · Remove all existing groups..................................  SUCCESS
 · Remove all existing identities..............................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

Summary
In this chapter, you learned:

• A newly-installed OpenShift cluster provides two authentication methods that grant
administrative access: the kubeconfig file and the kubeadmin virtual user.
• The HTPasswd identity provider authenticates users against credentials stored in a secret. The
name of the secret, and other settings for the identity provider, are stored inside the OAuth
custom resource.
• To manage user credentials using the HTPasswd identity provider, you must extract data from
the secret, change that data using the htpasswd command, and then apply the data back to
the secret.
• Creating OpenShift users requires valid credentials, managed by an identity provider, plus user
and identity resources.
• Deleting OpenShift users requires deleting their credentials from the identity provider, and also
deleting their user and identity resources.
• OpenShift uses role-based access control (RBAC) to control user actions. A role is a collection
of rules that govern interaction with OpenShift resources. Default roles exist for cluster
administrators, developers, and auditors.
• To control user interaction, assign a user to one or more roles. A role binding contains all of the
associations of a role to users and groups.
• To grant a user cluster administrator privileges, assign the cluster-admin role to that user.

---------------------------------------------------------19Oct22-------------------------------------------------
CH-11 - GE-Managing Sensitive Information with Secrets

[student@workstation ~]$ lab authorization-secrets start

Checking prerequisites for Guided Exercise: Managing Sensitive Information With Secrets

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'authorization-secrets' project is absent...............  SUCCESS

Setting up the classroom for Guided Exercise: Managing Sensitive Information With Secrets

 · Create HTPasswd entry for 'admin'...........................  SUCCESS
 · Create HTPasswd entry for 'leader'..........................  SUCCESS
 · Create HTPasswd entry for 'developer'.......................  SUCCESS
 · Create HTPasswd secret: 'localusers'........................  SUCCESS
 · Add HTPasswd IdP............................................  SUCCESS
 · Assigning the 'cluster-admin' role to the 'admin' user......  SUCCESS
 · Pause for creation of first oauth pod.......................  SUCCESS
 · Pause for creation of second oauth pod......................  SUCCESS
 · Delete all previous users...................................  SUCCESS
 · Delete all previous identities..............................  SUCCESS
 · Pause 5 seconds before validating authentication............  SUCCESS
 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation ~]$ oc new-project authorization-secrets
Now using project "authorization-secrets" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc create secret generic mysql --from-literal user=myuser --from-literal password=redhat123 --from-literal database=test_secrets --from-literal hostname=mysql
secret/mysql created
[student@workstation ~]$ oc get secret
NAME                       TYPE                                  DATA   AGE
builder-dockercfg-4nxrx    kubernetes.io/dockercfg               1      5m43s
builder-token-7w6sn        kubernetes.io/service-account-token   4      5m43s
builder-token-8ch4r        kubernetes.io/service-account-token   4      5m43s
default-dockercfg-9fj2s    kubernetes.io/dockercfg               1      5m43s
default-token-6m4cj        kubernetes.io/service-account-token   4      5m43s
default-token-6ptwk        kubernetes.io/service-account-token   4      5m43s
deployer-dockercfg-9tkcx   kubernetes.io/dockercfg               1      5m43s
deployer-token-4xzcc       kubernetes.io/service-account-token   4      5m43s
deployer-token-mvsgd       kubernetes.io/service-account-token   4      5m43s
mysql                      Opaque                                4      10s
[student@workstation ~]$ oc describe secret mysql
Name:         mysql
Namespace:    authorization-secrets
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
user:      6 bytes
database:  12 bytes
hostname:  5 bytes
password:  9 bytes
[student@workstation ~]$ oc new-app --name mysql --image registry.redhat.io/rhel8/mysql-80:1
--> Found container image b140346 (7 days old) from registry.redhat.io for "registry.redhat.io/rhel8/mysql-80:1"

    MySQL 8.0 
    --------- 
    MySQL is a multi-user, multi-threaded SQL database server. The container image provides a containerized packaging of the MySQL mysqld daemon and client application. The mysqld server daemon accepts connections from clients and provides access to content from MySQL databases on behalf of the clients.

    Tags: database, mysql, mysql80, mysql-80

    * An image stream tag will be created as "mysql:1" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "mysql" created
    deployment.apps "mysql" created
    service "mysql" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/mysql' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS             RESTARTS      AGE
mysql-75c857cb77-fcqqt   0/1     CrashLoopBackOff   1 (12s ago)   28s
mysql-75c857cb77-fcqqt   0/1     Error              2 (15s ago)   31s

mysql-75c857cb77-fcqqt   0/1     CrashLoopBackOff   2 (11s ago)   42s
^C[student@workstation ~]$ oc set env deployment/mysql --from secret/mysql --prefix MYSQL_
deployment.apps/mysql updated
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS    RESTARTS   AGE
mysql-8566d5db48-6x8cf   1/1     Running   0          21s
^C[student@workstation ~]$ oc set volume deployment/mysql --add --type secret --mount-path /run/secrets/mysql --secret-name mysql
info: Generated volume name: volume-wpxgz
deployment.apps/mysql volume updated
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS    RESTARTS   AGE
mysql-556846b745-t9dnl   1/1     Running   0          17s
^C[student@workstation ~]$ oc rsh mysql-556846b745-t9dnl
sh-4.4$ mysql -u myuser --password=redhat123 test_secrets -e 'show databases;'
mysql: [Warning] Using a password on the command line interface can be insecure.
+--------------------+
| Database           |
+--------------------+
| information_schema |
| test_secrets       |
+--------------------+
sh-4.4$ df -h | grep mysql
tmpfs            15G   16K   15G   1% /run/secrets/mysql
sh-4.4$ cd /run/secrets/mysql/
sh-4.4$ ls
database  hostname  password  user
sh-4.4$ cat database 
test_secretssh-4.4$ for FILE in $(ls /run/secrets/mysql); do  echo "${FILE}: $(cat /run/secrets/mysql/${FILE})" ; done
database: test_secrets
hostname: mysql
password: redhat123
user: myuser
sh-4.4$ exit
exit
[student@workstation ~]$ oc new-app --name quotes --image quay.io/redhattraining/famous-quotes:2.1
--> Found container image 7ff1a7b (2 years old) from quay.io for "quay.io/redhattraining/famous-quotes:2.1"

    Quotes 2.1 
    ---------- 
    Famous Quotes is a PoC application for Go and MySQL

    Tags: poc, mysql, golang

    * An image stream tag will be created as "quotes:2.1" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "quotes" created
    deployment.apps "quotes" created
    service "quotes" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/quotes' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get pods -l deployment=quotes -w
NAME                      READY   STATUS              RESTARTS   AGE
quotes-66b987df5d-c95c4   0/1     ContainerCreating   0          14s
quotes-66b987df5d-c95c4   0/1     Error               0          19s
quotes-66b987df5d-c95c4   0/1     Error               1 (2s ago)   20s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    1 (14s ago)   33s
quotes-66b987df5d-c95c4   0/1     Error               2 (15s ago)   34s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    2 (12s ago)   46s
quotes-66b987df5d-c95c4   0/1     Error               3 (27s ago)   61s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    3 (15s ago)   76s
quotes-66b987df5d-c95c4   0/1     Error               4 (42s ago)   103s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    4 (13s ago)   116s
[student@workstation ~]$ oc set env deployment/quotes --from secret/mysql --prefix QUOTES_
deployment.apps/quotes updated
[student@workstation ~]$ oc get pods -l deployment=quotes 
NAME                      READY   STATUS    RESTARTS   AGE
quotes-7776b797c5-mt87d   1/1     Running   0          12s
[student@workstation ~]$ oc logs quotes-7776b797c5-mt87d | head -n2
2022/10/20 16:48:04 Connecting to the database: myuser:redhat123@tcp(mysql:3306)/test_secrets
2022/10/20 16:48:09 Database connection OK
[student@workstation ~]$ oc expose service quotes --hostname quotes.apps.ocp4.example.com
route.route.openshift.io/quotes exposed
[student@workstation ~]$ oc get route quotes
NAME     HOST/PORT                      PATH   SERVICES   PORT       TERMINATION   WILDCARD
quotes   quotes.apps.ocp4.example.com          quotes     8000-tcp                 None
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/env | grep QUOTES_
                <li>QUOTES_USER: myuser </li>
                <li>QUOTES_PASSWORD: redhat123 </li>
                <li>QUOTES_DATABASE: test_secrets</li>
                <li>QUOTES_HOST: mysql</li>
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/status
Database connection OK
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/random
6: Hell, if I could explain it to the average person, it wouldn't have been worth the Nobel prize.
- Richard Feynman
[student@workstation ~]$ oc delete project authorization-secrets
project.project.openshift.io "authorization-secrets" deleted
[student@workstation ~]$ lab authorization-secrets finish

Completing Guided Exercise: Managing Sensitive Information With Secrets


Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

---------------------------GE -- Controlling Application Permissions with Security Context Constraints ----

[student@workstation ~]$ lab authorization-secrets start

Checking prerequisites for Guided Exercise: Managing Sensitive Information With Secrets

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'authorization-secrets' project is absent...............  SUCCESS

Setting up the classroom for Guided Exercise: Managing Sensitive Information With Secrets

 · Create HTPasswd entry for 'admin'...........................  SUCCESS
 · Create HTPasswd entry for 'leader'..........................  SUCCESS
 · Create HTPasswd entry for 'developer'.......................  SUCCESS
 · Create HTPasswd secret: 'localusers'........................  SUCCESS
 · Add HTPasswd IdP............................................  SUCCESS
 · Assigning the 'cluster-admin' role to the 'admin' user......  SUCCESS
 · Pause for creation of first oauth pod.......................  SUCCESS
 · Pause for creation of second oauth pod......................  SUCCESS
 · Delete all previous users...................................  SUCCESS
 · Delete all previous identities..............................  SUCCESS
 · Pause 5 seconds before validating authentication............  SUCCESS
 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation ~]$ oc new-project authorization-secrets
Now using project "authorization-secrets" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc create secret generic mysql --from-literal user=myuser --from-literal password=redhat123 --from-literal database=test_secrets --from-literal hostname=mysql
secret/mysql created
[student@workstation ~]$ oc get secret
NAME                       TYPE                                  DATA   AGE
builder-dockercfg-4nxrx    kubernetes.io/dockercfg               1      5m43s
builder-token-7w6sn        kubernetes.io/service-account-token   4      5m43s
builder-token-8ch4r        kubernetes.io/service-account-token   4      5m43s
default-dockercfg-9fj2s    kubernetes.io/dockercfg               1      5m43s
default-token-6m4cj        kubernetes.io/service-account-token   4      5m43s
default-token-6ptwk        kubernetes.io/service-account-token   4      5m43s
deployer-dockercfg-9tkcx   kubernetes.io/dockercfg               1      5m43s
deployer-token-4xzcc       kubernetes.io/service-account-token   4      5m43s
deployer-token-mvsgd       kubernetes.io/service-account-token   4      5m43s
mysql                      Opaque                                4      10s
[student@workstation ~]$ oc describe secret mysql
Name:         mysql
Namespace:    authorization-secrets
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
user:      6 bytes
database:  12 bytes
hostname:  5 bytes
password:  9 bytes
[student@workstation ~]$ oc new-app --name mysql --image registry.redhat.io/rhel8/mysql-80:1
--> Found container image b140346 (7 days old) from registry.redhat.io for "registry.redhat.io/rhel8/mysql-80:1"

    MySQL 8.0 
    --------- 
    MySQL is a multi-user, multi-threaded SQL database server. The container image provides a containerized packaging of the MySQL mysqld daemon and client application. The mysqld server daemon accepts connections from clients and provides access to content from MySQL databases on behalf of the clients.

    Tags: database, mysql, mysql80, mysql-80

    * An image stream tag will be created as "mysql:1" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "mysql" created
    deployment.apps "mysql" created
    service "mysql" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/mysql' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS             RESTARTS      AGE
mysql-75c857cb77-fcqqt   0/1     CrashLoopBackOff   1 (12s ago)   28s
mysql-75c857cb77-fcqqt   0/1     Error              2 (15s ago)   31s

mysql-75c857cb77-fcqqt   0/1     CrashLoopBackOff   2 (11s ago)   42s
^C[student@workstation ~]$ oc set env deployment/mysql --from secret/mysql --prefix MYSQL_
deployment.apps/mysql updated
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS    RESTARTS   AGE
mysql-8566d5db48-6x8cf   1/1     Running   0          21s
^C[student@workstation ~]$ oc set volume deployment/mysql --add --type secret --mount-path /run/secrets/mysql --secret-name mysql
info: Generated volume name: volume-wpxgz
deployment.apps/mysql volume updated
[student@workstation ~]$ oc get pods -w
NAME                     READY   STATUS    RESTARTS   AGE
mysql-556846b745-t9dnl   1/1     Running   0          17s
^C[student@workstation ~]$ oc rsh mysql-556846b745-t9dnl
sh-4.4$ mysql -u myuser --password=redhat123 test_secrets -e 'show databases;'
mysql: [Warning] Using a password on the command line interface can be insecure.
+--------------------+
| Database           |
+--------------------+
| information_schema |
| test_secrets       |
+--------------------+
sh-4.4$ df -h | grep mysql
tmpfs            15G   16K   15G   1% /run/secrets/mysql
sh-4.4$ cd /run/secrets/mysql/
sh-4.4$ ls
database  hostname  password  user
sh-4.4$ cat database 
test_secretssh-4.4$ for FILE in $(ls /run/secrets/mysql); do  echo "${FILE}: $(cat /run/secrets/mysql/${FILE})" ; done
database: test_secrets
hostname: mysql
password: redhat123
user: myuser
sh-4.4$ exit
exit
[student@workstation ~]$ oc new-app --name quotes --image quay.io/redhattraining/famous-quotes:2.1
--> Found container image 7ff1a7b (2 years old) from quay.io for "quay.io/redhattraining/famous-quotes:2.1"

    Quotes 2.1 
    ---------- 
    Famous Quotes is a PoC application for Go and MySQL

    Tags: poc, mysql, golang

    * An image stream tag will be created as "quotes:2.1" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "quotes" created
    deployment.apps "quotes" created
    service "quotes" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/quotes' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get pods -l deployment=quotes -w
NAME                      READY   STATUS              RESTARTS   AGE
quotes-66b987df5d-c95c4   0/1     ContainerCreating   0          14s
quotes-66b987df5d-c95c4   0/1     Error               0          19s
quotes-66b987df5d-c95c4   0/1     Error               1 (2s ago)   20s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    1 (14s ago)   33s
quotes-66b987df5d-c95c4   0/1     Error               2 (15s ago)   34s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    2 (12s ago)   46s
quotes-66b987df5d-c95c4   0/1     Error               3 (27s ago)   61s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    3 (15s ago)   76s
quotes-66b987df5d-c95c4   0/1     Error               4 (42s ago)   103s
quotes-66b987df5d-c95c4   0/1     CrashLoopBackOff    4 (13s ago)   116s
[student@workstation ~]$ oc set env deployment/quotes --from secret/mysql --prefix QUOTES_
deployment.apps/quotes updated
[student@workstation ~]$ oc get pods -l deployment=quotes 
NAME                      READY   STATUS    RESTARTS   AGE
quotes-7776b797c5-mt87d   1/1     Running   0          12s
[student@workstation ~]$ oc logs quotes-7776b797c5-mt87d | head -n2
2022/10/20 16:48:04 Connecting to the database: myuser:redhat123@tcp(mysql:3306)/test_secrets
2022/10/20 16:48:09 Database connection OK
[student@workstation ~]$ oc expose service quotes --hostname quotes.apps.ocp4.example.com
route.route.openshift.io/quotes exposed
[student@workstation ~]$ oc get route quotes
NAME     HOST/PORT                      PATH   SERVICES   PORT       TERMINATION   WILDCARD
quotes   quotes.apps.ocp4.example.com          quotes     8000-tcp                 None
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/env | grep QUOTES_
                <li>QUOTES_USER: myuser </li>
                <li>QUOTES_PASSWORD: redhat123 </li>
                <li>QUOTES_DATABASE: test_secrets</li>
                <li>QUOTES_HOST: mysql</li>
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/status
Database connection OK
[student@workstation ~]$ curl -s http://quotes.apps.ocp4.example.com/random
6: Hell, if I could explain it to the average person, it wouldn't have been worth the Nobel prize.
- Richard Feynman
[student@workstation ~]$ oc delete project authorization-secrets
project.project.openshift.io "authorization-secrets" deleted
[student@workstation ~]$ lab authorization-secrets finish

Completing Guided Exercise: Managing Sensitive Information With Secrets


Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

-------------------------------Lab-Ch11------------------
 
[student@workstation ~]$ lab authorization-review start

Checking prerequisites for Lab: Configuring Application Security

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'authorization-review' project is absent................  SUCCESS

Setting up the classroom for Lab: Configuring Application Security

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS

Overall start status...........................................  SUCCESS


[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You have one project on this server: "developer-deploy"

Using project "developer-deploy".
[student@workstation ~]$ oc new-project authorization-review
Now using project "authorization-review" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$
[student@workstation ~]$ oc new-app --name mysql --image registry.redhat.io/rhel8/mysql-80:1
--> Found container image b140346 (8 days old) from registry.redhat.io for "registry.redhat.io/rhel8/mysql-80:1"

    MySQL 8.0 
    --------- 
    MySQL is a multi-user, multi-threaded SQL database server. The container image provides a containerized packaging of the MySQL mysqld daemon and client application. The mysqld server daemon accepts connections from clients and provides access to content from MySQL databases on behalf of the clients.

    Tags: database, mysql, mysql80, mysql-80

    * An image stream tag will be created as "mysql:1" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "mysql" created
    deployment.apps "mysql" created
    service "mysql" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/mysql' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc status
In project authorization-review on server https://api.ocp4.example.com:6443

svc/mysql - 172.30.179.224:3306
  deployment/mysql deploys istag/mysql:1 
    deployment #2 running for 8 seconds - 0/1 pods (warning: 1 restarts)
    deployment #1 deployed 9 seconds ago - 0/1 pods growing to 1

Errors:
  * pod/mysql-75c857cb77-m8jmk is crash-looping

1 error, 1 info identified, use 'oc status --suggest' to see details.

[student@workstation ~]$ oc create secret generic review-secret --from-literal user=wpuser --from-literal password=redhat123 --from-literal database=wordpress
secret/review-secret created
[student@workstation ~]$ oc set env deployment/mysql --prefix MYSQL_ --from secret/review-secret
deployment.apps/mysql updated
[student@workstation ~]$ oc status
In project authorization-review on server https://api.ocp4.example.com:6443

svc/mysql - 172.30.179.224:3306
  deployment/mysql deploys istag/mysql:1 
    deployment #3 running for 3 seconds - 1 pod
    deployment #2 deployed 34 seconds ago
    deployment #1 deployed 35 seconds ago


1 info identified, use 'oc status --suggest' to see details.
[student@workstation ~]$ oc get pods
NAME                    READY   STATUS    RESTARTS   AGE
mysql-6f5b588f8-cgvng   1/1     Running   0          9s
[student@workstation ~]$ oc new-app --name wordpress --image quay.io/redhattraining/wordpress:5.7-php7.4-apache -e WORDPRESS_DB_HOST=mysql -e WORDPRESS_DB_NAME=wordpress -e WORDPRESS_TITLE=auth-review -e WORDPRESS_USER=wpuser -e WORDPRESS_PASSWORD=redhat123 -e WORDPRESS_EMAIL=student@redhat.com -e WORDPRESS_URL=wordpress-review.apps.ocp4.example.com
--> Found container image 4d3c70b (15 months old) from quay.io for "quay.io/redhattraining/wordpress:5.7-php7.4-apache"

    * An image stream tag will be created as "wordpress:5.7-php7.4-apache" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "wordpress" created
    deployment.apps "wordpress" created
    service "wordpress" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/wordpress' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc set env deployment/wordpress --prefix WORDPRESS_DB_ --from secret/review-secret
deployment.apps/wordpress updated
[student@workstation ~]$ oc status
In project authorization-review on server https://api.ocp4.example.com:6443

svc/mysql - 172.30.179.224:3306
  deployment/mysql deploys istag/mysql:1 
    deployment #3 running for 4 minutes - 1 pod
    deployment #2 deployed 5 minutes ago
    deployment #1 deployed 5 minutes ago

svc/wordpress - 172.30.226.26:80
  deployment/wordpress deploys istag/wordpress:5.7-php7.4-apache 
    deployment #3 running for 4 seconds - 1 pod
    deployment #2 deployed 36 seconds ago
    deployment #1 deployed 37 seconds ago


2 infos identified, use 'oc status --suggest' to see details.
[student@workstation ~]$ watch oc get pods -l deployment=wordpress
[student@workstation ~]$  oc get pods -l deployment=wordpress
NAME                         READY   STATUS             RESTARTS      AGE
wordpress-684c9d4ffc-c7d85   0/1     CrashLoopBackOff   3 (30s ago)   82s
[student@workstation ~]$ oc logs wordpress-684c9d4ffc-c7d85
apache2-foreground
Checking if WordPress is installed
WordPress is already installed
AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 10.8.0.44. Set the 'ServerName' directive globally to suppress this message
(13)Permission denied: AH00072: make_sock: could not bind to address [::]:80
(13)Permission denied: AH00072: make_sock: could not bind to address 0.0.0.0:80
no listening sockets available, shutting down
AH00015: Unable to open logs
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "authorization-review".
[student@workstation ~]$ oc get pod/wordpress-684c9d4ffc-c7d85 -o yaml | oc adm policy scc-subject-review -f -
RESOURCE                         ALLOWED BY   
Pod/wordpress-684c9d4ffc-c7d85   anyuid       
[student@workstation ~]$ oc create serviceaccount wordpress-sa
serviceaccount/wordpress-sa created
[student@workstation ~]$ oc adm policy add-scc-to-user anyuid -z wordpress-sa
clusterrole.rbac.authorization.k8s.io/system:openshift:scc:anyuid added: "wordpress-sa"
[student@workstation ~]$ oc set serviceaccount deployment/wordpress wordpress-sa
deployment.apps/wordpress serviceaccount updated
[student@workstation ~]$ oc get pods -l deployment=wordpress
NAME                        READY   STATUS    RESTARTS   AGE
wordpress-bf74d8fcc-qnf5h   1/1     Running   0          19s
[student@workstation ~]$ oc expose service/wordpress --hostname wordpress-review.apps.ocp4.example.com
route.route.openshift.io/wordpress exposed
[student@workstation ~]$ curl -s http://wordpress-review.apps.ocp4.example.com/wp-admin/install.php | grep Installation
	<title>WordPress &rsaquo; Installation</title>
[student@workstation ~]$ lab authorization-review grade

Grading the student's work for Lab: Configuring Application Security

 Verifying the information collected about the cluster:
 · The 'authorization-review' project exists...................  PASS
 · The 'review-secret' secret exists...........................  PASS
 · The 'mysql' application exists..............................  PASS
 · The 'MYSQL_USER' environment variable is set from the 'revie
   w-secret' secret............................................  PASS
 · The 'MYSQL_PASSWORD' environment variable is set from the 'r
   eview-secret' secret........................................  PASS
 · The 'MYSQL_DATABASE' environment variable is set from the 'r
   eview-secret' secret........................................  PASS
 · The 'wordpress' application exists..........................  PASS
 · The 'WORDPRESS_DB_USER' environment variable is set from the
   'review-secret' secret......................................  PASS
 · The 'WORDPRESS_DB_PASSWORD' environment variable is set from
   the 'review-secret' secret..................................  PASS
 · The 'WORDPRESS_DB_DATABASE' environment variable is set from
   the 'review-secret' secret..................................  PASS
 · The 'wordpress-sa' service account exists...................  PASS
 · The 'wordpress-sa' service account uses the 'anyuid' SCC....  PASS
 · The 'wordpress' application uses the 'wordpress-sa' service 
   account.....................................................  PASS
 · The 'wordpress' application uses the 'anyuid' SCC...........  PASS
 · The 'wordpress' deployment is exposed at 'wordpress-review.a
   pps.ocp4.example.com'.......................................  PASS
 · The 'wordpress-review.apps.ocp4.example.com' URL responds to
   external requests...........................................  PASS

Overall exercise grade.........................................  PASS

[student@workstation ~]$ lab authorization-review finish

Completing Lab: Configuring Application Security

 · Delete OpenShift project 'authorization-review'.............  SUCCESS
 · Wait for project 'authorization-review' to be gone..........  SUCCESS
 · Removing the 'anyuid' SCC cluster role binding..............  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

--------------Summary----------------------------------------------
Summary
In this chapter, you learned:
• Secret resources allow you to separate sensitive information from application pods. You expose
secrets to an application pod either as environment variables or as ordinary files.
• OpenShift uses security context constraints (SCCs) to define allowed pod interactions with
system resources. By default, pods operate under the restricted context which limits access
to node resources.

-----------------------------------------------26Oct22-----------------------------------------------------
[student@workstation ~]$ lab network-sdn start

Checking prerequisites for Guided Exercise: Troubleshooting OpenShift Software-Defined Networking

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'network-sdn' project is absent.........................  SUCCESS

Setting up the classroom for Guided Exercise: Troubleshooting OpenShift Software-Defined Networking

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Update HTPasswd entry for 'leader'..........................  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 · Updating htpasswd data in secret 'htpasswd-secret'..........  SUCCESS
 · Pause for creation of first oauth pod.......................  SUCCESS
 · Wait up to 1 minute for 'pod/oauth-openshift-58d4f6bb88-fwww
   k'..........................................................  SUCCESS
 · Wait up to 1 minute for oauth pod containers to be ready....  SUCCESS
 · Pause for creation of second oauth pod......................  SUCCESS
 · Wait up to 1 minute for 'pod/oauth-openshift-58d4f6bb88-w7nb
   h'..........................................................  SUCCESS
 · Wait up to 1 minute for oauth pod containers to be ready....  SUCCESS
 · Delete all previous users...................................  SUCCESS
 · Delete all previous identities..............................  SUCCESS
 · Pause 5 seconds before validating authentication............  SUCCESS
 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 Preparing the student's workstation:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

Welcome! See 'oc help' to get started.
[student@workstation ~]$ oc new-project network-sdn
Now using project "network-sdn" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ cd ~/DO280/labs/network-sdn
[student@workstation network-sdn]$ oc create -f todo-db.yaml
deployment.apps/mysql created
service/mysql created
[student@workstation network-sdn]$ oc status
In project network-sdn on server https://api.ocp4.example.com:6443

svc/mysql - 172.30.208.61:3306
  deployment/mysql deploys registry.redhat.io/rhel8/mysql-80:1
    deployment #1 running for 17 seconds - 0/1 pods


1 info identified, use 'oc status --suggest' to see details.
[student@workstation network-sdn]$ oc get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/mysql-68b778f957-slhr8   1/1     Running   0          30s

NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/mysql   ClusterIP   172.30.208.61   <none>        3306/TCP   30s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/mysql   1/1     1            1           30s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/mysql-68b778f957   1         1         1       30s
[student@workstation network-sdn]$ oct get pods
bash: oct: command not found...
[student@workstation network-sdn]$ oc get pods
NAME                     READY   STATUS    RESTARTS   AGE
mysql-68b778f957-slhr8   1/1     Running   0          66s
[student@workstation network-sdn]$ ls
db-data.sql  todo-db.yaml  todo-frontend.yaml
[student@workstation network-sdn]$ oc cp db-data.sql mysql-68b778f957-slhr8:/tmp/
[student@workstation network-sdn]$ oc rsh mysql-68b778f957-slhr8 /bin/bash
bash-4.4$ mysql -u root items < /tmp/db-data.sql
bash-4.4$ mysql -u root items -e "SHOW TABLES;"
+-----------------+
| Tables_in_items |
+-----------------+
| Item            |
+-----------------+
bash-4.4$ exit
exit
[student@workstation network-sdn]$ oc create -f todo-frontend.yaml
deployment.apps/frontend created
service/frontend created
[student@workstation network-sdn]$ oc get pods
NAME                        READY   STATUS              RESTARTS   AGE
frontend-85d58fb74c-q6ctw   0/1     ContainerCreating   0          9s
mysql-68b778f957-slhr8      1/1     Running             0          6m26s
[student@workstation network-sdn]$ oc expose service frontend --hostname todo.apps.ocp4.example.com
route.route.openshift.io/frontend exposed
[student@workstation network-sdn]$ oc get routes
NAME       HOST/PORT                    PATH   SERVICES   PORT   TERMINATION   WILDCARD
frontend   todo.apps.ocp4.example.com          frontend   8080                 None
[student@workstation network-sdn]$ oc logs frontend-85d58fb74c-q6ctw
App is ready at : 8080
[student@workstation network-sdn]$ oc get svc
NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
frontend   ClusterIP   172.30.200.47   <none>        8080/TCP   3m40s
mysql      ClusterIP   172.30.208.61   <none>        3306/TCP   9m57s
[student@workstation network-sdn]$ oc debug -t deployment/frontend
Starting pod/frontend-debug ...
Pod IP: 10.9.0.25
If you don't see a command prompt, try pressing enter.
sh-4.2$ curl -v telnet://172.30.208.61:3306
* About to connect() to 172.30.208.61 port 3306 (#0)
*   Trying 172.30.208.61...
* Connected to 172.30.208.61 (172.30.208.61) port 3306 (#0)
J
8.0.30
* RCVD IAC 2
* RCVD IAC 223

* RCVD IAC 135
^C
sh-4.2$ exit
exit

Removing debug pod ...
[student@workstation network-sdn]$ oc debug -t deployment/mysql --image registry.access.redhat.com/ubi8/ubi:8.4
Starting pod/mysql-debug ...
Pod IP: 10.8.0.45
If you don't see a command prompt, try pressing enter.
sh-4.4$ 
sh-4.4$ curl -m 10 -v http://172.30.200.47:8080
* Rebuilt URL to: http://172.30.200.47:8080/
*   Trying 172.30.200.47...
* TCP_NODELAY set
* Connection timed out after 10000 milliseconds
* Closing connection 0
curl: (28) Connection timed out after 10000 milliseconds
sh-4.4$ exit
exit

Removing debug pod ...
[student@workstation network-sdn]$ oc get pods -o wide -l name=frontend
NAME                        READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES
frontend-85d58fb74c-q6ctw   1/1     Running   0          8m41s   10.9.0.24   master01   <none>           <none>
[student@workstation network-sdn]$ oc debug -t deployment/mysql --image registry.access.redhat.com/ubi8/ubi:8.4
Starting pod/mysql-debug ...
Pod IP: 10.8.0.46
If you don't see a command prompt, try pressing enter.
sh-4.4$ curl -v http://10.9.0.24:8080/todo/
*   Trying 10.9.0.24...
* TCP_NODELAY set
* Connected to 10.9.0.24 (10.9.0.24) port 8080 (#0)
> GET /todo/ HTTP/1.1
> Host: 10.9.0.24:8080
> User-Agent: curl/7.61.1
> Accept: */*
> 
< HTTP/1.1 200 OK
< Server: restify
< Cache-Control: public, max-age=3600
< Content-Length: 4508
< Content-Type: text/html
< Last-Modified: Thu, 05 Dec 2019 22:50:51 GMT
< Connection: Keep-Alive
< Date: Wed, 26 Oct 2022 17:38:31 GMT
< Request-Id: 298c2003-66fd-42ab-8089-d7e8e24f4136
< Response-Time: 10
< 
<!DOCTYPE html>

<html ng-app="items">
<head>
    <title>To Do List</title>

    <link rel="stylesheet" href="lib/dependencies/css/bootstrap.min.css" />
    <link rel="stylesheet" href="lib/dependencies/css/ng-grid.min.css" />

    <!-- build:css css/application.css -->
    <link rel="stylesheet" type="text/css" href="css/style.css"/>
    <!-- endbuild -->

    <script src="lib/dependencies/jquery.min.js"></script>
    <script src="lib/dependencies/angular.min.js"></script>
    <script src="lib/dependencies/angular-resource.min.js"></script>
    <script src="lib/dependencies/ng-grid-2.0.11.min.js"></script>
    <script src="lib/dependencies/ui-bootstrap-tpls.min.js"></script>

    <!-- build:js script/all.js -->
    <script src="script/item.js"></script>
    <!-- endbuild -->
</head>

<body>

<h1>To Do List Application</h1>

<br/>

<!-- Specify a Angular controller script that binds Javascript variables to the feedback messages.-->
<div class="message" ng-controller="alertMessagesController">
    <alert ng-repeat="alert in alerts" type="{{alert.type}}" close="closeAlert($index)">{{alert.msg}}</alert>
</div>

<br>

<!-- Specify a Angular controller script that binds Javascript variables to the grid.-->
<div class="grid" ng-controller="itemsListController">
    <div>
        <h3>To Do List</h3>
    </div>

    <!-- Binds the grid component to be displayed. -->
    <div class="gridStyle" ng-grid="gridOptions"></div>

    <!--  Bind the pagination component to be displayed. -->
    <pagination direction-links="true" boundary-links="true"
                total-items="items.totalResults" items-per-page="items.pageSize"
                ng-model="items.currentPage" ng-change="refreshGrid()">
    </pagination>
</div>

<!-- Specify a Angular controller script that binds Javascript variables to the form.-->
<div class="form" ng-controller="itemsFormController">
    <!-- Verify item, if there is no id present, that we are Adding a Item -->
    <div ng-if="item.id == null">
        <h3>Add Task</h3>
    </div>
    <!-- Otherwise it's an Edit -->
    <div ng-if="item.id != null">
        <h3>Edit Task</h3>
    </div>

    <div>
        <!-- Specify the function to be called on submit and disable HTML5 validation, since we're using Angular validation-->
        <form name="itemForm" ng-submit="updateItem()" novalidate>

            <!-- Display an error if the input is invalid and is dirty (only when someone changes the value) -->
            <div class="form-group" ng-class="{'has-error' : itemForm.description.$invalid && itemForm.description.$dirty}">
                <label for="description">Description:</label>
                <!-- Display a check when the field is valid and was modified -->
                <span ng-class="{'glyphicon glyphicon-ok' : itemForm.description.$valid && itemForm.description.$dirty}"></span>

                <input id="description" name="description" type="text" class="form-control" maxlength="100"
                       ng-model="item.description"
                       required ng-minlength="5" ng-maxlength="100"/>

                <!-- Validation messages to be displayed on required, minlength and maxlength -->
                <p class="help-block" ng-show="itemForm.description.$error.required">Add Description.</p>
                <p class="help-block" ng-show="itemForm.description.$error.minlength">Description must be at least 5 characters long.</p>
                <p class="help-block" ng-show="itemForm.description.$error.maxlength">Description cannot be longer than 100 characters.</p>
            </div>

            <div class="form-group" ng-class="{'has-error' : itemForm.done.$invalid && itemForm.done.$dirty}">
                <label for="done">Completed:</label>
                <!-- Display a check when the field is valid and was modified -->
                <span ng-class="{'glyphicon glyphicon-ok' : itemForm.done.$valid && itemForm.done.$dirty}"></span>

                <input id="done" name="done" type="checkbox" class="form-control"
                       ng-model="item.done" />

            </div>

            <!-- Form buttons. The 'Save' button is only enabled when the form is valid. -->
            <div class="buttons">
                <button type="button" class="btn btn-primary" ng-click="clearForm()">Clear</button>
                <button type="submit" class="btn btn-primary" ng-disabled="itemForm.$invalid">Save</button>
            </div>
        </form>
    </div>
</div>

</body>
</html>
* Connection #0 to host 10.9.0.24 left intact
sh-4.4$ exit
exit

Removing debug pod ...
[student@workstation network-sdn]$ oc get svc
NAME       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
frontend   ClusterIP   172.30.200.47   <none>        8080/TCP   12m
mysql      ClusterIP   172.30.208.61   <none>        3306/TCP   19m
[student@workstation network-sdn]$ oc describe svc frontend
Name:              frontend
Namespace:         network-sdn
Labels:            app=todonodejs
                   name=frontend
Annotations:       <none>
Selector:          name=api
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.200.47
IPs:               172.30.200.47
Port:              <unset>  8080/TCP
TargetPort:        8080/TCP
Endpoints:         <none>
Session Affinity:  None
Events:            <none>
[student@workstation network-sdn]$ oc describe svc mysql
Name:              mysql
Namespace:         network-sdn
Labels:            app=todonodejs
                   name=mysql
Annotations:       <none>
Selector:          name=mysql
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.208.61
IPs:               172.30.208.61
Port:              <unset>  3306/TCP
TargetPort:        3306/TCP
Endpoints:         10.9.0.23:3306
Session Affinity:  None
Events:            <none>
[student@workstation network-sdn]$ oc get pod -o wide
NAME                        READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
frontend-85d58fb74c-q6ctw   1/1     Running   0          13m   10.9.0.24   master01   <none>           <none>
mysql-68b778f957-slhr8      1/1     Running   0          20m   10.9.0.23   master01   <none>           <none>
[student@workstation network-sdn]$ oc describe deployment/frontend | grep -A1 Labels
Labels:                 app=todonodejs
                        name=frontend
--
  Labels:  app=todonodejs
           name=frontend
[student@workstation network-sdn]$ oc edit svc/frontend
service/frontend edited
[student@workstation network-sdn]$ oc describe svc/frontend
Name:              frontend
Namespace:         network-sdn
Labels:            app=todonodejs
                   name=frontend
Annotations:       <none>
Selector:          name=frontend
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                172.30.200.47
IPs:               172.30.200.47
Port:              <unset>  8080/TCP
TargetPort:        8080/TCP
Endpoints:         10.9.0.24:8080
Session Affinity:  None
Events:            <none>
[student@workstation network-sdn]$ cd
[student@workstation ~]$ oc delete project network-sdn
project.project.openshift.io "network-sdn" deleted
[student@workstation ~]$ lab network-sdn finish

Completing Guided Exercise: Troubleshooting OpenShift Software-Defined Networking

 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
-------------------------------------------------------------27oct2022------------------------------------------

[student@workstation ~]$ lab network-ingress start

Checking prerequisites for Guided Exercise: Controlling Cluster Network Ingress

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'network-ingress' project is absent.....................  SUCCESS

Setting up the classroom for Guided Exercise: Controlling Cluster Network Ingress

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 Preparing Workstation:
 · Download exercise files.....................................  SUCCESS
 Configuring Certificates:
 · Generating unique CA key password...........................  SUCCESS
 · Setting environment variable in cert. configuration file....  SUCCESS
 · Generating the CA key.......................................  SUCCESS
 · Generating CA certificate...................................  SUCCESS
 · Updating privileges on certs directory......................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project network-ingress
Now using project "network-ingress" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc create -f ~/DO280/labs/network-ingress/todo-app-v1.yaml
deployment.apps/todo-http created
service/todo-http created
[student@workstation ~]$ cat !$
cat ~/DO280/labs/network-ingress/todo-app-v1.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: todo-http
  labels:
    app: todo-http
    name: todo-http
  namespace: network-ingress
spec:
  replicas: 1
  selector:
    matchLabels:
      app: todo-http
      name: todo-http
  template:
    metadata:
      labels:
        app: todo-http
        name: todo-http
    spec:
      containers:
      - resources:
          limits:
            cpu: '0.5'
        image: quay.io/redhattraining/todo-angular:v1.1
        name: todo-http
        ports:
        - containerPort: 8080
          name: todo-http
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: todo-http
    name: todo-http
  name: todo-http
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    name: todo-http[student@workstation ~]$ oc status
In project network-ingress on server https://api.ocp4.example.com:6443

svc/todo-http - 172.30.150.207:80 -> 8080
  deployment/todo-http deploys quay.io/redhattraining/todo-angular:v1.1
    deployment #1 running for 37 seconds - 1 pod


1 info identified, use 'oc status --suggest' to see details.
[student@workstation ~]$ oc expose svc todo-http --hostname todo-http.apps.ocp4.example.com
route.route.openshift.io/todo-http exposed
[student@workstation ~]$ oct get routes
bash: oct: command not found...
[student@workstation ~]$ oc get routes
NAME        HOST/PORT                         PATH   SERVICES    PORT   TERMINATION   WILDCARD
todo-http   todo-http.apps.ocp4.example.com          todo-http   8080                 None
[student@workstation ~]$ cd ~/DO280/labs/network-ingressoc create route edge todo-https --service todo-http --hostname todo-https.apps.ocp4.example.com
bash: cd: too many arguments
[student@workstation ~]$ cd ~/DO280/labs/network-ingress
[student@workstation network-ingress]$ oc create route edge todo-https --service todo-http --hostname todo-https.apps.ocp4.example.com
route.route.openshift.io/todo-https created
[student@workstation network-ingress]$ oc get svc todo-http -o jsonpath="{.spec.clusterIP}{'\n'}"
172.30.150.207
[student@workstation network-ingress]$ oc debug -t deployment/todo-http --image registry.access.redhat.com/ubi8/ubi:8.4
Starting pod/todo-http-debug ...

Pod IP: 10.8.0.35
If you don't see a command prompt, try pressing enter.
sh-4.4$ 
sh-4.4$ curl -v 172.30.102.29
* Rebuilt URL to: 172.30.102.29/
*   Trying 172.30.102.29...
* TCP_NODELAY set
* connect to 172.30.102.29 port 80 failed: No route to host
* Failed to connect to 172.30.102.29 port 80: No route to host
* Closing connection 0
curl: (7) Failed to connect to 172.30.102.29 port 80: No route to host
sh-4.4$ curl -v 172.30.150.207
* Rebuilt URL to: 172.30.150.207/
*   Trying 172.30.150.207...
* TCP_NODELAY set
* Connected to 172.30.150.207 (172.30.150.207) port 80 (#0)
> GET / HTTP/1.1
> Host: 172.30.150.207
> User-Agent: curl/7.61.1
> Accept: */*
> 
< HTTP/1.1 200 OK
< Server: nginx/1.14.1
< Date: Thu, 27 Oct 2022 14:23:38 GMT
< Content-Type: text/html
< Transfer-Encoding: chunked
< Connection: keep-alive
< 
<!DOCTYPE html>
<html lang="en" ng-app="todoItemsApp" ng-controller="appCtl">
<head>
    <meta charset="utf-8">
    <title>ToDo app</title>

    <link rel="stylesheet" href="assets/css/libs/bootstrap/bootstrap.css">
    <link rel="stylesheet" href="assets/css/libs/angular-motion/angular-motion.css">
    <link rel="stylesheet" href="assets/css/libs/angular-xeditable/xeditable.css">

    <link rel="stylesheet" href="assets/css/app.css">

    <script type="text/javascript" src="assets/js/libs/jquery/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="assets/js/libs/bootstrap/bootstrap.min.js"></script>
    <script type="text/javascript" src="assets/js/libs/angular/angular.min.js"></script>

    <script type="text/javascript" src="assets/js/libs/angular/angular-route.min.js"></script>
    <script type="text/javascript" src="assets/js/libs/angular/angular-animate.min.js"></script>

    <script type="text/javascript" src="assets/js/libs/angular-ui-router/angular-ui-router.js"></script>

    <script type="text/javascript" src="assets/js/libs/angular-strap/angular-strap.js"></script>
    <script type="text/javascript" src="assets/js/libs/angular-strap/angular-strap.tpl.js"></script>
    <script type="text/javascript" src="assets/js/libs/angular-xeditable/xeditable.js"></script>

    <script type="text/javascript" src="assets/js/libs/angular/angular-sanitize.js"></script>
    <script type="text/javascript" src="assets/js/app/utils/md5.js"></script>

    <script type="text/javascript" src="assets/js/app/module.js"></script>
    <script type="text/javascript" src="assets/js/app/states/states.js"></script>

    <script type="text/javascript" src="assets/js/app/domain/todoitems.js"></script>
    <script type="text/javascript" src="assets/js/app/ui/filters.js"></script>

    <script type="text/javascript" src="assets/js/app/ui/focus.js"></script>
    <script type="text/javascript" src="assets/js/app/ui/gravatar.js"></script>
    <script type="text/javascript" src="assets/js/app/ui/editable.js"></script>
</head>
<body>

<nav class="navbar navbar-default" role="navigation">
    <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#nav-toggle">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="/">ToDo App</a>
    </div>
    <div class="collapse navbar-collapse" id="nav-toggle">
        <ul class="nav navbar-nav">
            <li ui-sref-active="active"><a ui-sref="list">Browse</a></li>
            <li ui-sref-active="active"><a ui-sref="create">Create</a></li>
        </ul>
        <form class="navbar-form navbar-right" role="search">
            <input type="text" class="form-control" placeholder="Search" ng-model="search.description" ng-keyup="startSearch()">
        </form>
    </div>

</nav>
<div class="container">
    <div ui-view></div>
</div>

</body>
* Connection #0 to host 172.30.150.207 left intact
</html>sh-4.4$ exit
exit

Removing debug pod ...
[student@workstation network-ingress]$ oc delete route todo-https
route.route.openshift.io "todo-https" deleted
[student@workstation network-ingress]$ cd certs
[student@workstation certs]$ ls -l
total 20
-rw-rw-r--. 1 student student  566 Aug  8 14:21 openssl-commands.txt
-rw-rw-r--. 1 student student   33 Oct 27 10:08 passphrase.txt
-rw-------. 1 student student 1751 Oct 27 10:08 training-CA.key
-rw-r--r--. 1 student student 1334 Oct 27 10:08 training-CA.pem
-rw-r--r--. 1 student student  352 Oct 27 10:08 training.ext
[student@workstation certs]$ cat openssl-commands.txt 
## Run the following command to create the private key

openssl genrsa -out training.key 4096

## Run the following command to generate a certificate signing request

openssl req -new \
  -subj "/C=US/ST=North Carolina/L=Raleigh/O=Red Hat/CN=todo-https.apps.ocp4.example.com" \
  -key training.key -out training.csr

## Run the following command to generate a certificate

openssl x509 -req -in training.csr \
  -passin file:passphrase.txt \
  -CA training-CA.pem -CAkey training-CA.key -CAcreateserial \
  -out training.crt -days 1825 -sha256 -extfile training.ext
[student@workstation certs]$ openssl genrsa -out training.key 4096
Generating RSA private key, 4096 bit long modulus (2 primes)
...........................................................................++++
...................................................................................................................................++++
e is 65537 (0x010001)
[student@workstation certs]$ openssl req -new -key training.key -out training.csr -subj "/C=US/ST=North Carolina/L=Raleigh/O=Red Hat/ CN=todo-https.apps.ocp4.example.com"
req: Skipping unknown attribute " CN"
[student@workstation certs]$ openssl x509 -req -in training.csr -passin file:passphrase.txt -CA training-CA.pem -CAkey training-CA.key -CAcreateserial -out training.crt -days 1825 -sha256 -extfile training.ext
Signature ok
subject=C = US, ST = North Carolina, L = Raleigh, O = Red Hat
Getting CA Private Key
[student@workstation certs]$ ls -lhrt
total 36K
-rw-rw-r--. 1 student student  566 Aug  8 14:21 openssl-commands.txt
-rw-rw-r--. 1 student student   33 Oct 27 10:08 passphrase.txt
-rw-r--r--. 1 student student  352 Oct 27 10:08 training.ext
-rw-------. 1 student student 1.8K Oct 27 10:08 training-CA.key
-rw-r--r--. 1 student student 1.4K Oct 27 10:08 training-CA.pem
-rw-------. 1 student student 3.2K Oct 27 10:25 training.key
-rw-rw-r--. 1 student student 1.7K Oct 27 10:26 training.csr
-rw-rw-r--. 1 student student   41 Oct 27 10:27 training-CA.srl
-rw-rw-r--. 1 student student 1.7K Oct 27 10:27 training.crt
[student@workstation certs]$ cd ~/DO280/labs/network-ingress
[student@workstation network-ingress]$ oc create secret tls todo-certs --cert certs/training.crt --key certs/training.key
secret/todo-certs created
[student@workstation network-ingress]$ oc create -f todo-app-v2.yaml
deployment.apps/todo-https created
service/todo-https created
[student@workstation network-ingress]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
todo-http-c87b84b48-q4m5m     1/1     Running   0          18m
todo-https-6c87f66c89-j2lww   1/1     Running   0          16s
[student@workstation network-ingress]$ oc describe pod todo-https-6c87f66c89-j2lww | grep -A2 Mounts
    Mounts:
      /usr/local/etc/ssl/certs from tls-certs (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xd2f9 (ro)
[student@workstation network-ingress]$ oc create route passthrough todo-https --service todo-https --port 8443 --hostname todo-https.apps.ocp4.example.com
route.route.openshift.io/todo-https created
[student@workstation network-ingress]$ curl -vv -I --cacert certs/training-CA.pem https://todo-https.apps.ocp4.example.com
* Rebuilt URL to: https://todo-https.apps.ocp4.example.com/
*   Trying 192.168.50.254...
* TCP_NODELAY set
* Connected to todo-https.apps.ocp4.example.com (192.168.50.254) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: certs/training-CA.pem
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server accepted to use h2
* Server certificate:
*  subject: C=US; ST=North Carolina; L=Raleigh; O=Red Hat
*  start date: Oct 27 14:27:57 2022 GMT
*  expire date: Oct 26 14:27:57 2027 GMT
*  subjectAltName: host "todo-https.apps.ocp4.example.com" matched cert's "*.apps.ocp4.example.com"
*  issuer: C=US; ST=North Carolina; L=Raleigh; O=Red Hat; CN=ocp4.example.com
*  SSL certificate verify ok.
* Using HTTP2, server supports multi-use
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x55c192ea16b0)
> HEAD / HTTP/2
> Host: todo-https.apps.ocp4.example.com
> User-Agent: curl/7.61.1
> Accept: */*
> 
* Connection state changed (MAX_CONCURRENT_STREAMS == 128)!
< HTTP/2 200 
HTTP/2 200 
< server: nginx/1.14.1
server: nginx/1.14.1
< date: Thu, 27 Oct 2022 14:32:16 GMT
date: Thu, 27 Oct 2022 14:32:16 GMT
< content-type: text/html
content-type: text/html
< content-length: 3017
content-length: 3017
< last-modified: Thu, 28 Nov 2019 19:53:20 GMT
last-modified: Thu, 28 Nov 2019 19:53:20 GMT
< etag: "5de025b0-bc9"
etag: "5de025b0-bc9"
< strict-transport-security: max-age=63072000; includeSubdomains
strict-transport-security: max-age=63072000; includeSubdomains
< x-frame-options: DENY
x-frame-options: DENY
< x-content-type-options: nosniff
x-content-type-options: nosniff
< accept-ranges: bytes
accept-ranges: bytes

< 
* Connection #0 to host todo-https.apps.ocp4.example.com left intact
[student@workstation network-ingress]$ oc get svc todo-https -o jsonpath="{.spec.clusterIP}{'\n'}"
172.30.223.194
[student@workstation network-ingress]$ oc debug -t deployment/todo-https --image registry.access.redhat.com/ubi8/ubi:8.4
Starting pod/todo-https-debug ...
Pod IP: 10.9.0.18
If you don't see a command prompt, try pressing enter.
sh-4.4$ curl -I 172.30.223.194
HTTP/1.1 301 Moved Permanently
Server: nginx/1.14.1
Date: Thu, 27 Oct 2022 14:34:01 GMT
Content-Type: text/html
Connection: keep-alive
Location: https://172.30.223.194:8443/

sh-4.4$ curl -s -k https://172.30.223.194:8443 | head -n5
<!DOCTYPE html>
<html lang="en" ng-app="todoItemsApp" ng-controller="appCtl">
<head>
    <meta charset="utf-8">
    <title>ToDo app</title>
sh-4.4$ exit
exit

Removing debug pod ...
[student@workstation network-ingress]$ cd
[student@workstation ~]$ oc delete project network-ingress
project.project.openshift.io "network-ingress" deleted
[student@workstation ~]$ lab network-ingress finish

Completing Guided Exercise: Controlling Cluster Network Ingress

 · Remove exercise files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
-----------------------------------------------------------------29Oct22-----------------------------------

[student@workstation ~]$ lab network-policy start

Checking prerequisites for Guided Exercise: Configuring Network Policies

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'network-policy' project is absent......................  SUCCESS
 · The 'network-test' project is absent........................  SUCCESS

Setting up the classroom for Guided Exercise: Configuring Network Policies

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 Preparing Workstation:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project network-policy
Now using project "network-policy" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc new-app --name hello --image quay.io/redhattraining/hello-world-nginx:v1.0
--> Found container image 44eaa13 (3 years old) from quay.io for "quay.io/redhattraining/hello-world-nginx:v1.0"

    Red Hat Universal Base Image 8 
    ------------------------------ 
    The Universal Base Image is designed and engineered to be the base layer for all of your containerized applications, middleware and utilities. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.

    Tags: base rhel8

    * An image stream tag will be created as "hello:v1.0" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "hello" created
    deployment.apps "hello" created
    service "hello" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/hello' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc status
In project network-policy on server https://api.ocp4.example.com:6443

svc/hello - 172.30.219.111:8080
  deployment/hello deploys istag/hello:v1.0 
    deployment #2 running for 23 seconds - 1 pod
    deployment #1 deployed 23 seconds ago


1 info identified, use 'oc status --suggest' to see details.
[student@workstation ~]$ oc get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/hello-787445fd88-2lqc6   1/1     Running   0          35s

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/hello   ClusterIP   172.30.219.111   <none>        8080/TCP   35s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/hello   1/1     1            1           35s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/hello-787445fd88   1         1         1       35s
replicaset.apps/hello-84959f84f5   0         0         0       35s

NAME                                   IMAGE REPOSITORY                                                        TAGS   UPDATED
imagestream.image.openshift.io/hello   image-registry.openshift-image-registry.svc:5000/network-policy/hello   v1.0   35 seconds ago
[student@workstation ~]$ oc expose service hello
route.route.openshift.io/hello exposed
[student@workstation ~]$ ~/DO280/labs/network-policy/display-project-info.sh
===================================================================
PROJECT: network-policy

POD NAME                 IP ADDRESS
hello-787445fd88-2lqc6   10.9.0.17

SERVICE NAME   CLUSTER-IP
hello          172.30.219.111

ROUTE NAME   HOSTNAME                                     PORT
hello        hello-network-policy.apps.ocp4.example.com   8080-tcp

===================================================================
[student@workstation ~]$ cat ~/DO280/labs/network-policy/display-project-info.sh
#!/usr/bin/bash

if oc get project -o jsonpath='{.items[*].metadata.name}' | grep -q network-policy
then
  echo "==================================================================="
  echo "PROJECT: network-policy"
  echo
  oc get pods -o custom-columns="POD NAME:.metadata.name,IP ADDRESS:.status.podIP" -n network-policy
  echo
  oc get svc -o custom-columns="SERVICE NAME:.metadata.name,CLUSTER-IP:.spec.clusterIP" -n network-policy
  echo
  oc get route -o custom-columns="ROUTE NAME:.metadata.name,HOSTNAME:.spec.host,PORT:.spec.port.targetPort" -n network-policy
  echo
  echo "==================================================================="
fi

if oc get project -o jsonpath='{.items[*].metadata.name}' | grep -q network-test
then
  echo "PROJECT: network-test"
  echo
  oc get pods -o custom-columns="POD NAME:.metadata.name" -n network-test
  echo
  echo "==================================================================="
fi
[student@workstation ~]$ oc get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/hello-787445fd88-2lqc6   1/1     Running   0          3m18s

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/hello   ClusterIP   172.30.219.111   <none>        8080/TCP   3m18s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/hello   1/1     1            1           3m18s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/hello-787445fd88   1         1         1       3m18s
replicaset.apps/hello-84959f84f5   0         0         0       3m18s

NAME                                   IMAGE REPOSITORY                                                        TAGS   UPDATED
imagestream.image.openshift.io/hello   image-registry.openshift-image-registry.svc:5000/network-policy/hello   v1.0   3 minutes ago

NAME                             HOST/PORT                                    PATH   SERVICES   PORT       TERMINATION   WILDCARD
route.route.openshift.io/hello   hello-network-policy.apps.ocp4.example.com          hello      8080-tcp                 None
[student@workstation ~]$ oc new-app --name test --image quay.io/redhattraining/hello-world-nginx:v1.0
--> Found container image 44eaa13 (3 years old) from quay.io for "quay.io/redhattraining/hello-world-nginx:v1.0"

    Red Hat Universal Base Image 8 
    ------------------------------ 
    The Universal Base Image is designed and engineered to be the base layer for all of your containerized applications, middleware and utilities. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.

    Tags: base rhel8

    * An image stream tag will be created as "test:v1.0" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "test" created
    deployment.apps "test" created
    service "test" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/test' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/hello-787445fd88-2lqc6   1/1     Running   0          4m34s
pod/test-54bc94685b-hmjp9    1/1     Running   0          8s

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/hello   ClusterIP   172.30.219.111   <none>        8080/TCP   4m34s
service/test    ClusterIP   172.30.246.126   <none>        8080/TCP   9s

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/hello   1/1     1            1           4m34s
deployment.apps/test    1/1     1            1           9s

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/hello-787445fd88   1         1         1       4m34s
replicaset.apps/hello-84959f84f5   0         0         0       4m34s
replicaset.apps/test-54bc94685b    1         1         1       8s
replicaset.apps/test-68bd9bc7c9    0         0         0       9s

NAME                                   IMAGE REPOSITORY                                                        TAGS   UPDATED
imagestream.image.openshift.io/hello   image-registry.openshift-image-registry.svc:5000/network-policy/hello   v1.0   4 minutes ago
imagestream.image.openshift.io/test    image-registry.openshift-image-registry.svc:5000/network-policy/test    v1.0   8 seconds ago

NAME                             HOST/PORT                                    PATH   SERVICES   PORT       TERMINATION   WILDCARD
route.route.openshift.io/hello   hello-network-policy.apps.ocp4.example.com          hello      8080-tcp                 None
[student@workstation ~]$ ~/DO280/labs/network-policy/display-project-info.sh
===================================================================
PROJECT: network-policy

POD NAME                 IP ADDRESS
hello-787445fd88-2lqc6   10.9.0.17
test-54bc94685b-hmjp9    10.9.0.18

SERVICE NAME   CLUSTER-IP
hello          172.30.219.111
test           172.30.246.126

ROUTE NAME   HOSTNAME                                     PORT
hello        hello-network-policy.apps.ocp4.example.com   8080-tcp

===================================================================
[student@workstation ~]$ oc rsh test-54bc94685b-hmjp9
sh-4.4$ curl 10.9.0.17:8080 | grep -i hello
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    72  100    72    0     0  36000      0 --:--:-- --:--:-- --:--:-- 36000
    <h1>Hello, world from nginx!</h1>
sh-4.4$ exit
exit
[student@workstation ~]$ oc rsh test-54bc94685b-hmjp9 curl 172.30.219.111:8080| grep -i hello
    <h1>Hello, world from nginx!</h1>
[student@workstation ~]$ curl hello-network-policy.apps.ocp4.example.com:8080| grep -i hello
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  4927  100  4927    0     0   601k      0 --:--:-- --:--:-- --:--:--  601k
[student@workstation ~]$ 
[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You have one project on this server: "network-policy"

Using project "network-policy".
[student@workstation ~]$ oc get all
NAME                         READY   STATUS    RESTARTS   AGE
pod/hello-787445fd88-2lqc6   1/1     Running   0          20m
pod/test-54bc94685b-hmjp9    1/1     Running   0          15m

NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/hello   ClusterIP   172.30.219.111   <none>        8080/TCP   20m
service/test    ClusterIP   172.30.246.126   <none>        8080/TCP   15m

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/hello   1/1     1            1           20m
deployment.apps/test    1/1     1            1           15m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/hello-787445fd88   1         1         1       20m
replicaset.apps/hello-84959f84f5   0         0         0       20m
replicaset.apps/test-54bc94685b    1         1         1       15m
replicaset.apps/test-68bd9bc7c9    0         0         0       15m

NAME                                   IMAGE REPOSITORY                                                        TAGS   UPDATED
imagestream.image.openshift.io/hello   image-registry.openshift-image-registry.svc:5000/network-policy/hello   v1.0   20 minutes ago
imagestream.image.openshift.io/test    image-registry.openshift-image-registry.svc:5000/network-policy/test    v1.0   15 minutes ago

NAME                             HOST/PORT                                    PATH   SERVICES   PORT       TERMINATION   WILDCARD
route.route.openshift.io/hello   hello-network-policy.apps.ocp4.example.com          hello      8080-tcp                 None
[student@workstation ~]$ oc new-project network-test
Now using project "network-test" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc new-app --name sample-app --image quay.io/redhattraining/hello-world-nginx:v1.0
--> Found container image 44eaa13 (3 years old) from quay.io for "quay.io/redhattraining/hello-world-nginx:v1.0"

    Red Hat Universal Base Image 8 
    ------------------------------ 
    The Universal Base Image is designed and engineered to be the base layer for all of your containerized applications, middleware and utilities. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.

    Tags: base rhel8

    * An image stream tag will be created as "sample-app:v1.0" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "sample-app" created
    deployment.apps "sample-app" created
    service "sample-app" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/sample-app' 
    Run 'oc status' to view your app.
[student@workstation ~]$ ~/DO280/labs/network-policy/display-project-info.sh
===================================================================
PROJECT: network-policy

POD NAME                 IP ADDRESS
hello-787445fd88-2lqc6   10.9.0.17
test-54bc94685b-hmjp9    10.9.0.18

SERVICE NAME   CLUSTER-IP
hello          172.30.219.111
test           172.30.246.126

ROUTE NAME   HOSTNAME                                     PORT
hello        hello-network-policy.apps.ocp4.example.com   8080-tcp

===================================================================
PROJECT: network-test

POD NAME
sample-app-7cf4f6ff64-t8q9n

===================================================================
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
sample-app-7cf4f6ff64-t8q9n   1/1     Running   0          103s
[student@workstation ~]$ oc rsh sample-app-7cf4f6ff64-t8q9n curl 10.9.0.17:8080| grep -i hello
    <h1>Hello, world from nginx!</h1>
[student@workstation ~]$ oc rsh sample-app-7cf4f6ff64-t8q9n curl 10.9.0.18:8080| grep -i hello
    <h1>Hello, world from nginx!</h1>
[student@workstation ~]$ oc project network-policy
Now using project "network-policy" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ cd ~/DO280/labs/network-policy
[student@workstation network-policy]$ ls
allow-from-openshift-ingress.yaml  allow-specific.yaml  deny-all.yaml  display-project-info.sh
[student@workstation network-policy]$ cat deny-all.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-all
spec:
[student@workstation network-policy]$ oc create -f deny-all.yaml
networkpolicy.networking.k8s.io/deny-all created
[student@workstation network-policy]$ curl hello-network-policy.apps.ocp4.example.com | grep -i hello
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0^C
[student@workstation network-policy]$ oc rsh test-54bc94685b-hmjp9 curl 10.9.0.17:8080| grep -i hello
command terminated with exit code 130
[student@workstation network-policy]$ oc project network-test
Now using project "network-test" on server "https://api.ocp4.example.com:6443".
[student@workstation network-policy]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
sample-app-7cf4f6ff64-t8q9n   1/1     Running   0          10m
[student@workstation network-policy]$ oc rsh sample-app-7cf4f6ff64-t8q9n curl 10.9.0.18:8080| grep -i hello
command terminated with exit code 130
[student@workstation network-policy]$ pwd
/home/student/DO280/labs/network-policy
[student@workstation network-policy]$ ls
allow-from-openshift-ingress.yaml  allow-specific.yaml  deny-all.yaml  display-project-info.sh
[student@workstation network-policy]$ cat allow-specific.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-specific
spec:
  podSelector:
    matchLabels:
      deployment: CHANGE_ME
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: CHANGE_ME
        podSelector:
          matchLabels:
            deployment: CHANGE_ME
      ports:
      - port: CHANGE_ME
        protocol: CHANGE_ME
[student@workstation network-policy]$ cd ~/DO280/solutions/network-policy/
[student@workstation network-policy]$ pwd
/home/student/DO280/solutions/network-policy
[student@workstation network-policy]$ ls
allow-from-openshift-ingress.yaml  allow-specific.yaml  deny-all.yaml
[student@workstation network-policy]$ cat allow-specific.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-specific
spec:
  podSelector:
    matchLabels:
      deployment: hello
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: network-test
        podSelector:
          matchLabels:
            deployment: sample-app
      ports:
      - port: 8080
        protocol: TCP
[student@workstation network-policy]$ oc create -n network-policy -f allow-specific.yaml
networkpolicy.networking.k8s.io/allow-specific created
[student@workstation network-policy]$ oc get networkpolicies -n network-policy
NAME             POD-SELECTOR       AGE
allow-specific   deployment=hello   24s
deny-all         <none>             7m34s
[student@workstation network-policy]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "network-test".
[student@workstation network-policy]$ oc label namespace network-test name=network-test
namespace/network-test labeled
[student@workstation network-policy]$ oc describe namespace network-test| grep -i lable
[student@workstation network-policy]$ oc describe namespace network-test| grep -i labels
Labels:       kubernetes.io/metadata.name=network-test
[student@workstation network-policy]$ oc describe namespace network-test
Name:         network-test
Labels:       kubernetes.io/metadata.name=network-test
              name=network-test
Annotations:  openshift.io/description: 
              openshift.io/display-name: 
              openshift.io/requester: developer
              openshift.io/sa.scc.mcs: s0:c26,c20
              openshift.io/sa.scc.supplemental-groups: 1000690000/10000
              openshift.io/sa.scc.uid-range: 1000690000/10000
Status:       Active

No resource quota.

No LimitRange resource.
[student@workstation network-policy]$ oc login -u developer -p developer
Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

    network-policy
  * network-test

Using project "network-test".
[student@workstation network-policy]$ oc project network-test
Already on project "network-test" on server "https://api.ocp4.example.com:6443".
[student@workstation network-policy]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
sample-app-7cf4f6ff64-t8q9n   1/1     Running   0          17m
[student@workstation network-policy]$ oc rsh sample-app-7cf4f6ff64-t8q9n curl 10.9.0.17:8080| grep -i hello
    <h1>Hello, world from nginx!</h1>
[student@workstation network-policy]$ oc rsh sample-app-7cf4f6ff64-t8q9n curl 10.9.0.18:8080| grep -i hello
command terminated with exit code 130
[student@workstation network-policy]$ ls
allow-from-openshift-ingress.yaml  allow-specific.yaml  deny-all.yaml
[student@workstation network-policy]$ cat allow-from-openshift-ingress.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-from-openshift-ingress
spec:
  podSelector: {}
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          network.openshift.io/policy-group: ingress
[student@workstation network-policy]$ oc create -n network-policy -f allow-from-openshift-ingress.yaml 
networkpolicy.networking.k8s.io/allow-from-openshift-ingress created
[student@workstation network-policy]$ oc get networkpolicies -n network-policy
NAME                           POD-SELECTOR       AGE
allow-from-openshift-ingress   <none>             18s
allow-specific                 deployment=hello   7m44s
deny-all                       <none>             14m
[student@workstation network-policy]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "network-test".
[student@workstation network-policy]$ oc label namespace default network.openshift.io/policy-group=ingress
namespace/default labeled
[student@workstation network-policy]$ curl -s hello-network-policy.apps.ocp4.example.com | grep -i hello
    <h1>Hello, world from nginx!</h1>
[student@workstation network-policy]$ cd
[student@workstation ~]$ lab network-policy finish

Completing Guided Exercise: Configuring Network Policies

 · Delete OpenShift project 'network-policy'...................  SUCCESS
 · Wait for project 'network-policy' to be gone................  SUCCESS
 · Delete OpenShift project 'network-test'.....................  SUCCESS
 · Wait for project 'network-test' to be gone..................  SUCCESS
 · Remove network.openshift.io/policy-group=ingress label from 
   the default project.........................................  SUCCESS
 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 

--------------------------------------------------------31Oct22------------------------------------------------------------
[student@workstation ~]$ lab network-review start

Checking prerequisites for Lab: Configuring OpenShift Networking for Applications

 Verify the OpenShift cluster is running:
 · Waiting up to 5 minutes for router pods to be available.....  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'network-review' project is absent......................  SUCCESS

Setting up the classroom for Lab: Configuring OpenShift Networking for Applications

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS
 Preparing Workstation:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS
 Configuring Certificates:
 · Generating unique CA key password...........................  SUCCESS
 · Setting environment variable in cert. configuration file....  SUCCESS
 · Generating the CA key.......................................  SUCCESS
 · Generating CA certificate...................................  SUCCESS
 · Creating private key........................................  SUCCESS
 · Updating privileges on certs directory......................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project network-review
Now using project "network-review" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ cd ~/DO280/labs/network-review
[student@workstation network-review]$ vi php-http.yaml 
[student@workstation network-review]$ cat php-http.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: php-http
  labels:
    app: php-http
    name: php-http
  namespace: network-review
spec:
  replicas: 1
  selector:
    matchLabels:
      app: php-http
      name: php-http
  template:
    metadata:
      labels:
        app: php-http
        name: php-http
    spec:
      containers:
      - resources:
          limits:
            memory: "128Mi"
            cpu: '0.5'
        # Set the container image name
        image: 'quay.io/redhattraining/php-ssl:v1.0'
        name: php-http
        ports:
          # Define the container port
        - containerPort: 8080
          name: php-http
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: php-http
    name: php-http
  name: php-http
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    name: php-http
[student@workstation network-review]$ oc create -f php-http.yaml
deployment.apps/php-http created
service/php-http created
[student@workstation network-review]$ oc get pods
NAME                        READY   STATUS    RESTARTS   AGE
php-http-5664cc5fbb-s7h7g   1/1     Running   0          20s
[student@workstation network-review]$ oc expose svc php-http --hostname php-http.apps.ocp4.example.com
route.route.openshift.io/php-http exposed
[student@workstation network-review]$ oc get routes
NAME       HOST/PORT                        PATH   SERVICES   PORT   TERMINATION   WILDCARD
php-http   php-http.apps.ocp4.example.com          php-http   8080                 None
[student@workstation network-review]$ cd ~/DO280/labs/network-review/
[student@workstation network-review]$ ls
allow-from-openshift-ingress.yaml  certs  deny-all.yaml  php-https.yaml  php-http.yaml
[student@workstation network-review]$ cat deny-all.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-all
spec:
[student@workstation network-review]$ vi deny-all.yaml 
[student@workstation network-review]$ cat deny-all.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-all
spec:
 podSelector: {}       
[student@workstation network-review]$ oc create -f deny-all.yaml
networkpolicy.networking.k8s.io/deny-all created
[student@workstation network-review]$ http://php-http.apps.ocp4.example.com
bash: http://php-http.apps.ocp4.example.com: No such file or directory
[student@workstation network-review]$ curl http://php-http.apps.ocp4.example.com
^C
[student@workstation network-review]$ ls
allow-from-openshift-ingress.yaml  certs  deny-all.yaml  php-https.yaml  php-http.yaml
[student@workstation network-review]$ cat allow-from-openshift-ingress.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-from-openshift-ingress
spec:
  ingress:
[student@workstation network-review]$ vi allow-from-openshift-ingress.yaml 
[student@workstation network-review]$ oc create -f allow-from-openshift-ingress.yaml 
error: error parsing allow-from-openshift-ingress.yaml: error converting YAML to JSON: yaml: line 6: did not find expected key
[student@workstation network-review]$ vi allow-from-openshift-ingress.yaml 
[student@workstation network-review]$ vi allow-from-openshift-ingress.yaml 
[student@workstation network-review]$ oc create -f allow-from-openshift-ingress.yaml 
networkpolicy.networking.k8s.io/allow-from-openshift-ingress created
[student@workstation network-review]$ cat allow-from-openshift-ingress.yaml 
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: allow-from-openshift-ingress
spec:
  podSelector: {}       
  ingress:
  - from:
     - namespaceSelector:
          matchLabels:
             network.openshift.io/policy-group: ingress      
[student@workstation network-review]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "network-review".
[student@workstation network-review]$ oc label namespace default network.openshift.io/policy-group=ingress
namespace/default labeled
[student@workstation network-review]$ for X in {1..4};do curl -s http://php-http.apps.ocp4.example.com | grep "PHP";done
    <title>PHP Application</title>
    <title>PHP Application</title>
    <title>PHP Application</title>
    <title>PHP Application</title>
[student@workstation network-review]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "network-review"

Using project "network-review".
[student@workstation network-review]$ cd certs
[student@workstation certs]$ openssl req -new -key training.key -subj "/C=US/ST=North Carolina/L=Raleigh/O=Red Hat/CN=php-https.apps.ocp4.example.com" -out training.csr
[student@workstation certs]$ ls -lhrt
total 28K
-rw-rw-r--. 1 student student  566 Aug  8 14:21 openssl-commands.txt
-rw-rw-r--. 1 student student   33 Oct 31 12:32 passphrase.txt
-rw-r--r--. 1 student student  352 Oct 31 12:32 training.ext
-rw-------. 1 student student 1.8K Oct 31 12:32 training-CA.key
-rw-r--r--. 1 student student 1.4K Oct 31 12:32 training-CA.pem
-rw-------. 1 student student 1.7K Oct 31 12:32 training.key
-rw-rw-r--. 1 student student 1021 Oct 31 12:52 training.csr
[student@workstation certs]$ cat openssl-commands.txt 
## Run the following command to generate a certificate signing request
## Update where necessary before running the command!

openssl req -new -key training.key \
  -subj "/C=US/ST=North Carolina/L=Raleigh/O=Red Hat/CN=php-https.<WILDCARD DOMAIN>" \
  -out <EXPORT CSR>

## Run the following command to generate a certificate
## Update where necessary before running the command!

openssl x509 -req -in <CSR FILE> \
  -CA <CA FILE> -CAkey training-CA.key -CAcreateserial \
  -passin file:passphrase.txt \
  -out <EXPORT CRT> -days 3650 -sha256 -extfile training.ext
[student@workstation certs]$ openssl x509 -req -in training.csr -CA training-CA.pem -CAkey training-CA.key -CAcreateserial -passin file:passphrase.txt -out training.crt -days 3650 -sha256 -extfile training.ext
Signature ok
subject=C = US, ST = North Carolina, L = Raleigh, O = Red Hat, CN = php-https.apps.ocp4.example.com
Getting CA Private Key
[student@workstation certs]$ ls -lhrt
total 36K
-rw-rw-r--. 1 student student  566 Aug  8 14:21 openssl-commands.txt
-rw-rw-r--. 1 student student   33 Oct 31 12:32 passphrase.txt
-rw-r--r--. 1 student student  352 Oct 31 12:32 training.ext
-rw-------. 1 student student 1.8K Oct 31 12:32 training-CA.key
-rw-r--r--. 1 student student 1.4K Oct 31 12:32 training-CA.pem
-rw-------. 1 student student 1.7K Oct 31 12:32 training.key
-rw-rw-r--. 1 student student 1021 Oct 31 12:52 training.csr
-rw-rw-r--. 1 student student   41 Oct 31 12:54 training-CA.srl
-rw-rw-r--. 1 student student 1.4K Oct 31 12:54 training.crt
[student@workstation certs]$ cd ~/DO280/labs/network-review
[student@workstation network-review]$ oc create secret tls php-certs --cert certs/training.crt --key certs/training.key
secret/php-certs created
[student@workstation network-review]$ oc get seceret
error: the server doesn't have a resource type "seceret"
[student@workstation network-review]$ oc get secret
NAME                       TYPE                                  DATA   AGE
builder-dockercfg-nzzkn    kubernetes.io/dockercfg               1      22m
builder-token-8qdcs        kubernetes.io/service-account-token   4      22m
builder-token-fmtj9        kubernetes.io/service-account-token   4      22m
default-dockercfg-tz6jt    kubernetes.io/dockercfg               1      22m
default-token-2jm2w        kubernetes.io/service-account-token   4      22m
default-token-psg8n        kubernetes.io/service-account-token   4      22m
deployer-dockercfg-xps7m   kubernetes.io/dockercfg               1      22m
deployer-token-wx6x4       kubernetes.io/service-account-token   4      22m
deployer-token-z5dsl       kubernetes.io/service-account-token   4      22m
php-certs                  kubernetes.io/tls                     2      12s
[student@workstation network-review]$ oc describe secret php-certs
Name:         php-certs
Namespace:    network-review
Labels:       <none>
Annotations:  <none>

Type:  kubernetes.io/tls

Data
====
tls.crt:  1395 bytes
tls.key:  1679 bytes
[student@workstation network-review]$ vi php-https.yaml 
[student@workstation network-review]$ cat php-https.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: php-https
  labels:
    app: php-https
    name: php-https
  namespace: network-review
spec:
  replicas: 1
  selector:
    matchLabels:
      app: php-https
      name: php-https
  template:
    metadata:
      labels:
        app: php-https
        name: php-https
    spec:
      containers:
      - resources:
          limits:
            memory: "128Mi"
            cpu: '0.5'
        # Set the container image name
        image: 'quay.io/redhattraining/php-ssl:v1.1'
        name: php-https
        ports:
          # Define the container port
        - containerPort: 8443
          name: php-https
        volumeMounts:
        - name: tls-certs
          readOnly: true
          mountPath: /usr/local/etc/ssl/certs
      volumes:
      - name: tls-certs
        secret:
          # Define the name the secret
          secretName: php-certs
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: php-https
    name: php-https
  name: php-https
spec:
  ports:
  - port: 443
    protocol: TCP
    targetPort: 8443
  selector:
    name: php-https
[student@workstation network-review]$ oc create -f php-https.yaml
deployment.apps/php-https created
service/php-https created
[student@workstation network-review]$ oc get pods
NAME                         READY   STATUS              RESTARTS   AGE
php-http-5664cc5fbb-s7h7g    1/1     Running             0          22m
php-https-5f86674898-2cpqv   0/1     ContainerCreating   0          8s
[student@workstation network-review]$ oc get pods
NAME                         READY   STATUS    RESTARTS   AGE
php-http-5664cc5fbb-s7h7g    1/1     Running   0          22m
php-https-5f86674898-2cpqv   1/1     Running   0          29s
[student@workstation network-review]$ oc create route passthrough php-https --service php-https --port 8443 --hostname php-https.apps.ocp4.example.com
route.route.openshift.io/php-https created
[student@workstation network-review]$ oc get route
NAME        HOST/PORT                         PATH   SERVICES    PORT   TERMINATION   WILDCARD
php-http    php-http.apps.ocp4.example.com           php-http    8080                 None
php-https   php-https.apps.ocp4.example.com          php-https   8443   passthrough   None
[student@workstation network-review]$ oc describe route php-https
Name:			php-https
Namespace:		network-review
Created:		25 seconds ago
Labels:			app=php-https
			name=php-https
Annotations:		<none>
Requested Host:		php-https.apps.ocp4.example.com
			   exposed on router default (host router-default.apps.ocp4.example.com) 25 seconds ago
Path:			<none>
TLS Termination:	passthrough
Insecure Policy:	<none>
Endpoint Port:		8443

Service:	php-https
Weight:		100 (100%)
Endpoints:	10.8.0.34:8443
[student@workstation network-review]$ curl -v --cacert certs/training-CA.pem https://php-https.apps.ocp4.example.com
* Rebuilt URL to: https://php-https.apps.ocp4.example.com/
*   Trying 192.168.50.254...
* TCP_NODELAY set
* Connected to php-https.apps.ocp4.example.com (192.168.50.254) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: certs/training-CA.pem
  CApath: none
* TLSv1.3 (OUT), TLS handshake, Client hello (1):
* TLSv1.3 (IN), TLS handshake, Server hello (2):
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8):
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, Certificate (11):
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, CERT verify (15):
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, Finished (20):
* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.3 (OUT), TLS handshake, [no content] (0):
* TLSv1.3 (OUT), TLS handshake, Finished (20):
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384
* ALPN, server accepted to use http/1.1
* Server certificate:
*  subject: C=US; ST=North Carolina; L=Raleigh; O=Red Hat; CN=php-https.apps.ocp4.example.com
*  start date: Oct 31 16:54:36 2022 GMT
*  expire date: Oct 28 16:54:36 2032 GMT
*  subjectAltName: host "php-https.apps.ocp4.example.com" matched cert's "*.apps.ocp4.example.com"
*  issuer: C=US; ST=North Carolina; L=Raleigh; O=Red Hat; CN=ocp4.example.com
*  SSL certificate verify ok.
* TLSv1.3 (OUT), TLS app data, [no content] (0):
> GET / HTTP/1.1
> Host: php-https.apps.ocp4.example.com
> User-Agent: curl/7.61.1
> Accept: */*
> 
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
* TLSv1.3 (IN), TLS handshake, [no content] (0):
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):
* TLSv1.3 (IN), TLS app data, [no content] (0):
< HTTP/1.1 200 OK
< Date: Mon, 31 Oct 2022 17:04:02 GMT
< Server: Apache/2.4.37 (Red Hat Enterprise Linux) OpenSSL/1.1.1
< X-Powered-By: PHP/7.2.11
< Transfer-Encoding: chunked
< Content-Type: text/html; charset=UTF-8
< 

<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <title>PHP Application</title>
  </head>
  <body>
    <h2><strong>About this application</strong></h2>
            <i class="fa fa-lock"/><span style="color: #339966;"><strong>
          The application is currently served over TLS        </span></strong>
          <ul>
      <li>
        <strong>Current system load:</strong> 151      </li>
      <li>
        <strong>Number of connections:</strong> 0      </li>
      <li>
        <strong>Memory usage:</strong> 45 Mb      </li>
    </ul>
  </body>
* Connection #0 to host php-https.apps.ocp4.example.com left intact
</html>[student@workstation network-review]$ cd
[student@workstation ~]$ lab network-review grade

Grading the student's work for Lab: Configuring OpenShift Networking for Applications

 · network-review is present...................................  PASS
 · php-http deployment is present..............................  PASS
 · php-http deployment points to v1.0 of the application.......  PASS
 · php-http deployment uses port 8080..........................  PASS
 · php-http container is running...............................  PASS
 · Route for php-http is present...............................  PASS
 · Route for php-http is accessible............................  PASS
 · SSL certificate is present..................................  PASS
 · SSL certificate matches required CN.........................  PASS
 · TLS secret is present.......................................  PASS
 · php-https deployment is present.............................  PASS
 · php-https deployment points to v1.1 of the application......  PASS
 · php-https deployment uses port 8443.........................  PASS
 · php-https container is running..............................  PASS
 · Route for php-https is present..............................  PASS
 · Route for php-https is accessible using TLS CA..............  PASS
 · Network policy denies pod to pod traffic....................  PASS
 · Default namespace is labeled with network.openshift.io/polic
   y-group=ingress.............................................  PASS

Overall exercise grade.........................................  PASS

[student@workstation ~]$ lab network-review finish

Completing Lab: Configuring OpenShift Networking for Applications

 · Delete OpenShift project 'network-review'...................  SUCCESS
 · Wait for project 'network-review' to be gone................  SUCCESS
 · Remove network.openshift.io/policy-group=ingress label from 
   the default project.........................................  SUCCESS
 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 
---------------------------------------------------SUMMARY-------------------------------
In this chapter, you learned:

• OpenShift implements a software-defined networking (SDN) to manage the network
infrastructure of the cluster. SDN decouples the software that handles the traffic from the
underlying mechanisms that route the traffic.
• Kubernetes provides services that allow the logical grouping of pods under a common access
route. Services act as load balancers in front of one or more pods.
• Services use selectors (labels) that indicate which pods available to the service.
• There are two kind of routes: secure, and insecure. Secure routes encrypt the traffic using TLS
certificates, and insecure routes forward traffic over an unencrypted connection.
Secure routes support three modes: edge, passthrough, and re-encryption.
• Network policies control network traffic to pods. Logical zones can be created in the SDN to
segregate traffic among pods in any namespace.

----------------------------------------------------Ch-13-Controlling Pod Scheduling-------------------------------------------------
GE- Controlling Pod Scheduling Behavior


[student@workstation ~]$ lab schedule-pods start

Checking prerequisites for Guided Exercise: Controlling Pod Scheduling Behavior

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS

 Checking for conflicts with existing OpenShift projects:
 · The 'schedule-pods' project is absent.......................  SUCCESS
 · The 'schedule-pods-ts' project is absent....................  SUCCESS

Setting up the classroom for Guided Exercise: Controlling Pod Scheduling Behavior

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS

 Preparing the student's cluster:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS
 · Label the first worker node with 'client=ACME'..............  SUCCESS
 · Create project 'schedule-pods-ts' for troubleshooting.......  SUCCESS
 · Assign 'edit' role to 'developer' on 'schedule-pods-ts'.....  SUCCESS
 · Deploy 'hello-ts' application to 'schedule-pods-ts'.........  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You have one project on this server: "schedule-pods-ts"

Using project "schedule-pods-ts".
[student@workstation ~]$ oc new-project schedule-pods
Now using project "schedule-pods" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc projects
You have access to the following projects and can switch between them with ' project <projectname>':

  * schedule-pods
    schedule-pods-ts

Using project "schedule-pods" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ oc new-app --name hello --image quay.io/redhattraining/hello-world-nginx:v1.0
--> Found container image 44eaa13 (3 years old) from quay.io for "quay.io/redhattraining/hello-world-nginx:v1.0"

    Red Hat Universal Base Image 8 
    ------------------------------ 
    The Universal Base Image is designed and engineered to be the base layer for all of your containerized applications, middleware and utilities. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly.

    Tags: base rhel8

    * An image stream tag will be created as "hello:v1.0" that will track this image

--> Creating resources ...
    imagestream.image.openshift.io "hello" created
    deployment.apps "hello" created
    service "hello" created
--> Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     'oc expose service/hello' 
    Run 'oc status' to view your app.
[student@workstation ~]$ oc expose svc/hello
route.route.openshift.io/hello exposed
[student@workstation ~]$ oc get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
hello-787445fd88-zzxqv   1/1     Running   0          28s   10.9.0.21   master01   <none>           <none>
[student@workstation ~]$ oc scale --replicas 4 deployment/hello
deployment.apps/hello scaled
[student@workstation ~]$ oc get pods -o wide
NAME                     READY   STATUS              RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
hello-787445fd88-87qv8   0/1     ContainerCreating   0          3s    <none>      master03   <none>           <none>
hello-787445fd88-9v25g   1/1     Running             0          3s    10.9.0.22   master01   <none>           <none>
hello-787445fd88-b4s9m   0/1     ContainerCreating   0          3s    <none>      master02   <none>           <none>
hello-787445fd88-zzxqv   1/1     Running             0          77s   10.9.0.21   master01   <none>           <none>
[student@workstation ~]$ oc get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE       NOMINATED NODE   READINESS GATES
hello-787445fd88-87qv8   1/1     Running   0          34s    10.10.0.51   master03   <none>           <none>
hello-787445fd88-9v25g   1/1     Running   0          34s    10.9.0.22    master01   <none>           <none>
hello-787445fd88-b4s9m   1/1     Running   0          34s    10.8.0.35    master02   <none>           <none>
hello-787445fd88-zzxqv   1/1     Running   0          108s   10.9.0.21    master01   <none>           <none>
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 69 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "schedule-pods".
[student@workstation ~]$ oc get nodes -L env
NAME       STATUS   ROLES           AGE   VERSION           ENV
master01   Ready    master,worker   95d   v1.23.3+e419edf   
master02   Ready    master,worker   95d   v1.23.3+e419edf   
master03   Ready    master,worker   95d   v1.23.3+e419edf   
[student@workstation ~]$ oc label node master01 env=dev
node/master01 labeled
[student@workstation ~]$ oc label node master02 env=prod
node/master02 labeled
[student@workstation ~]$ oc get nodes -L env
NAME       STATUS   ROLES           AGE   VERSION           ENV
master01   Ready    master,worker   95d   v1.23.3+e419edf   dev
master02   Ready    master,worker   95d   v1.23.3+e419edf   prod
master03   Ready    master,worker   95d   v1.23.3+e419edf   
[student@workstation ~]$ oc login -u developer -p developer
Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

  * schedule-pods
    schedule-pods-ts

Using project "schedule-pods".
[student@workstation ~]$ oc edit deployment/hello
Edit cancelled, no changes made.
[student@workstation ~]$ oc get deployment/hello -o yaml | grep -i nodeSelector
[student@workstation ~]$ oc edit deployment/hello
deployment.apps/hello edited
[student@workstation ~]$ oc get deployment/hello -o yaml | grep -i nodeSelector
[student@workstation ~]$ oc get deployment/hello -o yaml | less
[student@workstation ~]$ oc get deployment
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
hello   4/4     4            4           6m30s
[student@workstation ~]$ oc get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
hello-787445fd88-87qv8   1/1     Running   0          5m39s   10.10.0.51   master03   <none>           <none>
hello-787445fd88-9v25g   1/1     Running   0          5m39s   10.9.0.22    master01   <none>           <none>
hello-787445fd88-b4s9m   1/1     Running   0          5m39s   10.8.0.35    master02   <none>           <none>
hello-787445fd88-zzxqv   1/1     Running   0          6m53s   10.9.0.21    master01   <none>           <none>
[student@workstation ~]$ oc edit deployment/hello
deployment.apps/hello edited
[student@workstation ~]$ oc get deployment/hello -o yaml | grep -i nodeSelector
      nodeSelector:
[student@workstation ~]$ oc get pods -o wide
NAME                    READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
hello-b64bdf567-7dbn4   1/1     Running   0          10s   10.9.0.26   master01   <none>           <none>
hello-b64bdf567-8x5cb   1/1     Running   0          14s   10.9.0.23   master01   <none>           <none>
hello-b64bdf567-lt9qz   1/1     Running   0          11s   10.9.0.25   master01   <none>           <none>
hello-b64bdf567-r588f   1/1     Running   0          14s   10.9.0.24   master01   <none>           <none>
[student@workstation ~]$ oc users
error: unknown command "users" for "oc"
[student@workstation ~]$ oc projects
You have access to the following projects and can switch between them with ' project <projectname>':

  * schedule-pods
    schedule-pods-ts

Using project "schedule-pods" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ oc delete project schedule-pods
project.project.openshift.io "schedule-pods" deleted
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "default".
[student@workstation ~]$ oc get nodes -L env
NAME       STATUS   ROLES           AGE   VERSION           ENV
master01   Ready    master,worker   96d   v1.23.3+e419edf   dev
master02   Ready    master,worker   96d   v1.23.3+e419edf   prod
master03   Ready    master,worker   96d   v1.23.3+e419edf   
[student@workstation ~]$ oc label node -l env env-
node/master01 unlabeled
node/master02 unlabeled
[student@workstation ~]$ oc get nodes -L env
NAME       STATUS   ROLES           AGE   VERSION           ENV
master01   Ready    master,worker   96d   v1.23.3+e419edf   
master02   Ready    master,worker   96d   v1.23.3+e419edf   
master03   Ready    master,worker   96d   v1.23.3+e419edf   
[student@workstation ~]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "schedule-pods-ts"

Using project "schedule-pods-ts".
[student@workstation ~]$ oc get pods
NAME                        READY   STATUS    RESTARTS   AGE
hello-ts-5bbd56696f-m4c6h   0/1     Pending   0          14m
[student@workstation ~]$ oc describe pod hello-ts-5bbd56696f-m4c6h
Name:           hello-ts-5bbd56696f-m4c6h
Namespace:      schedule-pods-ts
Priority:       0
Node:           <none>
Labels:         app=hello-ts
                pod-template-hash=5bbd56696f
Annotations:    openshift.io/scc: restricted
Status:         Pending
IP:             
IPs:            <none>
Controlled By:  ReplicaSet/hello-ts-5bbd56696f
Containers:
  hello-world-nginx:
    Image:        quay.io/redhattraining/hello-world-nginx:v1.0
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-m9vds (ro)
Conditions:
  Type           Status
  PodScheduled   False 
Volumes:
  kube-api-access-m9vds:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
QoS Class:                   BestEffort
Node-Selectors:              client=acme
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                 From               Message
  ----     ------            ----                ----               -------
  Warning  FailedScheduling  55s (x15 over 14m)  default-scheduler  0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector.
[student@workstation ~]$ oc project schedule-pods-ts
Already on project "schedule-pods-ts" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "schedule-pods-ts".
[student@workstation ~]$ oc get nodes -L client
NAME       STATUS   ROLES           AGE   VERSION           CLIENT
master01   Ready    master,worker   96d   v1.23.3+e419edf   ACME
master02   Ready    master,worker   96d   v1.23.3+e419edf   
master03   Ready    master,worker   96d   v1.23.3+e419edf   
[student@workstation ~]$ oc describe pod hello-ts-5bbd56696f-m4c6h | grpe -i "Node-Selectors"
bash: grpe: command not found...
Similar command is: 'grep'
[student@workstation ~]$ oc describe pod hello-ts-5bbd56696f-m4c6h | grep -i "Node-Selectors"
Node-Selectors:              client=acme
[student@workstation ~]$ oc get nodes -L client| grep -i acme
master01   Ready    master,worker   96d   v1.23.3+e419edf   ACME
[student@workstation ~]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "schedule-pods-ts"

Using project "schedule-pods-ts".
[student@workstation ~]$ oc edit deployment/hello-ts
deployment.apps/hello-ts edited
[student@workstation ~]$ oc describe pod hello-ts-5bbd56696f-m4c6h | grep -i "Node-Selectors"
Error from server (NotFound): pods "hello-ts-5bbd56696f-m4c6h" not found
[student@workstation ~]$ oc get deployment
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
hello-ts   1/1     1            1           21m
[student@workstation ~]$ oc get pods
NAME                      READY   STATUS    RESTARTS   AGE
hello-ts-7bf4648f-x7xk4   1/1     Running   0          31s
[student@workstation ~]$ oc describe pod hello-ts-7bf4648f-x7xk4 | grep -i "Node-Selectors"
Node-Selectors:              client=ACME
[student@workstation ~]$ oc get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
hello-ts-7bf4648f-x7xk4   1/1     Running   0          64s   10.9.0.27   master01   <none>           <none>
[student@workstation ~]$ lab schedule-pods finish

Completing Guided Exercise: Controlling Pod Scheduling Behavior

 · Delete OpenShift project 'schedule-pods-ts'.................  SUCCESS
 · Wait for project 'schedule-pods-ts' to be gone..............  SUCCESS
 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  SUCCESS
 · Remove 'client' label from worker nodes.....................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 


-------------------------------------------------------------------------------------------------------------------
GE-Limiting Resource Usage by an Application
--------------------------------------------------------------------------------------------------------------------
[student@workstation ~]$ lab schedule-limit start

Checking prerequisites for Guided Exercise: Limiting Resource Usage by an Application

 Verify the OpenShift cluster is running:
 · Router pods are available...................................  SUCCESS
 · OAuth pods are available....................................  SUCCESS
 · API pods are available......................................  SUCCESS
 · Control plane node 'master01' is ready......................  SUCCESS
 · Control plane node 'master02' is ready......................  SUCCESS
 · Control plane node 'master03' is ready......................  SUCCESS

 Checking for conflicts with existing OpenShift projects:
 · The 'schedule-limit' project is absent......................  SUCCESS
 Checking for conflicts with existing OpenShift projects:
 · The 'template-test' project is absent.......................  SUCCESS

Setting up the classroom for Guided Exercise: Limiting Resource Usage by an Application

 · Validate 'admin' can log in with password 'redhat'..........  SUCCESS
 · Validate 'leader' can log in with password 'redhat'.........  SUCCESS
 · Validate 'developer' can log in with password 'developer'...  SUCCESS

 Preparing the student's cluster:
 · Download exercise files.....................................  SUCCESS
 · Download solution files.....................................  SUCCESS

Overall start status...........................................  SUCCESS

[student@workstation ~]$ oc login -u developer -p developer https://api.ocp4.example.com:6443
Login successful.

You don't have any projects. You can try to create a new project, by running

    oc new-project <projectname>

[student@workstation ~]$ oc new-project schedule-limit
Now using project "schedule-limit" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation ~]$ oc projects
You have one project on this server: "schedule-limit".

Using project "schedule-limit" on server "https://api.ocp4.example.com:6443".
[student@workstation ~]$ oc create deployment hello-limit --image quay.io/redhattraining/hello-world-nginx:v1.0 --dry-run=client -o yaml > ~/DO280/labs/schedule-limit/hello-limit.yaml
[student@workstation ~]$ vim !$
vim ~/DO280/labs/schedule-limit/hello-limit.yaml
[student@workstation ~]$ vim ~/DO280/labs/schedule-limit/hello-limit.yaml
[student@workstation ~]$ cat !$
cat ~/DO280/labs/schedule-limit/hello-limit.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: hello-limit
  name: hello-limit
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello-limit
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: hello-limit
    spec:
      containers:
      - image: quay.io/redhattraining/hello-world-nginx:v1.0
        name: hello-world-nginx
        resources: 
          requests:
            cpu: "3"
            memory: 20Mi
status: {}
[student@workstation ~]$ oc create --save-config -f ~/DO280/labs/schedule-limit/hello-limit.yaml
deployment.apps/hello-limit created
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
hello-limit-c5f68c5d5-mvrhp   0/1     Pending   0          10s
[student@workstation ~]$ oc get events --field-selector type=Warning
LAST SEEN   TYPE      REASON             OBJECT                            MESSAGE
28s         Warning   FailedScheduling   pod/hello-limit-c5f68c5d5-mvrhp   0/3 nodes are available: 3 Insufficient cpu.
[student@workstation ~]$ vim ~/DO280/labs/schedule-limit/hello-limit.yaml
[student@workstation ~]$ grep -i cpu !$
grep -i cpu ~/DO280/labs/schedule-limit/hello-limit.yaml
            cpu: "1200m"
[student@workstation ~]$ oc apply -f ~/DO280/labs/schedule-limit/hello-limit.yaml
deployment.apps/hello-limit configured
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS              RESTARTS   AGE
hello-limit-bdd4f9548-kq5x5   0/1     ContainerCreating   0          11s
hello-limit-c5f68c5d5-mvrhp   0/1     Pending             0          2m20s
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
hello-limit-bdd4f9548-kq5x5   1/1     Running   0          27s
[student@workstation ~]$ oc scale --replicas 4 deployment/hello-limit
deployment.apps/hello-limit scaled
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS              RESTARTS   AGE
hello-limit-bdd4f9548-6zpn6   0/1     ContainerCreating   0          4s
hello-limit-bdd4f9548-7mrww   0/1     Pending             0          4s
hello-limit-bdd4f9548-kq5x5   1/1     Running             0          56s
hello-limit-bdd4f9548-pq79x   0/1     ContainerCreating   0          4s
[student@workstation ~]$ oc get pods
NAME                          READY   STATUS    RESTARTS   AGE
hello-limit-bdd4f9548-6zpn6   1/1     Running   0          16s
hello-limit-bdd4f9548-7mrww   0/1     Pending   0          16s
hello-limit-bdd4f9548-kq5x5   1/1     Running   0          68s
hello-limit-bdd4f9548-pq79x   1/1     Running   0          16s
[student@workstation ~]$ oc get events --field-selector type=Warning
LAST SEEN   TYPE      REASON             OBJECT                            MESSAGE
38s         Warning   FailedScheduling   pod/hello-limit-bdd4f9548-7mrww   0/3 nodes are available: 3 Insufficient cpu.
84s         Warning   FailedScheduling   pod/hello-limit-c5f68c5d5-mvrhp   0/3 nodes are available: 3 Insufficient cpu.
77s         Warning   FailedScheduling   pod/hello-limit-c5f68c5d5-mvrhp   skip schedule deleting pod: schedule-limit/hello-limit-c5f68c5d5-mvrhp
[student@workstation ~]$ oc delete all -l app=hello-limit
pod "hello-limit-bdd4f9548-6zpn6" deleted
pod "hello-limit-bdd4f9548-7mrww" deleted
pod "hello-limit-bdd4f9548-kq5x5" deleted
pod "hello-limit-bdd4f9548-pq79x" deleted
deployment.apps "hello-limit" deleted
replicaset.apps "hello-limit-bdd4f9548" deleted
replicaset.apps "hello-limit-c5f68c5d5" deleted
[student@workstation ~]$ oc create --save-config -f ~/DO280/labs/schedule-limit/loadtest.yaml
deployment.apps/loadtest created
service/loadtest created
route.route.openshift.io/loadtest created
[student@workstation ~]$ oc get routes
NAME       HOST/PORT                        PATH   SERVICES   PORT   TERMINATION   WILDCARD
loadtest   loadtest.apps.ocp4.example.com          loadtest   8080                 None
[student@workstation ~]$ curl -X GET http://loadtest.apps.ocp4.example.com/api/loadtest/v1/mem/150/60
curl: (52) Empty reply from server
[student@workstation ~]$ curl -X GET http://loadtest.apps.ocp4.example.com/api/loadtest/v1/mem/200/60
<html><body><h1>502 Bad Gateway</h1>
The server returned an invalid or incomplete response.
</body></html>
[student@workstation ~]$ curl -X GET http://loadtest.apps.ocp4.example.com/api/loadtest/v1/mem/200/60
<html><body><h1>502 Bad Gateway</h1>
The server returned an invalid or incomplete response.
</body></html>
[student@workstation ~]$ curl -X GET http://loadtest.apps.ocp4.example.com/api/loadtest/v1/mem/200/60
<html><body><h1>502 Bad Gateway</h1>
The server returned an invalid or incomplete response.
</body></html>
[student@workstation ~]$ curl -X GET http://loadtest.apps.ocp4.example.com/api/loadtest/v1/mem/200/60
<html><body><h1>502 Bad Gateway</h1>
The server returned an invalid or incomplete response.
</body></html>
[student@workstation ~]$ oc delete all -l app=loadtest
pod "loadtest-54fb9b7b8c-v8hk6" deleted
service "loadtest" deleted
deployment.apps "loadtest" deleted
route.route.openshift.io "loadtest" deleted
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "schedule-limit".
[student@workstation ~]$ oc create quota project-quota --hard cpu="3",memory="1G",configmaps="2" -n schedule-limit
resourcequota/project-quota created
[student@workstation ~]$ oc get quota
NAME            AGE   REQUEST                                   LIMIT
project-quota   14s   configmaps: 2/2, cpu: 0/3, memory: 0/1G   
[student@workstation ~]$ oc login -u developer -p developer
Login successful.

You have one project on this server: "schedule-limit"

Using project "schedule-limit".
[student@workstation ~]$ oc create configmap my-config
error: failed to create configmap: configmaps "my-config" is forbidden: exceeded quota: project-quota, requested: configmaps=1, used: configmaps=2, limited: configmaps=2
[student@workstation ~]$ oc login -u admin -p redhat
Login successful.

You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects'

Using project "schedule-limit".
[student@workstation ~]$ oc adm create-bootstrap-project-template -o yaml > /tmp/project-template.yaml
[student@workstation ~]$ cd ~/DO280/solutions/schedule-limit
[student@workstation schedule-limit]$ ls
project-template.yaml
[student@workstation schedule-limit]$ cat project-template.yaml 
apiVersion: template.openshift.io/v1
kind: Template
metadata:
  creationTimestamp: null
  name: project-request
objects:
- apiVersion: project.openshift.io/v1
  kind: Project
  metadata:
    annotations:
      openshift.io/description: ${PROJECT_DESCRIPTION}
      openshift.io/display-name: ${PROJECT_DISPLAYNAME}
      openshift.io/requester: ${PROJECT_REQUESTING_USER}
    creationTimestamp: null
    name: ${PROJECT_NAME}
  spec: {}
  status: {}
- apiVersion: rbac.authorization.k8s.io/v1
  kind: RoleBinding
  metadata:
    creationTimestamp: null
    name: admin
    namespace: ${PROJECT_NAME}
  roleRef:
    apiGroup: rbac.authorization.k8s.io
    kind: ClusterRole
    name: admin
  subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: ${PROJECT_ADMIN_USER}
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    name: ${PROJECT_NAME}-quota
  spec:
    hard:
      cpu: 3
      memory: 10G
- apiVersion: v1
  kind: LimitRange
  metadata:
    name: ${PROJECT_NAME}-limits
  spec:
    limits:
      - type: Container
        defaultRequest:
          cpu: 30m
          memory: 30M
parameters:
- name: PROJECT_NAME
- name: PROJECT_DISPLAYNAME
- name: PROJECT_DESCRIPTION
- name: PROJECT_ADMIN_USER
- name: PROJECT_REQUESTING_USER
[student@workstation schedule-limit]$ oc create -f project-template.yaml -n openshift-config
template.template.openshift.io/project-request created
[student@workstation schedule-limit]$ oc edit projects.config.openshift.io/cluster
project.config.openshift.io/cluster edited
[student@workstation schedule-limit]$ oc get pods -n openshift-apiserver
NAME                         READY   STATUS    RESTARTS   AGE
apiserver-6f8564cb8f-5sjkx   2/2     Running   0          24m
apiserver-6f8564cb8f-lhlnz   2/2     Running   0          24m
apiserver-6f8564cb8f-lvrqc   2/2     Running   0          22m
[student@workstation schedule-limit]$ oc get pods -n openshift-apiserver
NAME                         READY   STATUS    RESTARTS   AGE
apiserver-6f8564cb8f-5sjkx   2/2     Running   0          24m
apiserver-6f8564cb8f-lhlnz   2/2     Running   0          24m
apiserver-6f8564cb8f-lvrqc   2/2     Running   0          23m
[student@workstation schedule-limit]$ oc get pods -n openshift-apiserver
NAME                         READY   STATUS        RESTARTS   AGE
apiserver-6f8564cb8f-5sjkx   2/2     Terminating   0          25m
apiserver-6f8564cb8f-lhlnz   2/2     Running       0          24m
apiserver-6f8564cb8f-lvrqc   2/2     Running       0          23m
apiserver-7dc45d8d7-5bvlp    0/2     Pending       0          15s
[student@workstation schedule-limit]$ oc get pods -n openshift-apiserver
NAME                         READY   STATUS        RESTARTS   AGE
apiserver-6f8564cb8f-lhlnz   2/2     Running       0          26m
apiserver-6f8564cb8f-lvrqc   2/2     Terminating   0          24m
apiserver-7dc45d8d7-5bvlp    2/2     Running       0          91s
apiserver-7dc45d8d7-qzqn4    0/2     Pending       0          9s
[student@workstation schedule-limit]$ oc get pods -n openshift-apiserver
NAME                        READY   STATUS    RESTARTS   AGE
apiserver-7dc45d8d7-5bvlp   2/2     Running   0          6m
apiserver-7dc45d8d7-qzqn4   2/2     Running   0          4m38s
apiserver-7dc45d8d7-s475w   2/2     Running   0          3m17s
[student@workstation schedule-limit]$ oc new-project template-test
Now using project "template-test" on server "https://api.ocp4.example.com:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname

[student@workstation schedule-limit]$ oc get resourcequotas,limitranges
NAME                                AGE   REQUEST                   LIMIT
resourcequota/template-test-quota   14s   cpu: 0/3, memory: 0/10G   

NAME                              CREATED AT
limitrange/template-test-limits   2022-11-02T16:09:18Z
[student@workstation schedule-limit]$ oc delete project schedule-limit
project.project.openshift.io "schedule-limit" deleted
[student@workstation schedule-limit]$ oc delete project template-test
project.project.openshift.io "template-test" deleted
[student@workstation schedule-limit]$ lab schedule-limit finish

Completing Guided Exercise: Limiting Resource Usage by an Application

 · Removing project template 'template.template.openshift.io/pr
   oject-request'..............................................  SUCCESS
 · Reverting the cluster to use the default project template...  SUCCESS
 · Removing /tmp/project-template.yaml.........................  SUCCESS
 · Remove exercise files.......................................  SUCCESS
 · Remove solution files.......................................  FAIL

Cannot continue due to the previous errors.....................  FAIL
One or more terminal prompts is at /home/student/DO280/solutions/schedule-limit (or a subdirectory). Change to the /home/student/ directory and run 'lab schedule-limit finish' again.

[student@workstation schedule-limit]$ cd
[student@workstation ~]$ lab schedule-limit finish

Completing Guided Exercise: Limiting Resource Usage by an Application

 · Remove solution files.......................................  SUCCESS

Please use start if you wish to do the exercise again.

[student@workstation ~]$ 


